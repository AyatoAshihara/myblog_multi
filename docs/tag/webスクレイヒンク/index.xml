<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Webスクレイピング | 東京の資産運用会社で働く社会人が研究に没頭するブログ</title>
    <link>/tag/web%E3%82%B9%E3%82%AF%E3%83%AC%E3%82%A4%E3%83%92%E3%83%B3%E3%82%AF/</link>
      <atom:link href="/tag/web%E3%82%B9%E3%82%AF%E3%83%AC%E3%82%A4%E3%83%92%E3%83%B3%E3%82%AF/index.xml" rel="self" type="application/rss+xml" />
    <description>Webスクレイピング</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>ja</language><lastBuildDate>Sun, 05 Jul 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>Webスクレイピング</title>
      <link>/tag/web%E3%82%B9%E3%82%AF%E3%83%AC%E3%82%A4%E3%83%92%E3%83%B3%E3%82%AF/</link>
    </image>
    
    <item>
      <title>CNNを使って馬体写真から順位予想してみた</title>
      <link>/post/post18/</link>
      <pubDate>Sun, 05 Jul 2020 00:00:00 +0000</pubDate>
      <guid>/post/post18/</guid>
      <description>
&lt;script src=&#34;index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#データ収集のためのクローリング&#34;&gt;1. データ収集のためのクローリング&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#データをどこから取得するか&#34;&gt;データをどこから取得するか&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#seleniumでクローリングを実行する&#34;&gt;seleniumでクローリングを実行する&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#kerasを用いてcnnを学習させる&#34;&gt;2. &lt;code&gt;Keras&lt;/code&gt;を用いてCNNを学習させる&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#kerasとは&#34;&gt;Kerasとは？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#cnnとは&#34;&gt;CNNとは？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#コーディング&#34;&gt;コーディング&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#不均衡データ調整のためのアンダーサンプリング&#34;&gt;不均衡データ調整のためのアンダーサンプリング&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#shap値を用いた結果解釈&#34;&gt;3. Shap値を用いた結果解釈&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#最後に&#34;&gt;4. 最後に&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;おはこんばんにちは。今回は競馬予想についての記事を書きたいと思います。前回、&lt;code&gt;LightGBM&lt;/code&gt;を用いてyahoo競馬から取得したレース結果データ(テーブルデータ)を用いて、競馬順位予想モデルを作成しました。前回は構造データを用いましたが、このご時世ですからこんな分析は誰にでもできるわけです。時代は非構造データ、というわけで今回は馬体画像から特徴量を抽出し、順位予想を行う畳み込みニューラルネットワーク(&lt;code&gt;Convolutional Neural Network&lt;/code&gt;, CNN)を作成してみました。画像解析は&lt;code&gt;Earth Engine&lt;/code&gt;を用いた衛星画像の解析に続いて2回目、深層学習はこのブログでは初めてと言うことになります。なお、Pythonを使用しています。&lt;/p&gt;
&lt;div id=&#34;データ収集のためのクローリング&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;1. データ収集のためのクローリング&lt;/h2&gt;
&lt;p&gt;まず、馬体画像をネットから収集することから始めます。1番良いのはレース当日のパドックの写真を使用することでしょう。ただ、パドックの写真をまとまった形で掲載してくれているサイトは調べた限りは存在しませんでした。もしかしたら、Youtubeに競馬ファンの方がパドック動画を上げていらっしゃるかも知れませんので、それを画像に切り抜いて使う or 動画としてCNN→RNNの&lt;code&gt;Encoder-Decoder&lt;/code&gt;モデルに適用すると面白いかもしれません。しかし、そこまでの能力は今の自分にはありません。&lt;/p&gt;
&lt;div id=&#34;データをどこから取得するか&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;データをどこから取得するか&lt;/h3&gt;
&lt;p&gt;そこで、今回は&lt;a href=&#34;https://www.daily.co.jp/horse/horsecheck/photo/&#34;&gt;デイリーのWebサイト&lt;/a&gt;からデータを取得しています。ここには直近1年間?のG1レースに出馬する競走馬のレース前の馬体写真が掲載されています。実際のレース場へ行けない馬券師さんたちはこの写真を見て馬の状態を分析していると思われます。&lt;br /&gt;
なお、このサイトには出馬全頭の馬体写真が掲載されているわけではありません。また、G1の限られたレースのみですので、そもそも全ての馬が仕上がっている可能性もあり、差がつかないことも十分予想されます。ただ、手っ取り早くやってみることを優先し、今回はこのデータを使用することにしたいと思います。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;seleniumでクローリングを実行する&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;seleniumでクローリングを実行する&lt;/h3&gt;
&lt;p&gt;クローリングにはseleniumを使用します。今回はCNNがメインなのでWebクローリングについては説明しません。使用したコードは以下です。&lt;br /&gt;
【注意】以下のコードを使用される場合は自己責任でお願いします。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.select import Select
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.alert import Alert
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException
from selenium.webdriver.common.action_chains import ActionChains
from time import sleep
from urllib import request
import random

# seleniumのオプション設定（おまじない）
options = Options()
options.add_argument(&amp;#39;--disable-gpu&amp;#39;);
options.add_argument(&amp;#39;--disable-extensions&amp;#39;);
options.add_argument(&amp;#39;--proxy-server=&amp;quot;direct://&amp;quot;&amp;#39;);
options.add_argument(&amp;#39;--proxy-bypass-list=*&amp;#39;);
options.add_argument(&amp;#39;--start-maximized&amp;#39;);

# driver指定
DRIVER_PATH = r&amp;#39;C:/Users/aashi/Desktop/chromedriver_win32/chromedriver.exe&amp;#39;
driver = webdriver.Chrome(executable_path=DRIVER_PATH, chrome_options=options)

# urlを渡し、サイトへアクセス
url = &amp;#39;https://www.daily.co.jp/horse/horsecheck/photo/&amp;#39;
driver.get(url)
driver.implicitly_wait(15) # オブジェクトのロード待ちの最大時間でこれを越えるとエラー
sleep(5) # webページの遷移を行うので1秒sleep

# 各レース毎に画像データ保存
selector0 = &amp;quot;body &amp;gt; div &amp;gt; main &amp;gt; div &amp;gt; div.primaryContents &amp;gt; article &amp;gt; div &amp;gt; section &amp;gt; a&amp;quot;
elements = driver.find_elements_by_css_selector(selector0)
for i in range(0,len(elements)):
  elements = driver.find_elements_by_css_selector(selector0)
  element = elements[i]
  element.click()
  sleep(5) # webページの遷移を行うので5秒sleep

  target = driver.find_element_by_link_text(&amp;#39;Ｇ１馬体診断写真集のTOP&amp;#39;)
  actions = ActionChains(driver)
  actions.move_to_element(target)
  actions.perform()
  sleep(5) # webページの遷移を行うので5秒sleep
  selector = &amp;quot;body &amp;gt; div.wrapper.horse.is-fixedHeader.is-fixedAnimation &amp;gt; main &amp;gt; div &amp;gt; div.primaryContents &amp;gt; article &amp;gt; article &amp;gt; div.photoDetail-wrapper &amp;gt; section &amp;gt; div &amp;gt; figure&amp;quot;
  figures = driver.find_elements_by_css_selector(selector)
  download_dir = r&amp;#39;C:\Users\aashi\umanalytics\photo\image&amp;#39;
  selector = &amp;quot;body &amp;gt; div &amp;gt; main &amp;gt; div &amp;gt; div.primaryContents &amp;gt; article &amp;gt; article &amp;gt; div.photoDetail-wrapper &amp;gt; section &amp;gt; h1&amp;quot;
  race_name = driver.find_element_by_css_selector(selector).text
  for figure in figures:
    img_name = figure.find_element_by_tag_name(&amp;#39;figcaption&amp;#39;).text
    horse_src = figure.find_element_by_tag_name(&amp;#39;img&amp;#39;).get_attribute(&amp;quot;src&amp;quot;)    
    save_name = download_dir + &amp;#39;/&amp;#39; + race_name + &amp;#39;_&amp;#39; + img_name + &amp;#39;.jpg&amp;#39;
    request.urlretrieve(horse_src,save_name)
  driver.back()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;保存した画像を実際のレース結果と突合し、手作業で上位3位以内グループとそれ以外のグループに分けました。以下のような感じで画像が保存されています。&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;horse_photo.PNG&#34; alt=&#34;&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;保存された馬体画像&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;これで元データの収集が完了しました。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;kerasを用いてcnnを学習させる&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;2. &lt;code&gt;Keras&lt;/code&gt;を用いてCNNを学習させる&lt;/h2&gt;
&lt;div id=&#34;kerasとは&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Kerasとは？&lt;/h3&gt;
&lt;p&gt;さて、次に&lt;code&gt;Keras&lt;/code&gt;を使ってCNNを学習させましょう。まず、&lt;code&gt;Keras&lt;/code&gt;とは&lt;code&gt;Tensorflow&lt;/code&gt;や&lt;code&gt;Theano&lt;/code&gt;上で動く&lt;code&gt;Neural Network&lt;/code&gt;ライブラリの1つです。&lt;code&gt;Keras&lt;/code&gt;は比較的短いコードでモデルを組むことができ、また学習アルゴリズムが多いことが特徴のようです。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;cnnとは&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;CNNとは？&lt;/h3&gt;
&lt;p&gt;CNNは画像解析を行う際によく使用される&lt;code&gt;(Deep) Neural Network&lt;/code&gt;の1種で、その名の通り&lt;code&gt;Convolution&lt;/code&gt;(畳み込み)を追加した物となっています。畳み込みとは以下のような処理のことを言います。&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://cdn-ak.f.st-hatena.com/images/fotolife/t/tdualdir/20180501/20180501211957.png&#34; alt=&#34;&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;畳み込み層の処理&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;ここのインプットとは画像データのことです。画像解析では画像を数値として認識し、解析を行います。コンピュータ上の画像は&lt;code&gt;RGB&lt;/code&gt;値という、赤(Red)、緑(Green)、青(Blue)の3色の0~255までの数値の強弱で表現されています。赤255、緑0、青0といった形で3層のベクトルになっており、この場合完全な赤が表現されます。上図の場合、a,b,cなどが各ピクセルの&lt;code&gt;RGB&lt;/code&gt;値のいずれかを表していると考えることができます。畳み込みはこの&lt;code&gt;RGB&lt;/code&gt;値をカーネルと呼ばれる行列との内積をとることで画像の特徴量を計算します。畳み込み層の意味は以下の動画がわかりやすいです。&lt;/p&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/vU-JfZNBdYU&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;p&gt;カーネルを上手くその画像の特徴的な部分を取得できるように学習することで、画像の識別が可能になります。畳み込み層はCNNの最重要部分だと思います。&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://th.bing.com/th/id/OIP.F2Ik_XFzmu5jZF-byiAKQQHaCg?w=342&amp;amp;h=118&amp;amp;c=7&amp;amp;o=5&amp;amp;dpr=1.25&amp;amp;pid=1.7&#34; alt=&#34;&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;CNNの全体像&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;上図のようにCNNは畳み込み意外にももちろん入力層や出力層など通常の&lt;code&gt;Neural Network&lt;/code&gt;と同じ層も持っています。なお、&lt;code&gt;MaxPooling&lt;/code&gt;層について知りたい人は以下の動画を参照されてください。&lt;/p&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/MLixg9K6oeU&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;p&gt;深層学習の学習方法については最急下降法(勾配法)がオーソドックスなものとして知られていますが、&lt;code&gt;Adam&lt;/code&gt;など色々な拡張アルゴリズムが提案されています。基本的には、&lt;code&gt;Adam&lt;/code&gt;は&lt;code&gt;momentum&lt;/code&gt;を使用することが多いでしょうか。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;コーディング&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;コーディング&lt;/h3&gt;
&lt;p&gt;では、実際にコーディングしていきます。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;from keras.utils import np_utils
from keras.models import Sequential
from keras.layers.convolutional import MaxPooling2D
from keras.layers import Activation, Conv2D, Flatten, Dense,Dropout
from sklearn.model_selection import train_test_split
from keras.optimizers import SGD, Adadelta, Adagrad, Adam, Adamax, RMSprop, Nadam
from PIL import Image
import numpy as np
import glob
import matplotlib.pyplot as plt
import time
import os&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;まず最初に収集してきた画像データを数値データに変換し学習データを作成します。
ディレクトリ構造は以下のようになっており、上位画像とその他画像が別ディレクトリに保存されています。各ディレクトリから画像を読み込む際に、上位画像には1、その他には0というカテゴリ変数を与えます。&lt;/p&gt;
&lt;p&gt;馬体写真&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;上位&lt;/li&gt;
&lt;li&gt;その他&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;#フォルダを指定
folders = os.listdir(r&amp;quot;C:\Users\aashi\umanalytics\photo\image&amp;quot;)
#画総数を指定(今回は50×50×3)。
image_size = 300
dense_size = len(folders)

X = []
Y = []

#それぞれのフォルダから画像を読み込み、Image関数を使用してRGB値ベクトル(numpy array)へ変換
for i, folder in enumerate(folders):
  files = glob.glob(&amp;quot;C:/Users/aashi/umanalytics/photo/image/&amp;quot; + folder + &amp;quot;/*.jpg&amp;quot;)
  index = i
  for k, file in enumerate(files):
    image = Image.open(file)
    image = image.convert(&amp;quot;L&amp;quot;).convert(&amp;quot;RGB&amp;quot;)
    image = image.resize((image_size, image_size)) #画素数を落としている
 
    data = np.asarray(image)
    X.append(data)
    Y.append(index)

X = np.array(X)
Y = np.array(Y)
X = X.astype(&amp;#39;float32&amp;#39;)
X = X / 255.0 # 0~1へ変換
X.shape
Y = np_utils.to_categorical(Y, dense_size)

#訓練データとテストデータへ変換
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;訓練データとテストデータの分割ができました。今考えているのは「上位」と「その他」の2値分類となっていますが、「上位」を3位以内と定義したので不均衡なデータとなっています(その他データが上位データの5倍くらい)。こういった場合、そのままのデータで学習をするとサンプルサイズが多い方のラベル(この場合「その他」)を予測しやすくなり、バイアスのあるモデルとなります。よって、学習データは2クラスそれぞれが同じサンプルサイズとなるよう調整してやる必要があります。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;index_zero = np.random.choice(np.array(np.where(y_train[:,1]==0))[0,],np.count_nonzero(y_train[:,1]==1),replace=False)
index_one = np.array(np.where(y_train[:,1]==1))[0]
y_resampled = y_train[np.hstack((index_one,index_zero))]
X_resampled = X_train[np.hstack((index_one,index_zero))]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;学習データにはこの&lt;code&gt;y_resampled&lt;/code&gt;と&lt;code&gt;X_resampled&lt;/code&gt;を使用します。次に、CNNを構築していきます。&lt;code&gt;Keras&lt;/code&gt;では、&lt;code&gt;sequential model&lt;/code&gt;を指定し、&lt;code&gt;add&lt;/code&gt;メソッドで層を追加して行くことでモデルを定義します。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;model = Sequential()
model.add(Conv2D(32, (3, 3), padding=&amp;#39;same&amp;#39;,input_shape=X_train.shape[1:]))
model.add(Activation(&amp;#39;relu&amp;#39;))
model.add(Conv2D(32, (3, 3)))
model.add(Activation(&amp;#39;relu&amp;#39;))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Conv2D(64, (3, 3), padding=&amp;#39;same&amp;#39;))
model.add(Activation(&amp;#39;relu&amp;#39;))
model.add(Conv2D(64, (3, 3)))
model.add(Activation(&amp;#39;relu&amp;#39;))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(512))
model.add(Activation(&amp;#39;relu&amp;#39;))
model.add(Dropout(0.5))
model.add(Dense(dense_size))
model.add(Activation(&amp;#39;softmax&amp;#39;))

model.summary()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Model: &amp;quot;sequential&amp;quot;
## _________________________________________________________________
## Layer (type)                 Output Shape              Param #   
## =================================================================
## conv2d (Conv2D)              (None, 300, 300, 32)      896       
## _________________________________________________________________
## activation (Activation)      (None, 300, 300, 32)      0         
## _________________________________________________________________
## conv2d_1 (Conv2D)            (None, 298, 298, 32)      9248      
## _________________________________________________________________
## activation_1 (Activation)    (None, 298, 298, 32)      0         
## _________________________________________________________________
## max_pooling2d (MaxPooling2D) (None, 149, 149, 32)      0         
## _________________________________________________________________
## dropout (Dropout)            (None, 149, 149, 32)      0         
## _________________________________________________________________
## conv2d_2 (Conv2D)            (None, 149, 149, 64)      18496     
## _________________________________________________________________
## activation_2 (Activation)    (None, 149, 149, 64)      0         
## _________________________________________________________________
## conv2d_3 (Conv2D)            (None, 147, 147, 64)      36928     
## _________________________________________________________________
## activation_3 (Activation)    (None, 147, 147, 64)      0         
## _________________________________________________________________
## max_pooling2d_1 (MaxPooling2 (None, 73, 73, 64)        0         
## _________________________________________________________________
## dropout_1 (Dropout)          (None, 73, 73, 64)        0         
## _________________________________________________________________
## flatten (Flatten)            (None, 341056)            0         
## _________________________________________________________________
## dense (Dense)                (None, 512)               174621184 
## _________________________________________________________________
## activation_4 (Activation)    (None, 512)               0         
## _________________________________________________________________
## dropout_2 (Dropout)          (None, 512)               0         
## _________________________________________________________________
## dense_1 (Dense)              (None, 2)                 1026      
## _________________________________________________________________
## activation_5 (Activation)    (None, 2)                 0         
## =================================================================
## Total params: 174,687,778
## Trainable params: 174,687,778
## Non-trainable params: 0
## _________________________________________________________________&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;では、学習パートに入ります。アルゴリズムには&lt;code&gt;Adadelta&lt;/code&gt;を使用します。よくわかってないんですけどね。。。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;optimizers =&amp;quot;Adadelta&amp;quot;
results = {}
epochs = 50
model.compile(loss=&amp;#39;categorical_crossentropy&amp;#39;, optimizer=optimizers, metrics=[&amp;#39;accuracy&amp;#39;])
results = model.fit(X_resampled, y_resampled, validation_split=0.2, epochs=epochs)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;不均衡データ調整のためのアンダーサンプリング&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;不均衡データ調整のためのアンダーサンプリング&lt;/h3&gt;
&lt;p&gt;ここから、Testデータで2値分類を行うのですが、学習データをアンダーサンプリングしているので、予測確率を計算する際にアンダーサンプリングを行ったサンプル選択バイアスが生じてしまいます。論文は&lt;a href=&#34;https://www3.nd.edu/~dial/publications/dalpozzolo2015calibrating.pdf&#34;&gt;こちら&lt;/a&gt;。
よって、補正が必要になるのですがこの部分の定式化をここでしておきたいと思います。現在行っている2値分類問題を説明千数&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;から2値を取る目的変数&lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;を予測する問題と表現することにします。データセット&lt;span class=&#34;math inline&#34;&gt;\((X,Y)\)&lt;/span&gt;は正例が負例よりもかなり少なく、負例のサンプルサイズを正例に合わせたデータセットを&lt;span class=&#34;math inline&#34;&gt;\((X_s,Y_s)\)&lt;/span&gt;とします。ここで、&lt;span class=&#34;math inline&#34;&gt;\((X,Y)\)&lt;/span&gt;のサンプル組が&lt;span class=&#34;math inline&#34;&gt;\((X_s,Y_s)\)&lt;/span&gt;にも含まれる場合に1を取り、含まれない場合に0をとるカテゴリ変数&lt;span class=&#34;math inline&#34;&gt;\(s\)&lt;/span&gt;を定義します。
データセット&lt;span class=&#34;math inline&#34;&gt;\((X,Y)\)&lt;/span&gt;を用いて構築したモデルに説明変数&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;を与えた時、正例と予測する条件付き確率は&lt;span class=&#34;math inline&#34;&gt;\(P(y=1|x)\)&lt;/span&gt;で表すことができます。一方、&lt;span class=&#34;math inline&#34;&gt;\((X_s,Y_s)\)&lt;/span&gt;を用いて構築したモデルで正例を予測する条件付き確率はベイズの定理とカテゴリ変数&lt;span class=&#34;math inline&#34;&gt;\(s\)&lt;/span&gt;を用いて、&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
P(y=1|x,s=1) = \frac{P(s=1|y=1)P(y=1|x)}{P(s=1|y=1)P(y=1|x) + P(s=1|y=0)P(y=0|x)}
\]&lt;/span&gt;
と書けます。&lt;span class=&#34;math inline&#34;&gt;\((X_s,Y_s)\)&lt;/span&gt;は負例のサンプルサイズを正例に合わせているため、&lt;span class=&#34;math inline&#34;&gt;\(P(s=1,y=1)=1\)&lt;/span&gt;であるので上式は&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
P(y=1|x,s=1) = \frac{P(y=1|x)}{P(y=1|x) + P(s=1|y=0)P(y=0|x)}
= \frac{P(y=1|x)}{P(y=1|x) + P(s=1|y=0)(1-P(y=1|x))}
\]&lt;/span&gt;
と書き換えることができます。&lt;span class=&#34;math inline&#34;&gt;\(P(s=1|y=0)\neq0\)&lt;/span&gt;であることは&lt;span class=&#34;math inline&#34;&gt;\((X_s,Y_s)\)&lt;/span&gt;の定義より自明です(0だと正例しかない不均衡データになる)。よって、&lt;span class=&#34;math inline&#34;&gt;\(P(y=0,x)\neq0\)&lt;/span&gt;である限り、アンダーサンプリングのモデルが正例とはじき出す確率は元のデータセットが出す確率に対して正のバイアスがあることがわかります。求めたいのはバイアスのない&lt;span class=&#34;math inline&#34;&gt;\(P(y=1|x)\)&lt;/span&gt;なので&lt;span class=&#34;math inline&#34;&gt;\(P=P(y=1|x),P_s=P(y|x,s=1),\beta=P(s=1,y=0)\)&lt;/span&gt;とすると、&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
P = \frac{\beta P_s}{\beta P_s-P_s+1}
\]&lt;/span&gt;
とかけ、この関係式を用いてバイアスを補正することができます。
今確認したことを関数として定義しましょう。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;def calibration(y_proba, beta):
    return y_proba / (y_proba + (1 - y_proba) / beta)

sampling_rate = sum(y_train[:,1]) / sum(1-y_train[:,1])
y_proba_calib = calibration(model.predict(X_test), sampling_rate)
y_pred = np_utils.to_categorical(np.argmax(y_proba_calib,axis=1), dense_size)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score
score = accuracy_score(y_test, y_pred)
print(&amp;#39;Test accuracy:&amp;#39;, score)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Test accuracy: 0.288135593220339&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;まったく良くない結果です。&lt;code&gt;ConfusionMatrix&lt;/code&gt;を出してみたところどうやらうまくいっていないことがわかりました。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;ConfusionMatrixDisplay(confusion_matrix(np.argmax(y_test,axis=1), np.argmax(y_pred,axis=1))).plot()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;lt;sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay object at 0x000000004939E748&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;plt.show()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;plt.close()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;不均衡データのバイアス修正はしたんですが、それでもなお負値を予測しやすいモデルとなっています。これでは使えないですね。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;shap値を用いた結果解釈&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;3. Shap値を用いた結果解釈&lt;/h2&gt;
&lt;p&gt;今学習したモデルの&lt;code&gt;shap&lt;/code&gt;値を考え、結果の解釈をしたいと思います。&lt;code&gt;shap&lt;/code&gt;値については時間があれば、説明を追記したいと思います。簡単に言えば、CNNが画像のどの部分に特徴を捉え、馬が上位に入るかを予想したかを可視化で捉えることができます。この馬の解析をすることにします。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;plt.imshow(X_test[0])
plt.show()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;plt.close()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import shap
background = X_train[np.random.choice(X_train.shape[0],100,replace=False)]

e = shap.GradientExplainer(model,background)

shap_values = e.shap_values(X_test[[0]])
shap.image_plot(shap_values[1],X_test[[0]])&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;非常に微妙ですが、足や臀部などを評価しているようにみえます。ですが、背景に反応しているようにも見えるので馬体のみ取り出すトリミングをやる必要がありますね。これは物体検知のモデルを構築する必要がありそうです。また、今度の機会に考えます。
各層において画像のどの側面を捉えているかを可視化してみたいと思います。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;from keras import models

layer_outputs = [layer.output for layer in model.layers[:8]]
layer_names = []
for layer in model.layers[:8]:
    layer_names.append(layer.name)
images_per_row = 16

activation_model = models.Model(inputs=model.input, outputs=layer_outputs)
activations = activation_model.predict(X_train[[0]])

for layer_name, layer_activation in zip(layer_names, activations):
    n_features = layer_activation.shape[-1]

    size = layer_activation.shape[1]

    n_cols = n_features // images_per_row
    display_grid = np.zeros((size * n_cols, images_per_row * size))

    for col in range(n_cols):
        for row in range(images_per_row):
            channel_image = layer_activation[0,
                                             :, :,
                                             col * images_per_row + row]
            channel_image -= channel_image.mean()
            channel_image /= channel_image.std()
            channel_image *= 64
            channel_image += 128
            channel_image = np.clip(channel_image, 0, 255).astype(&amp;#39;uint8&amp;#39;)
            display_grid[col * size : (col + 1) * size,
                         row * size : (row + 1) * size] = channel_image

    scale = 1. / size
    plt.figure(figsize=(scale * display_grid.shape[1],
                        scale * display_grid.shape[0]))
    plt.title(layer_name)
    plt.grid(False)
    plt.imshow(display_grid, cmap=&amp;#39;viridis&amp;#39;)
    plt.show()
    plt.close()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;1536&#34; /&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-16-2.png&#34; width=&#34;1536&#34; /&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-16-3.png&#34; width=&#34;1536&#34; /&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-16-4.png&#34; width=&#34;1536&#34; /&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-16-5.png&#34; width=&#34;1536&#34; /&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-16-6.png&#34; width=&#34;1536&#34; /&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-16-7.png&#34; width=&#34;1536&#34; /&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-16-8.png&#34; width=&#34;1536&#34; /&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-16-9.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;自分が未熟なこともあり、解釈が難しいですね。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;最後に&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;4. 最後に&lt;/h2&gt;
&lt;p&gt;正直まったく上手くいっていません。やはり馬体から順位予測をするのは難しいのでしょうか。ほかの変数と掛け合わせると結果が変わったりするのでしょうか。今のままだとよい特徴量を抽出することができていないように思います。
Youtubeからパドック動画を取得して、&lt;code&gt;Encoder-Decoder&lt;/code&gt;モデルで解析するところまでやらないとうまくいかないんですかね。自分の実力が十分上がれば是非やってみたいと思います(いつになることやら)。それまでには、PCのスペックを上げないといけません。定額給付金を使うかな。。。&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>rvestでyahoo競馬にある過去のレース結果をスクレイピングしてみた（2回目）</title>
      <link>/post/post11/</link>
      <pubDate>Sat, 13 Jul 2019 00:00:00 +0000</pubDate>
      <guid>/post/post11/</guid>
      <description>&lt;p&gt;2回目になりますが、またrvestで過去のレース結果を落としてみたいと思います。過去の記事を見てないという人は先にそちらをご覧になられることをお勧めします。&lt;/p&gt;
&lt;p&gt;今回データを取り直そうと思ったのは、競馬の分析をした際により多くの項目を説明変数に加えて、分析をしたいと思ったからです。なので、今回は前回のRスクリプトに追記を行う形でプログラムを作成しました。新たに追加したデータ項目は以下の14個です。&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;芝かダートか&lt;/li&gt;
&lt;li&gt;右回りか左回りか&lt;/li&gt;
&lt;li&gt;レースコンディション（良や稍重など）&lt;/li&gt;
&lt;li&gt;天候&lt;/li&gt;
&lt;li&gt;馬の毛色（栗毛、鹿毛など）&lt;/li&gt;
&lt;li&gt;馬主&lt;/li&gt;
&lt;li&gt;生産者&lt;/li&gt;
&lt;li&gt;産地&lt;/li&gt;
&lt;li&gt;生年月日&lt;/li&gt;
&lt;li&gt;父馬&lt;/li&gt;
&lt;li&gt;母馬&lt;/li&gt;
&lt;li&gt;そのレースまでの獲得賞金（2003年から入手可能）&lt;/li&gt;
&lt;li&gt;ジョッキーの体重&lt;/li&gt;
&lt;li&gt;ジョッキーの体重の増減&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;実はまだデータ収集は終わっていなくて、Rのプログラムがずっと実行中になっています（3日くらい回しています）。しかし、プログラム自体はきっちり回っているのでスクリプトの紹介をしていこうと思います。もしかしたら追記で結果を書くかもしれません。&lt;/p&gt;
&lt;div id=&#34;スクリプトの中身&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;1. スクリプトの中身&lt;/h2&gt;
&lt;p&gt;まずはパッケージの呼び出しです。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# rvestによる競馬データのwebスクレイピング

#install.packages(&amp;quot;rvest&amp;quot;)
#if (!require(&amp;quot;pacman&amp;quot;)) install.packages(&amp;quot;pacman&amp;quot;)
#install.packages(&amp;quot;beepr&amp;quot;)
#install.packages(&amp;quot;RSQLite&amp;quot;)
pacman::p_load(qdapRegex)
library(rvest)
library(stringr)
library(dplyr)
library(beepr)
library(RSQLite)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;かなりwarnningが出るのでそれを禁止し、SQLiteに接続しています&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# warnning禁止
options(warn=-1)

# SQLiteへの接続
con = dbConnect(SQLite(), &amp;quot;horse_data.db&amp;quot;, synchronous=&amp;quot;off&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;1994年からしかオッズが取れないので、1994年から直近までのデータを取得します。yahoo競馬では月ごとにレースがまとめられているので、それを変数として使用しながらデータをとっていきます。基本的には、&lt;a href=&#34;https://keiba.yahoo.co.jp/schedule/list/2018/?month=7&#34;&gt;該当年、該当月のレース結果一覧&lt;/a&gt;へアクセスし、そのページ上の各日の&lt;a href=&#34;https://keiba.yahoo.co.jp/race/list/18020106/&#34;&gt;個々の競馬場ごとのタイムテーブル&lt;/a&gt;へのリンクを取得します。個々の競馬場でレースはだいたい12ほどあるので、そのリンクを取得し、各レースの&lt;a href=&#34;https://keiba.yahoo.co.jp/race/result/1802010601/&#34;&gt;レース結果ページ&lt;/a&gt;にアクセスします。そして、レース結果を取得していきます。まず、各日の個々の競馬場ごとのタイムテーブルへのリンクの取得方法です。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;for(year in 1994:2019){
  start.time &amp;lt;- Sys.time() # 計算時間を図る
  # yahoo競馬のレース結果一覧ページの取得
  for (k in 1:12){ # kは月を表す
    
    tryCatch(
      {
        keiba.yahoo &amp;lt;- read_html(str_c(&amp;quot;https://keiba.yahoo.co.jp/schedule/list/&amp;quot;, year,&amp;quot;/?month=&amp;quot;,k)) # 該当年、該当月のレース結果一覧にアクセス
        Sys.sleep(2)
        race_lists &amp;lt;- keiba.yahoo %&amp;gt;%
          html_nodes(&amp;quot;a&amp;quot;) %&amp;gt;% 
          html_attr(&amp;quot;href&amp;quot;) # 全urlを取得
        
        # 競馬場ごとの各日のレースリストを取得
        race_lists &amp;lt;- race_lists[str_detect(race_lists, pattern=&amp;quot;race/list/\\d+/&amp;quot;)==1] # 「result」が含まれるurlを抽出
      }
      , error = function(e){signal &amp;lt;- 1}
    )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ここでは、取得したリンクのurlにresultという文字が含まれているものだけを抽出しています。要はそれが各競馬場のレーステーブルへのリンクとなります。ここからは取得した競馬場のレーステーブルのリンクを用いて、そのページにアクセスし、全12レースそれぞれのレース結果が掲載されているページのリンクを取得していきます。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;    for (j in 1:length(race_lists)){ # jは当該年月にあったレーステーブルへのリンクを表す
      
      tryCatch(
        {
          race_list &amp;lt;- read_html(str_c(&amp;quot;https://keiba.yahoo.co.jp&amp;quot;,race_lists[j]))
          race_url &amp;lt;- race_list %&amp;gt;% html_nodes(&amp;quot;a&amp;quot;) %&amp;gt;% html_attr(&amp;quot;href&amp;quot;) # 全urlを取得
          
          # レース結果のurlを取得
          race_url &amp;lt;- race_url[str_detect(race_url, pattern=&amp;quot;result&amp;quot;)==1] # 「result」が含まれるurlを抽出
        }
        , error = function(e){signal &amp;lt;- 1}
      )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;各レース結果へのリンクが取得できたので、ここからはいよいよレース結果の取得とその整形パートに入ります。かなり長ったらしく複雑なコードになってしまいました。レース結果は以下のようなテーブル属性に格納されているので、まずそれを単純に引っ張ってきます。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;      for (i in 1:length(race_url)){ # iは当該年月当該競馬場で開催されたレースを表す
        
        print(str_c(&amp;quot;現在、&amp;quot;, year, &amp;quot;年&amp;quot;, k, &amp;quot;月&amp;quot;,j, &amp;quot;グループ、&amp;quot;, i,&amp;quot;番目のレースの保存中です&amp;quot;))
        
        tryCatch(
          {
            race1 &amp;lt;-  read_html(str_c(&amp;quot;https://keiba.yahoo.co.jp&amp;quot;,race_url[i])) # レース結果のurlを取得
            signal &amp;lt;- 0
            Sys.sleep(2)
          }
          , error = function(e){signal &amp;lt;- 1}
        )
        
        # レースが中止orこれまでの過程でエラーでなければ処理を実行
        if (identical(race1 %&amp;gt;%
                      html_nodes(xpath = &amp;quot;//div[@class = &amp;#39;resultAtt mgnBL fntSS&amp;#39;]&amp;quot;) %&amp;gt;%
                      html_text(),character(0)) == TRUE &amp;amp;&amp;amp; signal == 0){
          
          # レース結果をスクレイピング
          race_result &amp;lt;- race1 %&amp;gt;% html_nodes(xpath = &amp;quot;//table[@id = &amp;#39;raceScore&amp;#39;]&amp;quot;) %&amp;gt;%
            html_table()
          race_result &amp;lt;- do.call(&amp;quot;data.frame&amp;quot;,race_result) # リストをデータフレームに変更
          
          colnames(race_result) &amp;lt;- c(&amp;quot;order&amp;quot;,&amp;quot;frame_number&amp;quot;,&amp;quot;horse_number&amp;quot;,&amp;quot;horse_name/age&amp;quot;,&amp;quot;time/margin&amp;quot;,&amp;quot;passing_rank/last_3F&amp;quot;,&amp;quot;jockey/weight&amp;quot;,&amp;quot;popularity/odds&amp;quot;,&amp;quot;trainer&amp;quot;) #　列名変更&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;tableをただ取得しただけでは以下のように、一つのセルに複数の情報が入っていたりと分析には使えないデータとなっています。なので、これを成型する必要が出てきます。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;          # 通過順位と上り3Fのタイム
          race_result &amp;lt;- dplyr::mutate(race_result,passing_rank=as.character(str_extract_all(race_result$`passing_rank/last_3F`,&amp;quot;(\\d{2}-\\d{2}-\\d{2}-\\d{2})|(\\d{2}-\\d{2}-\\d{2})|(\\d{2}-\\d{2})&amp;quot;)))
          race_result &amp;lt;- dplyr::mutate(race_result,last_3F=as.character(str_extract_all(race_result$`passing_rank/last_3F`,&amp;quot;\\d{2}\\.\\d&amp;quot;)))
          race_result &amp;lt;- race_result[-6]
          
          # タイムと着差
          race_result &amp;lt;- dplyr::mutate(race_result,time=as.character(str_extract_all(race_result$`time/margin`,&amp;quot;\\d\\.\\d{2}\\.\\d|\\d{2}\\.\\d&amp;quot;)))
          race_result &amp;lt;- dplyr::mutate(race_result,margin=as.character(str_extract_all(race_result$`time/margin`,&amp;quot;./.馬身|.馬身|.[:space:]./.馬身|[ア-ン-]+&amp;quot;)))
          race_result$margin[race_result$order==1] &amp;lt;- &amp;quot;トップ&amp;quot;
          race_result$margin[race_result$margin==&amp;quot;character(0)&amp;quot;] &amp;lt;- &amp;quot;大差&amp;quot;
          race_result$margin[race_result$order==0] &amp;lt;- NA
          race_result &amp;lt;- race_result[-5]
          
          # 馬名、馬齢、馬体重
          race_result &amp;lt;- dplyr::mutate(race_result,horse_name=as.character(str_extract_all(race_result$`horse_name/age`,&amp;quot;[ァ-ヴー・]+&amp;quot;)))
          race_result &amp;lt;- dplyr::mutate(race_result,horse_age=as.character(str_extract_all(race_result$`horse_name/age`,&amp;quot;牡\\d+|牝\\d+|せん\\d+&amp;quot;)))
          race_result$horse_sex &amp;lt;- str_extract(race_result$horse_age, pattern = &amp;quot;牡|牝|せん&amp;quot;)
          race_result$horse_age &amp;lt;- str_extract(race_result$horse_age, pattern = &amp;quot;\\d&amp;quot;)
          race_result &amp;lt;- dplyr::mutate(race_result,horse_weight=as.character(str_extract_all(race_result$`horse_name/age`,&amp;quot;\\d{3}&amp;quot;)))
          race_result &amp;lt;- dplyr::mutate(race_result,horse_weight_change=as.character(str_extract_all(race_result$`horse_name/age`,&amp;quot;\\([\\+|\\-]\\d+\\)|\\([\\d+]\\)&amp;quot;)))
          race_result$horse_weight_change &amp;lt;- sapply(rm_round(race_result$horse_weight_change, extract=TRUE), paste, collapse=&amp;quot;&amp;quot;)
          race_result &amp;lt;- dplyr::mutate(race_result,brinker=as.character(str_extract_all(race_result$`horse_name/age`,&amp;quot;B&amp;quot;)))
          race_result$brinker[race_result$brinker!=&amp;quot;B&amp;quot;] &amp;lt;- &amp;quot;N&amp;quot;
          race_result &amp;lt;- race_result[-4]
          
          # ジョッキー
          race_result &amp;lt;- dplyr::mutate(race_result,jockey=as.character(str_extract_all(race_result$`jockey/weight`,&amp;quot;[ぁ-ん一-龠]+\\s[ぁ-ん一-龠]+|[:upper:].[ァ-ヶー]+&amp;quot;)))
          race_result &amp;lt;- dplyr::mutate(race_result,jockey_weight=as.character(str_extract_all(race_result$`jockey/weight`,&amp;quot;\\d{2}&amp;quot;)))
          race_result$jockey_weight_change &amp;lt;- 0
          race_result$jockey_weight_change[str_detect(race_result$`jockey/weight`,&amp;quot;☆&amp;quot;)==1] &amp;lt;- 1
          race_result$jockey_weight_change[str_detect(race_result$`jockey/weight`,&amp;quot;△&amp;quot;)==1] &amp;lt;- 2
          race_result$jockey_weight_change[str_detect(race_result$`jockey/weight`,&amp;quot;△&amp;quot;)==1] &amp;lt;- 3
          race_result &amp;lt;- race_result[-4]
          
          # オッズと人気
          race_result &amp;lt;- dplyr::mutate(race_result,odds=as.character(str_extract_all(race_result$`popularity/odds`,&amp;quot;\\(.+\\)&amp;quot;)))
          race_result &amp;lt;- dplyr::mutate(race_result,popularity=as.character(str_extract_all(race_result$`popularity/odds`,&amp;quot;\\d+[^(\\d+.\\d)]&amp;quot;)))
          race_result$odds &amp;lt;- sapply(rm_round(race_result$odds, extract=TRUE), paste, collapse=&amp;quot;&amp;quot;)
          race_result &amp;lt;- race_result[-4]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;次に、今取得したtable以外の情報も取り込むことにします。具体的には、レース名や天候、馬場状態、日付、競馬場などです。これらの情報はレース結果ページの上部に掲載されています。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;          # レース情報
          race_date &amp;lt;- race1 %&amp;gt;% html_nodes(xpath = &amp;quot;//div[@id = &amp;#39;raceTitName&amp;#39;]/p[@id = &amp;#39;raceTitDay&amp;#39;]&amp;quot;) %&amp;gt;%
            html_text()
          race_name &amp;lt;- race1 %&amp;gt;% html_nodes(xpath = &amp;quot;//div[@id = &amp;#39;raceTitName&amp;#39;]/h1[@class = &amp;#39;fntB&amp;#39;]&amp;quot;) %&amp;gt;%
            html_text()
          race_distance &amp;lt;- race1 %&amp;gt;% html_nodes(xpath = &amp;quot;//p[@id = &amp;#39;raceTitMeta&amp;#39;]&amp;quot;) %&amp;gt;%
            html_text()
        
          race_result &amp;lt;- dplyr::mutate(race_result,race_date=as.character(str_extract_all(race_date,&amp;quot;\\d+年\\d+月\\d+日&amp;quot;)))
          race_result$race_date &amp;lt;- str_replace_all(race_result$race_date,&amp;quot;年&amp;quot;,&amp;quot;/&amp;quot;)
          race_result$race_date &amp;lt;- str_replace_all(race_result$race_date,&amp;quot;月&amp;quot;,&amp;quot;/&amp;quot;)
          race_result$race_date &amp;lt;- as.Date(race_result$race_date)
          race_course &amp;lt;- as.character(str_extract_all(race_date,pattern = &amp;quot;札幌|函館|福島|新潟|東京|中山|中京|京都|阪神|小倉&amp;quot;))
          race_result$race_course &amp;lt;- race_course
          race_result &amp;lt;- dplyr::mutate(race_result,race_name=as.character(str_replace_all(race_name,&amp;quot;\\s&amp;quot;,&amp;quot;&amp;quot;)))
          race_result &amp;lt;- dplyr::mutate(race_result,race_distance=as.character(str_extract_all(race_distance,&amp;quot;\\d+m&amp;quot;)))
          race_type=as.character(str_extract_all(race_distance,pattern = &amp;quot;芝|ダート&amp;quot;))
          race_result$type &amp;lt;- race_type
          race_turn &amp;lt;- as.character(str_extract_all(race_distance,pattern = &amp;quot;右|左&amp;quot;))
          race_result$race_turn &amp;lt;- race_turn
          
          if(length(race1 %&amp;gt;% html_nodes(xpath = &amp;quot;//img[@class = &amp;#39;spBg ryou&amp;#39;]&amp;quot;)) == 1){
            race_result$race_condition &amp;lt;- &amp;quot;良&amp;quot;
          } else if (length(race1 %&amp;gt;% 
                            html_nodes(xpath = &amp;quot;//img[@class = &amp;#39;spBg yayaomo&amp;#39;]&amp;quot;)) == 1){
            race_result$race_condition &amp;lt;- &amp;quot;稍重&amp;quot;
          } else if (length(race1 %&amp;gt;%
                            html_nodes(xpath = &amp;quot;//img[@class = &amp;#39;spBg omo&amp;#39;]&amp;quot;)) == 1){
            race_result$race_condition &amp;lt;- &amp;quot;重&amp;quot;
          } else if (length(race1 %&amp;gt;% 
                            html_nodes(xpath = &amp;quot;//img[@class = &amp;#39;spBg furyou&amp;#39;]&amp;quot;)) == 1){
            race_result$race_condition &amp;lt;- &amp;quot;不良&amp;quot;
          } else race_result$race_condition &amp;lt;- &amp;quot;NA&amp;quot;
          
          if (length(race1 %&amp;gt;% html_nodes(xpath = &amp;quot;//img[@class = &amp;#39;spBg hare&amp;#39;]&amp;quot;)) == 1){
            race_result$race_weather &amp;lt;- &amp;quot;晴れ&amp;quot;
          } else if (length(race1 %&amp;gt;% html_nodes(xpath = &amp;quot;//img[@class = &amp;#39;spBg ame&amp;#39;]&amp;quot;)) == 1){
            race_result$race_weather &amp;lt;- &amp;quot;曇り&amp;quot;
          } else if (length(race1 %&amp;gt;% html_nodes(xpath = &amp;quot;//img[@class = &amp;#39;spBg kumori&amp;#39;]&amp;quot;)) == 1){
            race_result$race_weather &amp;lt;- &amp;quot;雨&amp;quot;
          } else race_result$race_weather &amp;lt;- &amp;quot;その他&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;次は各馬の情報です。 実はさきほど取得したtableの馬名はリンクになっており、そのリンクをたどると&lt;a href=&#34;https://keiba.yahoo.co.jp/directory/horse/2015105508/&#34;&gt;各馬の情報&lt;/a&gt;が取得できます（毛色や生年月日など）。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;          horse_url &amp;lt;- race1 %&amp;gt;% html_nodes(&amp;quot;a&amp;quot;) %&amp;gt;% html_attr(&amp;quot;href&amp;quot;) 
          horse_url &amp;lt;- horse_url[str_detect(horse_url, pattern=&amp;quot;directory/horse&amp;quot;)==1] # 馬情報のリンクだけ抽出する
          
          for (l in 1:length(horse_url)){
            tryCatch(
              {
                horse1 &amp;lt;-  read_html(str_c(&amp;quot;https://keiba.yahoo.co.jp&amp;quot;,horse_url[l]))
                Sys.sleep(0.5)
                horse_name &amp;lt;- horse1 %&amp;gt;% html_nodes(xpath = &amp;quot;//div[@id = &amp;#39;dirTitName&amp;#39;]/h1[@class = &amp;#39;fntB&amp;#39;]&amp;quot;) %&amp;gt;% 
                  html_text()
                horse &amp;lt;- horse1 %&amp;gt;% html_nodes(xpath = &amp;quot;//div[@id = &amp;#39;dirTitName&amp;#39;]/ul&amp;quot;) %&amp;gt;% 
                  html_text()
                race_result$colour[race_result$horse_name==horse_name] &amp;lt;- as.character(str_extract_all(horse,&amp;quot;毛色：.+&amp;quot;)) 
                race_result$owner[race_result$horse_name==horse_name] &amp;lt;- as.character(str_extract_all(horse,&amp;quot;馬主：.+&amp;quot;))
                race_result$farm[race_result$horse_name==horse_name] &amp;lt;- as.character(str_extract_all(horse,&amp;quot;生産者：.+&amp;quot;))
                race_result$locality[race_result$horse_name==horse_name] &amp;lt;- as.character(str_extract_all(horse,&amp;quot;産地：.+&amp;quot;))
                race_result$horse_birthday[race_result$horse_name==horse_name] &amp;lt;- as.character(str_extract_all(horse,&amp;quot;\\d+年\\d+月\\d+日&amp;quot;))
                race_result$father[race_result$horse_name==horse_name] &amp;lt;- horse1 %&amp;gt;% html_nodes(xpath = &amp;quot;//td[@class = &amp;#39;bloodM&amp;#39;][@rowspan = &amp;#39;4&amp;#39;]&amp;quot;) %&amp;gt;% html_text()
                race_result$mother[race_result$horse_name==horse_name] &amp;lt;- horse1 %&amp;gt;% html_nodes(xpath = &amp;quot;//td[@class = &amp;#39;bloodF&amp;#39;][@rowspan = &amp;#39;4&amp;#39;]&amp;quot;) %&amp;gt;% html_text()
              }
              , error = function(e){
                race_result$colour[race_result$horse_name==horse_name] &amp;lt;- NA 
                race_result$owner[race_result$horse_name==horse_name] &amp;lt;- NA
                race_result$farm[race_result$horse_name==horse_name] &amp;lt;- NA
                race_result$locality[race_result$horse_name==horse_name] &amp;lt;- NA
                race_result$horse_birthday[race_result$horse_name==horse_name] &amp;lt;- NA
                race_result$father[race_result$horse_name==horse_name] &amp;lt;- NA
                race_result$mother[race_result$horse_name==horse_name] &amp;lt;- NA
                }
            )
          }
          
          race_result$colour &amp;lt;- str_replace_all(race_result$colour,&amp;quot;毛色：&amp;quot;,&amp;quot;&amp;quot;)
          race_result$owner &amp;lt;- str_replace_all(race_result$owner,&amp;quot;馬主：&amp;quot;,&amp;quot;&amp;quot;)
          race_result$farm &amp;lt;- str_replace_all(race_result$farm,&amp;quot;生産者：&amp;quot;,&amp;quot;&amp;quot;)
          race_result$locality &amp;lt;- str_replace_all(race_result$locality,&amp;quot;産地：&amp;quot;,&amp;quot;&amp;quot;)
          #race_result$horse_birthday &amp;lt;- str_replace_all(race_result$horse_birthday,&amp;quot;年&amp;quot;,&amp;quot;/&amp;quot;)
          #race_result$horse_birthday &amp;lt;- str_replace_all(race_result$horse_birthday,&amp;quot;月&amp;quot;,&amp;quot;/&amp;quot;)
          #race_result$horse_birthday &amp;lt;- as.Date(race_result$horse_birthday)
          
          race_result &amp;lt;- dplyr::arrange(race_result,horse_number) # 馬番順に並べる&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;次にそのレースまでに獲得した賞金額を落としに行きます。これはレース結果のページの&lt;a href=&#34;https://keiba.yahoo.co.jp/race/denma/1802010601/&#34;&gt;出馬表&lt;/a&gt;と書かれたリンクをたどるとアクセスできます。ここに賞金があるのでそれを取得します。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;          yosou_url &amp;lt;- race1 %&amp;gt;% html_nodes(&amp;quot;a&amp;quot;) %&amp;gt;% html_attr(&amp;quot;href&amp;quot;) 
          yosou_url &amp;lt;- yosou_url[str_detect(yosou_url, pattern=&amp;quot;denma&amp;quot;)==1]
          
          if (length(yosou_url)==1){
          yosou1 &amp;lt;-  read_html(str_c(&amp;quot;https://keiba.yahoo.co.jp&amp;quot;,yosou_url)) 
          Sys.sleep(2)
          yosou &amp;lt;- yosou1 %&amp;gt;% html_nodes(xpath = &amp;quot;//td[@class = &amp;#39;txC&amp;#39;]&amp;quot;) %&amp;gt;% as.character()
          prize &amp;lt;- yosou[grepl(&amp;quot;万&amp;quot;,yosou)==TRUE] %&amp;gt;% str_extract_all(&amp;quot;\\d+万&amp;quot;)
          prize &amp;lt;- t(do.call(&amp;quot;data.frame&amp;quot;,prize)) %&amp;gt;% as.character()
          race_result$prize &amp;lt;- prize
          race_result$prize &amp;lt;- str_replace_all(race_result$prize,&amp;quot;万&amp;quot;,&amp;quot;&amp;quot;) %&amp;gt;% as.numeric()
          } else race_result$prize &amp;lt;- NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;取得した各レース結果を格納するdatasetというデータフレームを作成し、データを格納していきます。1年ごとにそれをSQLite
へ保存していきます。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;          ## ファイル貯めるのかく
          if (k == 1 &amp;amp;&amp;amp; i == 1 &amp;amp;&amp;amp; j == 1){
            dataset &amp;lt;- race_result
          } else {
            dataset &amp;lt;- rbind(dataset,race_result)
          } # if文2の終わり
        }else
        {
          print(&amp;quot;保存できませんでした&amp;quot;) 
        }# if文1の終わり
      } # iループの終わり
    } # jループ終わり
  } # kループの終わり
  beep(3)
  write.csv(dataset,&amp;quot;race_result2.csv&amp;quot;, row.names = FALSE)
  
  if (year == 1994){
    dbWriteTable(con, &amp;quot;race_result&amp;quot;, dataset)
  } else {
    dbWriteTable(con, &amp;quot;temp&amp;quot;, dataset)
    dbSendQuery(con, &amp;quot;INSERT INTO race_result select * from temp&amp;quot;)
    dbSendQuery(con, &amp;quot;DROP TABLE temp&amp;quot;)
  } # ifの終わり
} # yearループの終わり
end.time &amp;lt;- Sys.time()
print(str_c(&amp;quot;処理時間は&amp;quot;,end.time-start.time,&amp;quot;です。&amp;quot;))
beep(5)

options(warn = 1)

dbDisconnect(con)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;以上です。取れたデータは以下のようになりました。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(race_result)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   order frame_number horse_number   trainer passing_rank last_3F   time
## 1    10            1            1   田中 剛        09-09    39.0 1.14.3
## 2    16            1            2 天間 昭一        11-11    40.3 1.15.7
## 3    15            2            3 田中 清隆        14-14    39.4 1.15.1
## 4     9            2            4 中舘 英二        08-08    39.1 1.14.3
## 5    12            3            5 根本 康広        11-11    39.0 1.14.4
## 6     4            3            6 杉浦 宏昭        04-04    38.4 1.13.2
##      margin         horse_name horse_age horse_sex horse_weight
## 1    アタマ     サトノジョニー         3        牡          512
## 2 3 1/2馬身       ツギノイッテ         3        牡          464
## 3     3馬身           ギュウホ         3        牡          444
## 4 2 1/2馬身 セイウンメラビリア         3        牝          466
## 5      クビ サバイバルトリック         3        牝          450
## 6    アタマ       ステイホット         3        牝          474
##   horse_weight_change brinker      jockey jockey_weight jockey_weight_change
## 1                 +30       N   松岡 正海            56                    0
## 2                  +8       N 西田 雄一郎            56                    0
## 3                  +8       N   杉原 誠人            56                    0
## 4                 +10       N   村田 一誠            54                    0
## 5                  -2       N 野中 悠太郎            51                    0
## 6                  -2       N   大野 拓弥            54                    0
##    odds popularity  race_date race_course       race_name race_distance   type
## 1  40.3         9  2019-01-05        中山 サラ系3歳未勝利         1200m ダート
## 2 340.9        16  2019-01-05        中山 サラ系3歳未勝利         1200m ダート
## 3 283.1        14  2019-01-05        中山 サラ系3歳未勝利         1200m ダート
## 4 299.7        15  2019-01-05        中山 サラ系3歳未勝利         1200m ダート
## 5  26.7         8  2019-01-05        中山 サラ系3歳未勝利         1200m ダート
## 6   2.4         1  2019-01-05        中山 サラ系3歳未勝利         1200m ダート
##   race_turn race_condition race_weather colour                           owner
## 1        右             良         晴れ   栗毛 株式会社 サトミホースカンパニー
## 2        右             良         晴れ 黒鹿毛                     西村 新一郎
## 3        右             良         晴れ   鹿毛           有限会社 ミルファーム
## 4        右             良         晴れ 青鹿毛                       西山 茂行
## 5        右             良         晴れ 黒鹿毛                       福田 光博
## 6        右             良         晴れ   栗毛                       小林 善一
##           farm   locality horse_birthday                 father
## 1   千代田牧場 新ひだか町  2016年1月29日         オルフェーヴル
## 2    織笠 時男     青森県  2016年4月17日 スクワートルスクワート
## 3    神垣 道弘 新ひだか町  2016年4月19日     ジャングルポケット
## 4  石郷岡 雅樹     新冠町  2016年4月21日     キンシャサノキセキ
## 5     原田牧場     日高町  2016年4月30日       リーチザクラウン
## 6 社台ファーム     千歳市  2016年3月13日     キャプテントゥーレ
##               mother prize
## 1 スパークルジュエル     0
## 2   エプソムアイリス     0
## 3     デライトシーン     0
## 4     ドリームシップ     0
## 5   フリーダムガール   180
## 6     ステイアライヴ   455&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
