<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python | 東京の資産運用会社で働く社会人が研究に没頭するブログ</title>
    <link>/tag/python/</link>
      <atom:link href="/tag/python/index.xml" rel="self" type="application/rss+xml" />
    <description>Python</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>ja</language><lastBuildDate>Tue, 03 Nov 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>Python</title>
      <link>/tag/python/</link>
    </image>
    
    <item>
      <title>Pythonのpandas_datareaderから色々なデータを取得してみる</title>
      <link>/post/post15/</link>
      <pubDate>Tue, 03 Nov 2020 00:00:00 +0000</pubDate>
      <guid>/post/post15/</guid>
      <description>
&lt;script src=&#34;index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#econdbからのデータ取得&#34;&gt;1. ECONDBからのデータ取得&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#econdbとは&#34;&gt;ECONDBとは？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#データ取得方法&#34;&gt;データ取得方法&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#world-bankからのデータ取得方法&#34;&gt;2. World Bankからのデータ取得方法&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#世界銀行から取得できるデータとは&#34;&gt;世界銀行から取得できるデータとは？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#データの検索方法&#34;&gt;データの検索方法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#データの取得方法&#34;&gt;データの取得方法&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#famafrench-data-libraryからのデータ取得方法&#34;&gt;3. Fama/French Data Libraryからのデータ取得方法&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#famafrench-data-libraryで取れるデータとは&#34;&gt;Fama/French Data Libraryで取れるデータとは&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#データ取得方法-1&#34;&gt;データ取得方法&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#ferdからのデータ取得方法&#34;&gt;4. FERDからのデータ取得方法&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#fredで取得できるデータとは&#34;&gt;FREDで取得できるデータとは&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#データ取得方法-2&#34;&gt;データ取得方法&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#oecdからのデータ取得方法&#34;&gt;5. OECDからのデータ取得方法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#eurostatからのデータ取得方法&#34;&gt;6. Eurostatからのデータ取得方法&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#eurostatから取得できるデータとは&#34;&gt;Eurostatから取得できるデータとは&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#データ取得方法-3&#34;&gt;データ取得方法&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#最後に&#34;&gt;最後に&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;おはこんばんにちは。最近会社のPCに&lt;code&gt;Anaconda&lt;/code&gt;を入れてもらいました。業務で使用することはないのですが、ワークショップで使用するので色々勉強しています。以前、Googleが提供している&lt;code&gt;Earth Engine&lt;/code&gt;から衛星画像を取得して解析した際に&lt;code&gt;Python&lt;/code&gt;を使用しましたが、今回は&lt;code&gt;Python&lt;/code&gt;から様々なデータが取得できる&lt;code&gt;pandas_datareader&lt;/code&gt;を使用したいと思います。&lt;code&gt;pandas_datareader&lt;/code&gt;では以下のようなデータソースからデータが取得できます。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Tiingo&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;IEX&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Alpha Vantage&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Enigma&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Quandl&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;St.Louis FED&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Kenneth French’s data library&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;World Bank&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;OECD&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Eurostat&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Thrift Saving Plan&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Nasdaq Trader symbol definitions&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Stooq&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;MOEX&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Naver Finance&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;なお、このブログでは&lt;code&gt;Rstuio&lt;/code&gt;と&lt;code&gt;blogdown&lt;/code&gt;パッケージ、&lt;code&gt;git&lt;/code&gt;を組み合わせて&lt;code&gt;github&lt;/code&gt;上に記事を投稿しています。ですが、&lt;code&gt;Rstudio&lt;/code&gt;と&lt;code&gt;reticulate&lt;/code&gt;パッケージのおかげで、&lt;code&gt;python&lt;/code&gt;を使用した記事も&lt;code&gt;rmd&lt;/code&gt;で作成し、&lt;code&gt;html&lt;/code&gt;として出力できています。ここでまず、&lt;code&gt;reticulate&lt;/code&gt;パッケージを用いて&lt;code&gt;conda&lt;/code&gt;仮想環境へ接続する方法を紹介しておきます。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(reticulate)
conda_path &amp;lt;- &amp;quot;C:\\Users\\hoge\\Anaconda3\\envs\\環境名&amp;quot;
use_condaenv(conda_path)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;これで接続できます。&lt;code&gt;conda_path&lt;/code&gt;には仮想環境へのパスを入力してください。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import sys
sys.version&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;#39;3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)]&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;econdbからのデータ取得&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;1. ECONDBからのデータ取得&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;pandas_datareader&lt;/code&gt;では、&lt;a href=&#34;https://www.econdb.com/&#34;&gt;ECOMDB&lt;/a&gt;からマクロ経済関連のデータを取得することができます。&lt;/p&gt;
&lt;div id=&#34;econdbとは&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;ECONDBとは？&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;econdb.PNG&#34; /&gt;&lt;/p&gt;
&lt;p&gt;ECONDBは各国の主要マクロ経済データをdashboard形式で提供してくれるWebサイトで、またAPIをサポートしており、PythonやExcelにシームレスにデータを連係してくれます。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;econdb2.PNG&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;データ取得方法&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;データ取得方法&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;pandas_datareader&lt;/code&gt;を用いた使用方法は以下の通りです。&lt;/p&gt;
&lt;div id=&#34;基本的な使用方法&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;基本的な使用方法&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;pandas_datareader&lt;/code&gt;からデータモジュールをインポートすることから始めます。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import pandas_datareader.data as web&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;EconDBからデータを取得するには、&lt;code&gt;DataReader&lt;/code&gt;メソッドを呼び出し、以下のように&lt;code&gt;data_source&lt;/code&gt;引数に&lt;code&gt;&#39;econdb&#39;&lt;/code&gt;と適当な&lt;code&gt;query&lt;/code&gt;を渡せばよいです。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df = web.DataReader(query, data_source=&amp;#39;econdb&amp;#39;, **kwargs)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;クエリパラメータの形式は、取得するデータの種類によって異なります。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;クエリ指定方法&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;クエリ指定方法&lt;/h4&gt;
&lt;p&gt;データはいくつかのデータセットに分割されます。データセットには、トピック、頻度、調査方法などの共通の特徴を抽出できるティッカーが付与されています。ユーザーは検索機能を使用してデータセットを探すことができます。UST_MSPDデータセットを例にしてみます。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;econdb3.PNG&#34; /&gt;&lt;/p&gt;
&lt;p&gt;ページに入ると、いくつかのフィルターがあり、特定のシリーズと特定のタイムフレームに選択を絞り込むことができます。適切なフィルタが設定された状態で、&lt;code&gt;Export&lt;/code&gt;ドロップダウンボタンをクリックすると、選択したデータをエクスポートするための多くのオプションとフォーマットが表示されます。その中でも、&lt;code&gt;Export to Python&lt;/code&gt;は、事前にフォーマットされたパラメータを持つコードの重要な部分を表示します。これをそのまま貼り付けてしまえばデータを取得できます。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;econdb4.PNG&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;query = &amp;quot;&amp;amp;&amp;quot;.join([
    &amp;quot;dataset=UST_MSPD&amp;quot;,
    &amp;quot;v=Category&amp;quot;,
    &amp;quot;h=TIME&amp;quot;,
    &amp;quot;from=2018-01-01&amp;quot;,
    &amp;quot;to=2019-12-31&amp;quot;
])
df = web.DataReader(query, &amp;#39;econdb&amp;#39;)
df.head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Category                         Bills  ... United States Savings Securities
## Holder      Intragovernmental Holdings  ...                           Totals
## TIME_PERIOD                             ...                                 
## 2015-12-01                      2928.0  ...                           171630
## 2016-01-01                      2642.0  ...                           171160
## 2016-02-01                      3584.0  ...                           170824
## 2016-03-01                      3582.0  ...                           170370
## 2016-04-01                      4176.0  ...                           169956
## 
## [5 rows x 51 columns]&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;実践的な取得コード&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;実践的な取得コード&lt;/h4&gt;
&lt;p&gt;こんなこともできます。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import pandas as pd
from matplotlib import pyplot as plt
import pandas_datareader.data as web
from datetime import datetime
import seaborn as sns

start = datetime(1980,1,1)
end = datetime(2019,12,31)

# parameters for data from econdb
country = [&amp;#39;US&amp;#39;,&amp;#39;UK&amp;#39;,&amp;#39;JP&amp;#39;,&amp;#39;EU&amp;#39;]
indicator = [&amp;#39;RGDP&amp;#39;,&amp;#39;CPI&amp;#39;,&amp;#39;URATE&amp;#39;,&amp;#39;CA&amp;#39;,&amp;#39;HOU&amp;#39;,&amp;#39;POP&amp;#39;,&amp;#39;RETA&amp;#39;,&amp;#39;IP&amp;#39;]

# Parse API from econdb
econ = pd.DataFrame()
for cnty in country:
    temp2 = pd.DataFrame()
    for idctr in indicator:
        temp = web.DataReader(&amp;#39;ticker=&amp;#39; + idctr + cnty,&amp;#39;econdb&amp;#39;,start,end)
        temp.columns = [idctr]
        temp2 = pd.concat([temp2,temp],join=&amp;#39;outer&amp;#39;,axis=1)
    temp2 = temp2.assign(kuni=cnty,kijyundate=temp2.index)
    econ = pd.concat([econ,temp2],join=&amp;#39;outer&amp;#39;)
    econ = econ.reset_index(drop=True)
econ.head()

# Plot CPI for example&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         RGDP   CPI  URATE       CA  HOU       POP  RETA     IP kuni kijyundate
## 0  6837641.0  78.0    6.3 -10666.0  NaN  226554.0   NaN  53.50   US 1980-01-01
## 1        NaN  79.0    6.3      NaN  NaN  226753.0   NaN  53.51   US 1980-02-01
## 2        NaN  80.1    6.3      NaN  NaN  226955.0   NaN  53.33   US 1980-03-01
## 3  6696753.0  80.9    6.9   9844.0  NaN  227156.0   NaN  52.23   US 1980-04-01
## 4        NaN  81.7    7.5      NaN  NaN  227387.0   NaN  50.96   US 1980-05-01&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;sns.set&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;lt;function set at 0x000000002EA68558&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;sns.relplot(data=econ,x=&amp;#39;kijyundate&amp;#39;,y=&amp;#39;CPI&amp;#39;,hue=&amp;#39;kuni&amp;#39;,kind=&amp;#39;line&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;lt;seaborn.axisgrid.FacetGrid object at 0x00000000307EFE48&amp;gt;
## 
## C:\Users\aashi\ANACON~1\envs\FINANC~1\lib\site-packages\pandas\plotting\_matplotlib\converter.py:103: FutureWarning: Using an implicitly registered datetime converter for a matplotlib plotting method. The converter was registered by pandas on import. Future versions of pandas will require you to explicitly register matplotlib converters.
## 
## To register the converters:
##  &amp;gt;&amp;gt;&amp;gt; from pandas.plotting import register_matplotlib_converters
##  &amp;gt;&amp;gt;&amp;gt; register_matplotlib_converters()
##   warnings.warn(msg, FutureWarning)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;plt.show()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;556&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;world-bankからのデータ取得方法&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;2. World Bankからのデータ取得方法&lt;/h2&gt;
&lt;div id=&#34;世界銀行から取得できるデータとは&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;世界銀行から取得できるデータとは？&lt;/h3&gt;
&lt;p&gt;世界銀行は前身が国際復興開発銀行(IBRD)、国際開発協会(IDA)であることからもわかるように開発系のデータが取得できます。最近ではCOVID-19関連のデータも取得することができます。 &lt;code&gt;pandas_datareader&lt;/code&gt;では、&lt;code&gt;wb&lt;/code&gt;関数を使用することで、&lt;a href=&#34;https://data.worldbank.org/&#34;&gt;World Bank’s World Development Indicators&lt;/a&gt;と呼ばれる世界銀行の数千ものパネルデータに簡単にアクセスできます。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;データの検索方法&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;データの検索方法&lt;/h3&gt;
&lt;p&gt;例えば、北米地域の国々の一人当たりの国内総生産をドルベースで比較したい場合は、&lt;code&gt;search&lt;/code&gt;関数を使用します。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;from pandas_datareader import wb
matches = wb.search(&amp;#39;gdp.*capita.*const&amp;#39;)
print(matches.loc[:,[&amp;#39;id&amp;#39;,&amp;#39;name&amp;#39;]])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                         id                                               name
## 680     6.0.GDPpc_constant  GDP per capita, PPP (constant 2011 internation...
## 9266        NY.GDP.PCAP.KD                 GDP per capita (constant 2010 US$)
## 9268        NY.GDP.PCAP.KN                      GDP per capita (constant LCU)
## 9270     NY.GDP.PCAP.PP.KD  GDP per capita, PPP (constant 2017 internation...
## 9271  NY.GDP.PCAP.PP.KD.87  GDP per capita, PPP (constant 1987 internation...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;NY.GDP.PCAP.KD&lt;/code&gt;がそれに当たることがわかります。2010年のUSドルベースで実質化されているようです。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;データの取得方法&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;データの取得方法&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;download&lt;/code&gt;関数でデータを取得します。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;dat = wb.download(indicator=&amp;#39;NY.GDP.PCAP.KD&amp;#39;, country=[&amp;#39;US&amp;#39;, &amp;#39;CA&amp;#39;, &amp;#39;MX&amp;#39;], start=2010, end=2018)
print(dat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                     NY.GDP.PCAP.KD
## country       year                
## Canada        2018    51476.200779
##               2017    51170.475834
##               2016    50193.750417
##               2015    50262.027666
##               2014    50306.944612
##               2013    49397.523320
##               2012    48785.936079
##               2011    48464.496279
##               2010    47448.013220
## Mexico        2018    10403.540397
##               2017    10301.357885
##               2016    10205.795753
##               2015    10037.201490
##               2014     9839.050191
##               2013     9693.722969
##               2012     9690.869065
##               2011     9477.887185
##               2010     9271.398233
## United States 2018    54659.198268
##               2017    53382.764823
##               2016    52555.518032
##               2015    52116.738813
##               2014    51028.824895
##               2013    50171.237133
##               2012    49603.253474
##               2011    48866.053277
##               2010    48467.515777&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;pandas&lt;/code&gt;の&lt;code&gt;dataframe&lt;/code&gt;形式でデータを取得できていることが分かります。年と国がindexになっていますね。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;famafrench-data-libraryからのデータ取得方法&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;3. Fama/French Data Libraryからのデータ取得方法&lt;/h2&gt;
&lt;div id=&#34;famafrench-data-libraryで取れるデータとは&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Fama/French Data Libraryで取れるデータとは&lt;/h3&gt;
&lt;p&gt;金融関連データになりますが、有名なFama/Frechの3 Factor modelのデータセットが&lt;a href=&#34;http://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html&#34;&gt;Fama/French Data Library&lt;/a&gt;から取得できます。&lt;code&gt;get_available_datasets&lt;/code&gt;関数は、利用可能なすべてのデータセットのリストを返します。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;データ取得方法-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;データ取得方法&lt;/h3&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;from pandas_datareader.famafrench import get_available_datasets
len(get_available_datasets())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 297&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;利用可能なデータセットは297です。 データセットにどんなものがあるか、20個ほどサンプリングしてみます。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import random
print(random.sample(get_available_datasets(),20))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [&amp;#39;6_Portfolios_2x3&amp;#39;, &amp;#39;6_Portfolios_ME_INV_2x3_daily&amp;#39;, &amp;#39;Portfolios_Formed_on_ME&amp;#39;, &amp;#39;F-F_ST_Reversal_Factor&amp;#39;, &amp;#39;Portfolios_Formed_on_VAR&amp;#39;, &amp;#39;Developed_ex_US_6_Portfolios_ME_INV_Daily&amp;#39;, &amp;#39;Developed_ex_US_3_Factors_Daily&amp;#39;, &amp;#39;Developed_25_Portfolios_ME_INV&amp;#39;, &amp;#39;48_Industry_Portfolios_daily&amp;#39;, &amp;#39;Europe_5_Factors&amp;#39;, &amp;#39;Asia_Pacific_ex_Japan_32_Portfolios_ME_BE-ME_INV(TA)_2x4x4&amp;#39;, &amp;#39;Developed_3_Factors&amp;#39;, &amp;#39;Europe_3_Factors&amp;#39;, &amp;#39;Europe_25_Portfolios_ME_INV_Daily&amp;#39;, &amp;#39;6_Portfolios_ME_INV_2x3_Wout_Div&amp;#39;, &amp;#39;6_Portfolios_ME_CFP_2x3_Wout_Div&amp;#39;, &amp;#39;North_America_25_Portfolios_ME_INV&amp;#39;, &amp;#39;Developed_ex_US_Mom_Factor&amp;#39;, &amp;#39;6_Portfolios_ME_OP_2x3_Wout_Div&amp;#39;, &amp;#39;17_Industry_Portfolios_Wout_Div&amp;#39;]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;日本株のポートフォリオも存在します。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;ds = web.DataReader(&amp;#39;5_Industry_Portfolios&amp;#39;, &amp;#39;famafrench&amp;#39;)
print(ds[&amp;#39;DESCR&amp;#39;])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 5 Industry Portfolios
## ---------------------
## 
## This file was created by CMPT_IND_RETS using the 202009 CRSP database. It contains value- and equal-weighted returns for 5 industry portfolios. The portfolios are constructed at the end of June. The annual returns are from January to December. Missing data are indicated by -99.99 or -999. Copyright 2020 Kenneth R. French
## 
##   0 : Average Value Weighted Returns -- Monthly (59 rows x 5 cols)
##   1 : Average Equal Weighted Returns -- Monthly (59 rows x 5 cols)
##   2 : Average Value Weighted Returns -- Annual (5 rows x 5 cols)
##   3 : Average Equal Weighted Returns -- Annual (5 rows x 5 cols)
##   4 : Number of Firms in Portfolios (59 rows x 5 cols)
##   5 : Average Firm Size (59 rows x 5 cols)
##   6 : Sum of BE / Sum of ME (6 rows x 5 cols)
##   7 : Value-Weighted Average of BE/ME (6 rows x 5 cols)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;5つ目がポートフォリオに含まれる銘柄数、1つ目がvalue weightedポートフォリオの月次リターンです。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;ds[4].head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          Cnsmr  Manuf  HiTec  Hlth   Other
## Date                                      
## 2015-11    544    653    736    586   1109
## 2015-12    542    649    730    583   1099
## 2016-01    539    638    725    581   1091
## 2016-02    537    635    718    576   1083
## 2016-03    536    630    715    576   1074&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;ds[0].head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          Cnsmr  Manuf  HiTec  Hlth   Other
## Date                                      
## 2015-11   0.29  -0.08   0.57   0.72   1.17
## 2015-12   0.13  -4.66  -2.59   0.38  -2.69
## 2016-01  -3.30  -3.46  -5.05  -9.40  -8.24
## 2016-02   0.51   1.39  -0.51  -1.06  -0.08
## 2016-03   5.81   8.10   7.91   2.92   7.06&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;ferdからのデータ取得方法&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;4. FERDからのデータ取得方法&lt;/h2&gt;
&lt;div id=&#34;fredで取得できるデータとは&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;FREDで取得できるデータとは&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://fred.stlouisfed.org/&#34;&gt;FRED&lt;/a&gt;では多種多様な経済統計データを取得することができます。サイトへ行くと、以下のように統計毎にページが存在します。この統計名の横についている&lt;code&gt;CPIAUCSL&lt;/code&gt;がTickerになっており、これを渡すことで、データを取得することができます。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;FRED.PNG&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;データ取得方法-2&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;データ取得方法&lt;/h3&gt;
&lt;p&gt;先ほど見たTickerを&lt;code&gt;DataReader&lt;/code&gt;関数に渡し、データソースを&lt;code&gt;fred&lt;/code&gt;とすることで、データを取得することができます。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import datetime
start = datetime.datetime(2010, 1, 1)
end = datetime.datetime(2013, 1, 27)

gdp = web.DataReader(&amp;#39;GDP&amp;#39;, &amp;#39;fred&amp;#39;, start, end)
inflation = web.DataReader([&amp;#39;CPIAUCSL&amp;#39;, &amp;#39;CPILFESL&amp;#39;], &amp;#39;fred&amp;#39;, start, end)

gdp.head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                   GDP
## DATE                 
## 2010-01-01  14721.350
## 2010-04-01  14926.098
## 2010-07-01  15079.917
## 2010-10-01  15240.843
## 2011-01-01  15285.828&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;inflation.head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             CPIAUCSL  CPILFESL
## DATE                          
## 2010-01-01   217.488   220.633
## 2010-02-01   217.281   220.731
## 2010-03-01   217.353   220.783
## 2010-04-01   217.403   220.822
## 2010-05-01   217.290   220.962&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;oecdからのデータ取得方法&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;5. OECDからのデータ取得方法&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://stats.oecd.org/&#34;&gt;OECD&lt;/a&gt;は以前以下の記事で紹介しましたが、&lt;code&gt;pandas_datareader&lt;/code&gt;でも取得することができます。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;ttps://ayatoashihara.github.io/myblog_multi/post/post22/&#34;&gt;OECD.orgからマクロパネルデータをAPIで取得する&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;ただ、&lt;code&gt;OECD dataset code&lt;/code&gt;を指定するだけ&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;なので、&lt;code&gt;pandasdmx&lt;/code&gt;よりは自由度が低いです。 あと、前回取得した&lt;code&gt;MEI_ARCHIVE&lt;/code&gt;とか指定するとデータが多すぎて、エラーが出ます。OECDデータを取得するときには、国や期間など細かい指定のできる&lt;code&gt;pandasdmx&lt;/code&gt;のほうが良いと個人的に思います。&lt;/p&gt;
&lt;p&gt;なお、使用方法はFREDと同様で、データソースに&lt;code&gt;oecd&lt;/code&gt;を指定します。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df = web.DataReader(&amp;#39;TUD&amp;#39;, &amp;#39;oecd&amp;#39;)
df.head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Country                Hungary                ...       Germany                     
## Source     Administrative data                ...   Survey data                     
## Series               Employees Union members  ... Union members Trade union  density
## Year                                          ...                                   
## 2016-01-01                 NaN           NaN  ...           NaN                  NaN
## 2017-01-01                 NaN           NaN  ...           NaN                  NaN
## 2018-01-01                 NaN           NaN  ...           NaN                  NaN
## 
## [3 rows x 216 columns]&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;eurostatからのデータ取得方法&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;6. Eurostatからのデータ取得方法&lt;/h2&gt;
&lt;div id=&#34;eurostatから取得できるデータとは&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Eurostatから取得できるデータとは&lt;/h3&gt;
&lt;p&gt;Eurostatは欧州連合の統計局で、主にEU地域のデータを取得することができます。データは以下のように多岐にわたっており、経済金融だけでなく農業や人口動態、輸送、環境等々多種多様なデータを取得することができます。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;eurostat.PNG&#34; /&gt;&lt;/p&gt;
&lt;p&gt;IDをどのように取得すればよいのかですが、以下の&lt;a href=&#34;https://ec.europa.eu/eurostat/data/database&#34;&gt;ページ&lt;/a&gt;にて、取得したいデータを順々に掘り進めていくと黄色で色を付けたようなIDコードが出てきます。これで取得データのIDを特定します。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;eurostat2.PNG&#34; /&gt;&lt;/p&gt;
&lt;p&gt;ただ、eurostatもOECDと同じくsdmxに対応しているため、&lt;code&gt;pandasdmx&lt;/code&gt;のほうが使いやすいかもしれません。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;データ取得方法-3&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;データ取得方法&lt;/h3&gt;
&lt;p&gt;一例として、 先ほど見た&lt;code&gt;Employment and activity by sex and age - annual data&lt;/code&gt;を取得してみます。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df = web.DataReader(&amp;#39;lfsi_emp_a&amp;#39;,&amp;#39;eurostat&amp;#39;).unstack()
df.head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## UNIT                            AGE                  SEX      INDIC_EM           GEO      FREQ    TIME_PERIOD
## Percentage of total population  From 15 to 24 years  Females  Active population  Austria  Annual  2016-01-01     54.6
##                                                                                                   2017-01-01     53.7
##                                                                                                   2018-01-01     53.8
##                                                                                                   2019-01-01     52.5
##                                                                                  Belgium  Annual  2016-01-01     26.2
## dtype: float64&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;最後に&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;最後に&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;pandas_datareader&lt;/code&gt;を使用して、様々なソースから多種多様なデータを取得しました。資産運用会社などで働いている方はbloombergやEIKONからデータを取得できるため、あまり魅力的に感じないかもしれませんが、個人で分析をしている方や定期的にデータを取得したい方は非常によいパッケージだと思います。自分自身、この新しいWebサイトにリニューアルしてから、週次や月次単位で経済分析を上げようかなと思っており、これらを使用して経済の定点観測をしたいなと思っているところです。皆さんも興味あるデータを&lt;code&gt;pandas_datareader&lt;/code&gt;で自動収集してみてください！&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;サイトで統計を選び、&lt;code&gt;export &amp;gt;- SDMX Query&lt;/code&gt;とするとその統計のコードが見れます。&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>OECD.orgからマクロパネルデータをAPIで取得する</title>
      <link>/post/post22/</link>
      <pubDate>Mon, 19 Oct 2020 00:00:00 +0000</pubDate>
      <guid>/post/post22/</guid>
      <description>
&lt;script src=&#34;index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#oecd.stat-web-api&#34;&gt;1.OECD.Stat Web API&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#pandasdmx&#34;&gt;2.pandasdmx&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#実装&#34;&gt;3.実装&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#別件ですが&#34;&gt;4.別件ですが。。。&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;おはこんばんにちは。マクロ経済データを集める方法はいくつかありますが、各国のデータを集めるとなると一苦労です。ですが、OECDからAPI経由でデータ取得すれば面倒な処理を自動化できます。今日はその方法をご紹介します。&lt;/p&gt;
&lt;div id=&#34;oecd.stat-web-api&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;1.OECD.Stat Web API&lt;/h2&gt;
&lt;p&gt;OECD.orgでは&lt;a href=&#34;https://stats.oecd.org/&#34;&gt;OECD.Stat&lt;/a&gt;というサービスを提供しており、OECD加盟国と特定の非加盟国の様々な経済データが提供されています。WEBサイトに行けば手動でcsvデータをダウンロードすることもできますが、定期的にデータを取得し、分析する必要があるならばデータ取得処理を自動化したい衝動に駆られます。OECDはWeb APIを提供しているので、&lt;code&gt;Python&lt;/code&gt;や&lt;code&gt;R&lt;/code&gt;さえ使えればこれを実現できます。&lt;/p&gt;
&lt;p&gt;&lt;OECD実施の具体的な内容&gt;&lt;/p&gt;
&lt;p&gt;以下は、現時点での特定のOECD REST SDMXインターフェースの実装詳細のリストです。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;匿名クエリのみがサポートされ、認証はありません。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;各レスポンスは1,000,000件のオブザベーションに制限されています。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;リクエストURLの最大長は1000文字です。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;クロスオリジンリクエストは、&lt;code&gt;CORS&lt;/code&gt; ヘッダでサポートされています (&lt;code&gt;CORS&lt;/code&gt;についての詳細は &lt;a href=&#34;http://www.html5rocks.com/en/tutorials/cors/&#34;&gt;こちら&lt;/a&gt;を参照)。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;エラーは結果には返されませんが、HTTP ステータスコードとメッセージは Web サービスガイドラインに従って設定されます。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;存在しないデータセットが要求された場合は、401 Unauthorizedが返されます。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;REST&lt;/code&gt; クエリの source (または Agency ID) パラメータは必須ですが、「ALL」キーワードはサポートされています。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;バージョニングはサポートされていません: 常に最新の実装バージョンが使用されます。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;データの並べ替えはサポートされていません。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;lastNObservations&lt;/code&gt;パラメータはサポートされていません。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;dimensionAtObservation=AllDimensions&lt;/code&gt; が使用されている場合でも、観測は時系列 (またはインポート固有) の順序に従います。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;現時点では、参照メタデータの検索はサポートされていません。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;pandasdmx&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;2.pandasdmx&lt;/h2&gt;
&lt;p&gt;Web APIは&lt;code&gt;sdmx-json&lt;/code&gt;という形式で提供されます。&lt;code&gt;Python&lt;/code&gt;ではこれを使用するための便利なパッケージが存在します。それが&lt;code&gt;**pandasdmx**&lt;/code&gt;です。データをダウンロードする方法は以下の通りです。&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;code&gt;pandasdmx&lt;/code&gt;を&lt;code&gt;import&lt;/code&gt;し、&lt;code&gt;Request&lt;/code&gt;メソッドに引数として’OECD’を渡し、&lt;code&gt;api.Request&lt;/code&gt;オブジェクトを作成する。&lt;/li&gt;
&lt;li&gt;作成した&lt;code&gt;api.Request&lt;/code&gt;オブジェクトのdataメソッドにクエリ条件を渡し、OECD.orgから&lt;code&gt;sdmx-json&lt;/code&gt;形式のデータをダウンロードする。&lt;/li&gt;
&lt;li&gt;ダウンロードしたデータを&lt;code&gt;to_pandas()&lt;/code&gt;メソッドで&lt;code&gt;pandas&lt;/code&gt;データフレームへ整形する。&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;実装&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;3.実装&lt;/h2&gt;
&lt;p&gt;では、実際にやってみましょう。取得するのは、「&lt;code&gt;**Revisions Analysis Dataset -- Infra-annual Economic Indicators**&lt;/code&gt;」というデータセットです。OECDのデータセットの一つである&lt;code&gt;Monthly Ecnomic Indicator&lt;/code&gt;(MEI)の修正を含む全てのデータにアクセスしているので、主要な経済変数(国内総生産とその支出項目、鉱工業生産と建設生産指数、国際収支、複合主要指標、消費者物価指数、小売取引高、失業率、就業者数、時間当たり賃金、貨マネーサプライ、貿易統計など)について、初出時の速報データから修正が加えられた確報データまで確認することができます。このデータセットでは、1999年2月から毎月の間隔で、過去に主要経済指標データベースで分析可能だったデータのスナップショットが提供されています。つまり、各時点で入手可能なデータに基づく、予測モデルの構築ができるデータセットになっています。最新のデータは有用ですが速報値なので不確実性がつきまといます。バックテストを行う際にはこの状況が再現できず実際の運用よりも良い環境で分析してしまうことが問題になったりします。いわゆる&lt;code&gt;Jagged edge&lt;/code&gt;問題です。このデータセットでは実運用の状況が再現できるため非常に有用であると思います。今回は以下のデータ項目を取得します。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;統計概要&lt;/th&gt;
&lt;th&gt;統計ID&lt;/th&gt;
&lt;th&gt;頻度&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;GDP&lt;/td&gt;
&lt;td&gt;101&lt;/td&gt;
&lt;td&gt;四半期&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;鉱工業生産指数&lt;/td&gt;
&lt;td&gt;201&lt;/td&gt;
&lt;td&gt;月次&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;小売業取引高&lt;/td&gt;
&lt;td&gt;202&lt;/td&gt;
&lt;td&gt;月次&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;マネーサプライ - 広義流動性&lt;/td&gt;
&lt;td&gt;601&lt;/td&gt;
&lt;td&gt;月次&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;貿易統計&lt;/td&gt;
&lt;td&gt;702+703&lt;/td&gt;
&lt;td&gt;月次&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;経常収支&lt;/td&gt;
&lt;td&gt;701&lt;/td&gt;
&lt;td&gt;四半期&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;就業者数&lt;/td&gt;
&lt;td&gt;502&lt;/td&gt;
&lt;td&gt;月次&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;失業率&lt;/td&gt;
&lt;td&gt;501&lt;/td&gt;
&lt;td&gt;月次&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;時間当たり賃金（製造業）&lt;/td&gt;
&lt;td&gt;503&lt;/td&gt;
&lt;td&gt;月次&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;単位あたり労働コスト&lt;/td&gt;
&lt;td&gt;504&lt;/td&gt;
&lt;td&gt;四半期&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;建築生産指数&lt;/td&gt;
&lt;td&gt;203&lt;/td&gt;
&lt;td&gt;月次&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;まず、関数を定義します。引数はデータベースID、その他ID(国IDや統計ID)、開始地点、終了地点です。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import pandasdmx as sdmx&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## C:\Users\aashi\Anaconda3\lib\site-packages\pandasdmx\remote.py:13: RuntimeWarning: optional dependency requests_cache is not installed; cache options to Session() have no effect
##   RuntimeWarning,&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;oecd = sdmx.Request(&amp;#39;OECD&amp;#39;)
def resp_OECD(dsname,dimensions,start,end):
    dim_args = [&amp;#39;+&amp;#39;.join(d) for d in dimensions]
    dim_str = &amp;#39;.&amp;#39;.join(dim_args)
    resp = oecd.data(resource_id=dsname, key=dim_str + &amp;quot;/all?startTime=&amp;quot; + start + &amp;quot;&amp;amp;endTime=&amp;quot; + end)
    df = resp.to_pandas().reset_index()
    return(df)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;データを取得する次元を指定します。以下では、①国、②統計項目、③入手時点、④頻度をタプルで指定しています。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;dimensions = ((&amp;#39;USA&amp;#39;,&amp;#39;JPN&amp;#39;,&amp;#39;GBR&amp;#39;,&amp;#39;FRA&amp;#39;,&amp;#39;DEU&amp;#39;,&amp;#39;ITA&amp;#39;,&amp;#39;CAN&amp;#39;,&amp;#39;NLD&amp;#39;,&amp;#39;BEL&amp;#39;,&amp;#39;SWE&amp;#39;,&amp;#39;CHE&amp;#39;),(&amp;#39;201&amp;#39;,&amp;#39;202&amp;#39;,&amp;#39;601&amp;#39;,&amp;#39;702&amp;#39;,&amp;#39;703&amp;#39;,&amp;#39;701&amp;#39;,&amp;#39;502&amp;#39;,&amp;#39;503&amp;#39;,&amp;#39;504&amp;#39;,&amp;#39;203&amp;#39;),(&amp;quot;202001&amp;quot;,&amp;quot;202002&amp;quot;,&amp;quot;202003&amp;quot;,&amp;quot;202004&amp;quot;,&amp;quot;202005&amp;quot;,&amp;quot;202006&amp;quot;,&amp;quot;202007&amp;quot;,&amp;quot;202008&amp;quot;),(&amp;quot;M&amp;quot;,&amp;quot;Q&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;関数を実行します。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;result = resp_OECD(&amp;#39;MEI_ARCHIVE&amp;#39;,dimensions,&amp;#39;2019-Q1&amp;#39;,&amp;#39;2020-Q2&amp;#39;)
result.count()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## LOCATION       8266
## VAR            8266
## EDI            8266
## FREQUENCY      8266
## TIME_PERIOD    8266
## value          8266
## dtype: int64&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;データの最初数件を見てみます。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;result.head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   LOCATION  VAR     EDI FREQUENCY TIME_PERIOD  value
## 0      BEL  201  202001         M     2019-01  112.5
## 1      BEL  201  202001         M     2019-02  111.8
## 2      BEL  201  202001         M     2019-03  109.9
## 3      BEL  201  202001         M     2019-04  113.5
## 4      BEL  201  202001         M     2019-05  112.1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;データがTidyな形(Long型)で入っているのがわかります。一番右側の&lt;code&gt;value&lt;/code&gt;が値として格納されており、その他インデックスは&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;LOCATION - 国&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;VAR - 統計項目&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;EDI - 入手時点(MEI_ARCHIVEの場合)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;FREQUENCY - 頻度(月次、四半期等)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;TIME_PERIOD - 統計の基準時点&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;となっています。よって、&lt;code&gt;EDI&lt;/code&gt;が異なる行で同じ&lt;code&gt;TIME_PERIOD&lt;/code&gt;が存在します。例えば、上ではベルギー(&lt;code&gt;BEL&lt;/code&gt;)の鉱工業生産指数(201)の2020/01時点で利用可能な2019-01~2019-05のデータが表示されています。可視化や回帰も行いやすいLongフォーマットでの提供なので非常にありがたいですね。鉱工業生産指数がアップデートされていく様子を可視化してみました。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

result = result[result[&amp;#39;FREQUENCY&amp;#39;]==&amp;#39;M&amp;#39;]
result[&amp;#39;TIME_PERIOD&amp;#39;] = pd.to_datetime(result[&amp;#39;TIME_PERIOD&amp;#39;],format=&amp;#39;%Y-%m&amp;#39;)
sns.relplot(data=result[lambda df: (df.VAR==&amp;#39;201&amp;#39;) &amp;amp; (pd.to_numeric(df.EDI) &amp;gt; 202004)],x=&amp;#39;TIME_PERIOD&amp;#39;,y=&amp;#39;value&amp;#39;,hue=&amp;#39;LOCATION&amp;#39;,kind=&amp;#39;line&amp;#39;,col=&amp;#39;EDI&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;lt;seaborn.axisgrid.FacetGrid object at 0x00000000316C0188&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;plt.show()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;2035&#34; /&gt;&lt;/p&gt;
&lt;p&gt;コロナの経済的な被害が大きくなるにつれて折れ線グラフが落ち込んでいく様子が見て取れる一方、微妙にですが過去値についても速報値→確報値へと修正が行われています。また、国によって統計データの公表にラグがあることも分かります。ベルギーは最も公表が遅いようです。時間があるときに、このデータを使った簡単な予測モデルの分析を追記したいと思います。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;別件ですが&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;4.別件ですが。。。&lt;/h2&gt;
&lt;p&gt;Python 3 エンジニア認定データ分析試験に合格しました。合格率70%だけあって、かなり簡単でしたが&lt;code&gt;Python&lt;/code&gt;を基礎から見返すいい機会になりました。今やっている業務ではデータ分析はおろか&lt;code&gt;Python&lt;/code&gt;や&lt;code&gt;R&lt;/code&gt;を使う機会すらないので、転職も含めた可能性を考えています。とりあえず、以下の資格を今年度中に取得する予定で、金融にこだわらずにスキルを活かせるポストを探していこうと思います。ダイエットと同じで宣言して自分を追い込まないと。。。&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;G検定&lt;/li&gt;
&lt;li&gt;Oracle Database Master Silver SQL&lt;/li&gt;
&lt;li&gt;Linuc レベル 1&lt;/li&gt;
&lt;li&gt;基本情報技術者&lt;/li&gt;
&lt;li&gt;AWS 認定ソリューションアーキテクト - アソシエイト&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;合格状況は都度ブログで報告していきたいと思います。&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>PytorchのPre-trainedモデルで馬体写真の背景を自動トリミングする</title>
      <link>/post/post20/</link>
      <pubDate>Wed, 12 Aug 2020 00:00:00 +0000</pubDate>
      <guid>/post/post20/</guid>
      <description>
&lt;script src=&#34;index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#pre-trainedモデルのダウンロード&#34;&gt;1. Pre-trainedモデルのダウンロード&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#背景削除処理の実行&#34;&gt;2. 背景削除処理の実行&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#cnnを用いた分析&#34;&gt;3. CNNを用いた分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#shap値を用いた結果解釈&#34;&gt;4. Shap値を用いた結果解釈&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#まとめ&#34;&gt;5.まとめ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;おはこんばんにちは。前回、競走馬の馬体写真からCNNを用いて順位を予想するモデルを構築しました。結果は芳しくなく、特に&lt;code&gt;shap&lt;/code&gt;値を用いた要因分析を行うと馬体よりも背景の厩舎に反応している様子が見えたりと分析の精緻化が必要となりました。今回はP&lt;code&gt;ytorch&lt;/code&gt;のPre-trainedモデルを用いて馬体写真から背景を切り出し、馬体のみとなった写真で再分析を行いたいと思います。&lt;/p&gt;
&lt;div id=&#34;pre-trainedモデルのダウンロード&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;1. Pre-trainedモデルのダウンロード&lt;/h2&gt;
&lt;p&gt;コードは&lt;a href=&#34;https://pytorch.org/hub/pytorch_vision_deeplabv3_resnet101/&#34;&gt;こちら&lt;/a&gt;のものを参考にしています。まず、パッケージをインストールします。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import numpy as np
import cv2
import matplotlib.pyplot as plt
import torch
import torchvision
from torchvision import transforms
import glob
from PIL import Image
import PIL
import os&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;学習済みモデルのインストールを行います。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;#学習済みモデルをインストール
device = torch.device(&amp;quot;cuda:0&amp;quot; if torch.cuda.is_available() else &amp;quot;cpu&amp;quot;)
model = torchvision.models.segmentation.deeplabv3_resnet101(pretrained=True)
model = model.to(device)
model.eval()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;どうやら全てのPre-trainedモデルは、同じ方法で正規化された形状&lt;span class=&#34;math inline&#34;&gt;\(（N, 3, H, W）\)&lt;/span&gt;の3チャンネルRGB画像のミニバッチを想定しているようです。ここで&lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt;は画像の数、&lt;span class=&#34;math inline&#34;&gt;\(H\)&lt;/span&gt;と&lt;span class=&#34;math inline&#34;&gt;\(W\)&lt;/span&gt;は少なくとも224ピクセルであることが想定されています。画像は、[0, 1]の範囲にスケーリングされ、その後、平均値＝[0.485, 0.456, 0.406]と標準値＝[0.229, 0.224, 0.225]を使用して正規化される必要があります。ということで、前処理を行う関数を定義します。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;#前処理
preprocess = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;背景削除処理の実行&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;2. 背景削除処理の実行&lt;/h2&gt;
&lt;p&gt;では、前回記事の&lt;code&gt;selenium&lt;/code&gt;を用いたコードで収集した画像を読み込み、1枚1枚背景削除処理を行っていきます。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;#フォルダを指定
folders = os.listdir(r&amp;quot;C:\Users\aashi\umanalytics\photo\image&amp;quot;)

#それぞれのフォルダから画像を読み込み、Image関数を使用してRGB値ベクトル(numpy array)へ変換
for i, folder in enumerate(folders):
  files = glob.glob(&amp;quot;C:/Users/aashi/umanalytics/photo/image/&amp;quot; + folder + &amp;quot;/*.jpg&amp;quot;)
  index = i
  for k, file in enumerate(files):
    img_array = np.fromfile(file, dtype=np.uint8)
    img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
    h,w,_ = img.shape
    input_tensor = preprocess(img)
    input_batch = input_tensor.unsqueeze(0).to(device)

    with torch.no_grad():
      output = model(input_batch)[&amp;#39;out&amp;#39;][0]
    output_predictions = output.argmax(0)
    mask_array = output_predictions.byte().cpu().numpy()
    Image.fromarray(mask_array*255).save(r&amp;#39;C:\Users\aashi\umanalytics\photo\image\mask.jpg&amp;#39;)
    mask = cv2.imread(r&amp;#39;C:\Users\aashi\umanalytics\photo\image\mask.jpg&amp;#39;)
    bg = np.full_like(img,255)
    img = cv2.multiply(img.astype(float), mask.astype(float)/255)
    bg = cv2.multiply(bg.astype(float), 1.0 - mask.astype(float)/255)
    outImage = cv2.add(img, bg)
    Image.fromarray(outImage.astype(np.uint8)).convert(&amp;#39;L&amp;#39;).save(file)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;行っている処理はPre-trainedモデルで以下のような&lt;code&gt;mask&lt;/code&gt;画像を出力し、実際の画像の&lt;code&gt;numpy&lt;/code&gt;配列と&lt;code&gt;mask&lt;/code&gt;画像を統合して、背景削除画像を生成しています。出力例は以下のような感じです。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;plt.gray()
plt.figure(figsize=(20,20))
plt.subplot(1,3,1)
plt.imshow(img)
plt.subplot(1,3,2)
plt.imshow(mask)
plt.subplot(1,3,3)
plt.imshow(outImage)
plt.show()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;1920&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;plt.close()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;フォルダはこんな感じです。うまく処理できているものもあれば調教師の方が映ってしまっているのもありますね。物体を識別して、馬だけを&lt;code&gt;mask&lt;/code&gt;する方法もあるとは思いますがこのモデルでは物体のラベリングまではできないのでこのまま進みます。&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;maskhorse.PNG&#34; alt=&#34;&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;フォルダ&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;cnnを用いた分析&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;3. CNNを用いた分析&lt;/h2&gt;
&lt;p&gt;ここからは前回記事と同じ内容です。結果のみ掲載します。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## Test accuracy: 0.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;lt;sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay object at 0x000000004AC69EC8&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;散々な結果になりました。
まったく識別できていません。馬体写真には順位を予測するような特徴量はないんでしょうか。それともG1の出走馬ではバラツキがなく、識別不可能なのでしょうか。いずれいにせよ、ちょっと厳しそうです。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;shap値を用いた結果解釈&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;4. Shap値を用いた結果解釈&lt;/h2&gt;
&lt;p&gt;前回同様、どのように失敗したのか&lt;code&gt;shap&lt;/code&gt;値を使って検証してみましょう。この画像を例として使います。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;plt.imshow(X_test[4])
plt.show()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;plt.close()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import shap
background = X_resampled[np.random.choice(X_resampled.shape[0],100,replace=False)]

e = shap.GradientExplainer(model,background)

shap_values = e.shap_values(X_test[[4]])
shap.image_plot(shap_values[1],X_test[[4]])&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;前足から顔にかけてを評価しているようです。意外に臀部を評価している様子はありません。
各層において画像のどの側面を捉えているかを可視化してみたいと思います。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;from keras import models

layer_outputs = [layer.output for layer in model.layers[:8]]
layer_names = []
for layer in model.layers[:8]:
    layer_names.append(layer.name)
images_per_row = 16

activation_model = models.Model(inputs=model.input, outputs=layer_outputs)
activations = activation_model.predict(X_train[[0]])

for layer_name, layer_activation in zip(layer_names, activations):
    n_features = layer_activation.shape[-1]

    size = layer_activation.shape[1]

    n_cols = n_features // images_per_row
    display_grid = np.zeros((size * n_cols, images_per_row * size))

    for col in range(n_cols):
        for row in range(images_per_row):
            channel_image = layer_activation[0,
                                             :, :,
                                             col * images_per_row + row]
            channel_image -= channel_image.mean()
            channel_image /= channel_image.std()
            channel_image *= 64
            channel_image += 128
            channel_image = np.clip(channel_image, 0, 255).astype(&amp;#39;uint8&amp;#39;)
            display_grid[col * size : (col + 1) * size,
                         row * size : (row + 1) * size] = channel_image

    scale = 1. / size
    plt.figure(figsize=(scale * display_grid.shape[1],
                        scale * display_grid.shape[0]))
    plt.title(layer_name)
    plt.grid(False)
    plt.imshow(display_grid, cmap=&amp;#39;viridis&amp;#39;)
    plt.show()
    plt.close()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;1536&#34; /&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-13-2.png&#34; width=&#34;1536&#34; /&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-13-3.png&#34; width=&#34;1536&#34; /&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-13-4.png&#34; width=&#34;1536&#34; /&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-13-5.png&#34; width=&#34;1536&#34; /&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-13-6.png&#34; width=&#34;1536&#34; /&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-13-7.png&#34; width=&#34;1536&#34; /&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-13-8.png&#34; width=&#34;1536&#34; /&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-13-9.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;こっちはやっぱり分からないですね。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;まとめ&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;5.まとめ&lt;/h2&gt;
&lt;p&gt;厩舎背景を削除し、再実行してみましたが結果変わらずでした。PyTorchを使ったり、背景削除を行ういい経験にはなりましたが結果は伴わずということで馬体写真はいったんここでストップです。&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>CNNを使って馬体写真から順位予想してみた</title>
      <link>/post/post18/</link>
      <pubDate>Sun, 05 Jul 2020 00:00:00 +0000</pubDate>
      <guid>/post/post18/</guid>
      <description>
&lt;script src=&#34;index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#データ収集のためのクローリング&#34;&gt;1. データ収集のためのクローリング&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#データをどこから取得するか&#34;&gt;データをどこから取得するか&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#seleniumでクローリングを実行する&#34;&gt;seleniumでクローリングを実行する&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#kerasを用いてcnnを学習させる&#34;&gt;2. &lt;code&gt;Keras&lt;/code&gt;を用いてCNNを学習させる&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#kerasとは&#34;&gt;Kerasとは？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#cnnとは&#34;&gt;CNNとは？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#コーディング&#34;&gt;コーディング&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#不均衡データ調整のためのアンダーサンプリング&#34;&gt;不均衡データ調整のためのアンダーサンプリング&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#shap値を用いた結果解釈&#34;&gt;3. Shap値を用いた結果解釈&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#最後に&#34;&gt;4. 最後に&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;おはこんばんにちは。今回は競馬予想についての記事を書きたいと思います。前回、&lt;code&gt;LightGBM&lt;/code&gt;を用いてyahoo競馬から取得したレース結果データ(テーブルデータ)を用いて、競馬順位予想モデルを作成しました。前回は構造データを用いましたが、このご時世ですからこんな分析は誰にでもできるわけです。時代は非構造データ、というわけで今回は馬体画像から特徴量を抽出し、順位予想を行う畳み込みニューラルネットワーク(&lt;code&gt;Convolutional Neural Network&lt;/code&gt;, CNN)を作成してみました。画像解析は&lt;code&gt;Earth Engine&lt;/code&gt;を用いた衛星画像の解析に続いて2回目、深層学習はこのブログでは初めてと言うことになります。なお、Pythonを使用しています。&lt;/p&gt;
&lt;div id=&#34;データ収集のためのクローリング&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;1. データ収集のためのクローリング&lt;/h2&gt;
&lt;p&gt;まず、馬体画像をネットから収集することから始めます。1番良いのはレース当日のパドックの写真を使用することでしょう。ただ、パドックの写真をまとまった形で掲載してくれているサイトは調べた限りは存在しませんでした。もしかしたら、Youtubeに競馬ファンの方がパドック動画を上げていらっしゃるかも知れませんので、それを画像に切り抜いて使う or 動画としてCNN→RNNの&lt;code&gt;Encoder-Decoder&lt;/code&gt;モデルに適用すると面白いかもしれません。しかし、そこまでの能力は今の自分にはありません。&lt;/p&gt;
&lt;div id=&#34;データをどこから取得するか&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;データをどこから取得するか&lt;/h3&gt;
&lt;p&gt;そこで、今回は&lt;a href=&#34;https://www.daily.co.jp/horse/horsecheck/photo/&#34;&gt;デイリーのWebサイト&lt;/a&gt;からデータを取得しています。ここには直近1年間?のG1レースに出馬する競走馬のレース前の馬体写真が掲載されています。実際のレース場へ行けない馬券師さんたちはこの写真を見て馬の状態を分析していると思われます。&lt;br /&gt;
なお、このサイトには出馬全頭の馬体写真が掲載されているわけではありません。また、G1の限られたレースのみですので、そもそも全ての馬が仕上がっている可能性もあり、差がつかないことも十分予想されます。ただ、手っ取り早くやってみることを優先し、今回はこのデータを使用することにしたいと思います。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;seleniumでクローリングを実行する&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;seleniumでクローリングを実行する&lt;/h3&gt;
&lt;p&gt;クローリングにはseleniumを使用します。今回はCNNがメインなのでWebクローリングについては説明しません。使用したコードは以下です。&lt;br /&gt;
【注意】以下のコードを使用される場合は自己責任でお願いします。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.select import Select
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.alert import Alert
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException
from selenium.webdriver.common.action_chains import ActionChains
from time import sleep
from urllib import request
import random

# seleniumのオプション設定（おまじない）
options = Options()
options.add_argument(&amp;#39;--disable-gpu&amp;#39;);
options.add_argument(&amp;#39;--disable-extensions&amp;#39;);
options.add_argument(&amp;#39;--proxy-server=&amp;quot;direct://&amp;quot;&amp;#39;);
options.add_argument(&amp;#39;--proxy-bypass-list=*&amp;#39;);
options.add_argument(&amp;#39;--start-maximized&amp;#39;);

# driver指定
DRIVER_PATH = r&amp;#39;C:/Users/aashi/Desktop/chromedriver_win32/chromedriver.exe&amp;#39;
driver = webdriver.Chrome(executable_path=DRIVER_PATH, chrome_options=options)

# urlを渡し、サイトへアクセス
url = &amp;#39;https://www.daily.co.jp/horse/horsecheck/photo/&amp;#39;
driver.get(url)
driver.implicitly_wait(15) # オブジェクトのロード待ちの最大時間でこれを越えるとエラー
sleep(5) # webページの遷移を行うので1秒sleep

# 各レース毎に画像データ保存
selector0 = &amp;quot;body &amp;gt; div &amp;gt; main &amp;gt; div &amp;gt; div.primaryContents &amp;gt; article &amp;gt; div &amp;gt; section &amp;gt; a&amp;quot;
elements = driver.find_elements_by_css_selector(selector0)
for i in range(0,len(elements)):
  elements = driver.find_elements_by_css_selector(selector0)
  element = elements[i]
  element.click()
  sleep(5) # webページの遷移を行うので5秒sleep

  target = driver.find_element_by_link_text(&amp;#39;Ｇ１馬体診断写真集のTOP&amp;#39;)
  actions = ActionChains(driver)
  actions.move_to_element(target)
  actions.perform()
  sleep(5) # webページの遷移を行うので5秒sleep
  selector = &amp;quot;body &amp;gt; div.wrapper.horse.is-fixedHeader.is-fixedAnimation &amp;gt; main &amp;gt; div &amp;gt; div.primaryContents &amp;gt; article &amp;gt; article &amp;gt; div.photoDetail-wrapper &amp;gt; section &amp;gt; div &amp;gt; figure&amp;quot;
  figures = driver.find_elements_by_css_selector(selector)
  download_dir = r&amp;#39;C:\Users\aashi\umanalytics\photo\image&amp;#39;
  selector = &amp;quot;body &amp;gt; div &amp;gt; main &amp;gt; div &amp;gt; div.primaryContents &amp;gt; article &amp;gt; article &amp;gt; div.photoDetail-wrapper &amp;gt; section &amp;gt; h1&amp;quot;
  race_name = driver.find_element_by_css_selector(selector).text
  for figure in figures:
    img_name = figure.find_element_by_tag_name(&amp;#39;figcaption&amp;#39;).text
    horse_src = figure.find_element_by_tag_name(&amp;#39;img&amp;#39;).get_attribute(&amp;quot;src&amp;quot;)    
    save_name = download_dir + &amp;#39;/&amp;#39; + race_name + &amp;#39;_&amp;#39; + img_name + &amp;#39;.jpg&amp;#39;
    request.urlretrieve(horse_src,save_name)
  driver.back()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;保存した画像を実際のレース結果と突合し、手作業で上位3位以内グループとそれ以外のグループに分けました。以下のような感じで画像が保存されています。&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;horse_photo.PNG&#34; alt=&#34;&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;保存された馬体画像&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;これで元データの収集が完了しました。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;kerasを用いてcnnを学習させる&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;2. &lt;code&gt;Keras&lt;/code&gt;を用いてCNNを学習させる&lt;/h2&gt;
&lt;div id=&#34;kerasとは&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Kerasとは？&lt;/h3&gt;
&lt;p&gt;さて、次に&lt;code&gt;Keras&lt;/code&gt;を使ってCNNを学習させましょう。まず、&lt;code&gt;Keras&lt;/code&gt;とは&lt;code&gt;Tensorflow&lt;/code&gt;や&lt;code&gt;Theano&lt;/code&gt;上で動く&lt;code&gt;Neural Network&lt;/code&gt;ライブラリの1つです。&lt;code&gt;Keras&lt;/code&gt;は比較的短いコードでモデルを組むことができ、また学習アルゴリズムが多いことが特徴のようです。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;cnnとは&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;CNNとは？&lt;/h3&gt;
&lt;p&gt;CNNは画像解析を行う際によく使用される&lt;code&gt;(Deep) Neural Network&lt;/code&gt;の1種で、その名の通り&lt;code&gt;Convolution&lt;/code&gt;(畳み込み)を追加した物となっています。畳み込みとは以下のような処理のことを言います。&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://cdn-ak.f.st-hatena.com/images/fotolife/t/tdualdir/20180501/20180501211957.png&#34; alt=&#34;&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;畳み込み層の処理&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;ここのインプットとは画像データのことです。画像解析では画像を数値として認識し、解析を行います。コンピュータ上の画像は&lt;code&gt;RGB&lt;/code&gt;値という、赤(Red)、緑(Green)、青(Blue)の3色の0~255までの数値の強弱で表現されています。赤255、緑0、青0といった形で3層のベクトルになっており、この場合完全な赤が表現されます。上図の場合、a,b,cなどが各ピクセルの&lt;code&gt;RGB&lt;/code&gt;値のいずれかを表していると考えることができます。畳み込みはこの&lt;code&gt;RGB&lt;/code&gt;値をカーネルと呼ばれる行列との内積をとることで画像の特徴量を計算します。畳み込み層の意味は以下の動画がわかりやすいです。&lt;/p&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/vU-JfZNBdYU&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;p&gt;カーネルを上手くその画像の特徴的な部分を取得できるように学習することで、画像の識別が可能になります。畳み込み層はCNNの最重要部分だと思います。&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://th.bing.com/th/id/OIP.F2Ik_XFzmu5jZF-byiAKQQHaCg?w=342&amp;amp;h=118&amp;amp;c=7&amp;amp;o=5&amp;amp;dpr=1.25&amp;amp;pid=1.7&#34; alt=&#34;&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;CNNの全体像&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;上図のようにCNNは畳み込み意外にももちろん入力層や出力層など通常の&lt;code&gt;Neural Network&lt;/code&gt;と同じ層も持っています。なお、&lt;code&gt;MaxPooling&lt;/code&gt;層について知りたい人は以下の動画を参照されてください。&lt;/p&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/MLixg9K6oeU&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;p&gt;深層学習の学習方法については最急下降法(勾配法)がオーソドックスなものとして知られていますが、&lt;code&gt;Adam&lt;/code&gt;など色々な拡張アルゴリズムが提案されています。基本的には、&lt;code&gt;Adam&lt;/code&gt;は&lt;code&gt;momentum&lt;/code&gt;を使用することが多いでしょうか。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;コーディング&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;コーディング&lt;/h3&gt;
&lt;p&gt;では、実際にコーディングしていきます。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;from keras.utils import np_utils
from keras.models import Sequential
from keras.layers.convolutional import MaxPooling2D
from keras.layers import Activation, Conv2D, Flatten, Dense,Dropout
from sklearn.model_selection import train_test_split
from keras.optimizers import SGD, Adadelta, Adagrad, Adam, Adamax, RMSprop, Nadam
from PIL import Image
import numpy as np
import glob
import matplotlib.pyplot as plt
import time
import os&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;まず最初に収集してきた画像データを数値データに変換し学習データを作成します。
ディレクトリ構造は以下のようになっており、上位画像とその他画像が別ディレクトリに保存されています。各ディレクトリから画像を読み込む際に、上位画像には1、その他には0というカテゴリ変数を与えます。&lt;/p&gt;
&lt;p&gt;馬体写真&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;上位&lt;/li&gt;
&lt;li&gt;その他&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;#フォルダを指定
folders = os.listdir(r&amp;quot;C:\Users\aashi\umanalytics\photo\image&amp;quot;)
#画総数を指定(今回は50×50×3)。
image_size = 300
dense_size = len(folders)

X = []
Y = []

#それぞれのフォルダから画像を読み込み、Image関数を使用してRGB値ベクトル(numpy array)へ変換
for i, folder in enumerate(folders):
  files = glob.glob(&amp;quot;C:/Users/aashi/umanalytics/photo/image/&amp;quot; + folder + &amp;quot;/*.jpg&amp;quot;)
  index = i
  for k, file in enumerate(files):
    image = Image.open(file)
    image = image.convert(&amp;quot;L&amp;quot;).convert(&amp;quot;RGB&amp;quot;)
    image = image.resize((image_size, image_size)) #画素数を落としている
 
    data = np.asarray(image)
    X.append(data)
    Y.append(index)

X = np.array(X)
Y = np.array(Y)
X = X.astype(&amp;#39;float32&amp;#39;)
X = X / 255.0 # 0~1へ変換
X.shape
Y = np_utils.to_categorical(Y, dense_size)

#訓練データとテストデータへ変換
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;訓練データとテストデータの分割ができました。今考えているのは「上位」と「その他」の2値分類となっていますが、「上位」を3位以内と定義したので不均衡なデータとなっています(その他データが上位データの5倍くらい)。こういった場合、そのままのデータで学習をするとサンプルサイズが多い方のラベル(この場合「その他」)を予測しやすくなり、バイアスのあるモデルとなります。よって、学習データは2クラスそれぞれが同じサンプルサイズとなるよう調整してやる必要があります。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;index_zero = np.random.choice(np.array(np.where(y_train[:,1]==0))[0,],np.count_nonzero(y_train[:,1]==1),replace=False)
index_one = np.array(np.where(y_train[:,1]==1))[0]
y_resampled = y_train[np.hstack((index_one,index_zero))]
X_resampled = X_train[np.hstack((index_one,index_zero))]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;学習データにはこの&lt;code&gt;y_resampled&lt;/code&gt;と&lt;code&gt;X_resampled&lt;/code&gt;を使用します。次に、CNNを構築していきます。&lt;code&gt;Keras&lt;/code&gt;では、&lt;code&gt;sequential model&lt;/code&gt;を指定し、&lt;code&gt;add&lt;/code&gt;メソッドで層を追加して行くことでモデルを定義します。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;model = Sequential()
model.add(Conv2D(32, (3, 3), padding=&amp;#39;same&amp;#39;,input_shape=X_train.shape[1:]))
model.add(Activation(&amp;#39;relu&amp;#39;))
model.add(Conv2D(32, (3, 3)))
model.add(Activation(&amp;#39;relu&amp;#39;))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Conv2D(64, (3, 3), padding=&amp;#39;same&amp;#39;))
model.add(Activation(&amp;#39;relu&amp;#39;))
model.add(Conv2D(64, (3, 3)))
model.add(Activation(&amp;#39;relu&amp;#39;))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(512))
model.add(Activation(&amp;#39;relu&amp;#39;))
model.add(Dropout(0.5))
model.add(Dense(dense_size))
model.add(Activation(&amp;#39;softmax&amp;#39;))

model.summary()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Model: &amp;quot;sequential&amp;quot;
## _________________________________________________________________
## Layer (type)                 Output Shape              Param #   
## =================================================================
## conv2d (Conv2D)              (None, 300, 300, 32)      896       
## _________________________________________________________________
## activation (Activation)      (None, 300, 300, 32)      0         
## _________________________________________________________________
## conv2d_1 (Conv2D)            (None, 298, 298, 32)      9248      
## _________________________________________________________________
## activation_1 (Activation)    (None, 298, 298, 32)      0         
## _________________________________________________________________
## max_pooling2d (MaxPooling2D) (None, 149, 149, 32)      0         
## _________________________________________________________________
## dropout (Dropout)            (None, 149, 149, 32)      0         
## _________________________________________________________________
## conv2d_2 (Conv2D)            (None, 149, 149, 64)      18496     
## _________________________________________________________________
## activation_2 (Activation)    (None, 149, 149, 64)      0         
## _________________________________________________________________
## conv2d_3 (Conv2D)            (None, 147, 147, 64)      36928     
## _________________________________________________________________
## activation_3 (Activation)    (None, 147, 147, 64)      0         
## _________________________________________________________________
## max_pooling2d_1 (MaxPooling2 (None, 73, 73, 64)        0         
## _________________________________________________________________
## dropout_1 (Dropout)          (None, 73, 73, 64)        0         
## _________________________________________________________________
## flatten (Flatten)            (None, 341056)            0         
## _________________________________________________________________
## dense (Dense)                (None, 512)               174621184 
## _________________________________________________________________
## activation_4 (Activation)    (None, 512)               0         
## _________________________________________________________________
## dropout_2 (Dropout)          (None, 512)               0         
## _________________________________________________________________
## dense_1 (Dense)              (None, 2)                 1026      
## _________________________________________________________________
## activation_5 (Activation)    (None, 2)                 0         
## =================================================================
## Total params: 174,687,778
## Trainable params: 174,687,778
## Non-trainable params: 0
## _________________________________________________________________&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;では、学習パートに入ります。アルゴリズムには&lt;code&gt;Adadelta&lt;/code&gt;を使用します。よくわかってないんですけどね。。。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;optimizers =&amp;quot;Adadelta&amp;quot;
results = {}
epochs = 50
model.compile(loss=&amp;#39;categorical_crossentropy&amp;#39;, optimizer=optimizers, metrics=[&amp;#39;accuracy&amp;#39;])
results = model.fit(X_resampled, y_resampled, validation_split=0.2, epochs=epochs)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;不均衡データ調整のためのアンダーサンプリング&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;不均衡データ調整のためのアンダーサンプリング&lt;/h3&gt;
&lt;p&gt;ここから、Testデータで2値分類を行うのですが、学習データをアンダーサンプリングしているので、予測確率を計算する際にアンダーサンプリングを行ったサンプル選択バイアスが生じてしまいます。論文は&lt;a href=&#34;https://www3.nd.edu/~dial/publications/dalpozzolo2015calibrating.pdf&#34;&gt;こちら&lt;/a&gt;。
よって、補正が必要になるのですがこの部分の定式化をここでしておきたいと思います。現在行っている2値分類問題を説明千数&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;から2値を取る目的変数&lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;を予測する問題と表現することにします。データセット&lt;span class=&#34;math inline&#34;&gt;\((X,Y)\)&lt;/span&gt;は正例が負例よりもかなり少なく、負例のサンプルサイズを正例に合わせたデータセットを&lt;span class=&#34;math inline&#34;&gt;\((X_s,Y_s)\)&lt;/span&gt;とします。ここで、&lt;span class=&#34;math inline&#34;&gt;\((X,Y)\)&lt;/span&gt;のサンプル組が&lt;span class=&#34;math inline&#34;&gt;\((X_s,Y_s)\)&lt;/span&gt;にも含まれる場合に1を取り、含まれない場合に0をとるカテゴリ変数&lt;span class=&#34;math inline&#34;&gt;\(s\)&lt;/span&gt;を定義します。
データセット&lt;span class=&#34;math inline&#34;&gt;\((X,Y)\)&lt;/span&gt;を用いて構築したモデルに説明変数&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;を与えた時、正例と予測する条件付き確率は&lt;span class=&#34;math inline&#34;&gt;\(P(y=1|x)\)&lt;/span&gt;で表すことができます。一方、&lt;span class=&#34;math inline&#34;&gt;\((X_s,Y_s)\)&lt;/span&gt;を用いて構築したモデルで正例を予測する条件付き確率はベイズの定理とカテゴリ変数&lt;span class=&#34;math inline&#34;&gt;\(s\)&lt;/span&gt;を用いて、&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
P(y=1|x,s=1) = \frac{P(s=1|y=1)P(y=1|x)}{P(s=1|y=1)P(y=1|x) + P(s=1|y=0)P(y=0|x)}
\]&lt;/span&gt;
と書けます。&lt;span class=&#34;math inline&#34;&gt;\((X_s,Y_s)\)&lt;/span&gt;は負例のサンプルサイズを正例に合わせているため、&lt;span class=&#34;math inline&#34;&gt;\(P(s=1,y=1)=1\)&lt;/span&gt;であるので上式は&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
P(y=1|x,s=1) = \frac{P(y=1|x)}{P(y=1|x) + P(s=1|y=0)P(y=0|x)}
= \frac{P(y=1|x)}{P(y=1|x) + P(s=1|y=0)(1-P(y=1|x))}
\]&lt;/span&gt;
と書き換えることができます。&lt;span class=&#34;math inline&#34;&gt;\(P(s=1|y=0)\neq0\)&lt;/span&gt;であることは&lt;span class=&#34;math inline&#34;&gt;\((X_s,Y_s)\)&lt;/span&gt;の定義より自明です(0だと正例しかない不均衡データになる)。よって、&lt;span class=&#34;math inline&#34;&gt;\(P(y=0,x)\neq0\)&lt;/span&gt;である限り、アンダーサンプリングのモデルが正例とはじき出す確率は元のデータセットが出す確率に対して正のバイアスがあることがわかります。求めたいのはバイアスのない&lt;span class=&#34;math inline&#34;&gt;\(P(y=1|x)\)&lt;/span&gt;なので&lt;span class=&#34;math inline&#34;&gt;\(P=P(y=1|x),P_s=P(y|x,s=1),\beta=P(s=1,y=0)\)&lt;/span&gt;とすると、&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
P = \frac{\beta P_s}{\beta P_s-P_s+1}
\]&lt;/span&gt;
とかけ、この関係式を用いてバイアスを補正することができます。
今確認したことを関数として定義しましょう。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;def calibration(y_proba, beta):
    return y_proba / (y_proba + (1 - y_proba) / beta)

sampling_rate = sum(y_train[:,1]) / sum(1-y_train[:,1])
y_proba_calib = calibration(model.predict(X_test), sampling_rate)
y_pred = np_utils.to_categorical(np.argmax(y_proba_calib,axis=1), dense_size)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score
score = accuracy_score(y_test, y_pred)
print(&amp;#39;Test accuracy:&amp;#39;, score)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Test accuracy: 0.288135593220339&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;まったく良くない結果です。&lt;code&gt;ConfusionMatrix&lt;/code&gt;を出してみたところどうやらうまくいっていないことがわかりました。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;ConfusionMatrixDisplay(confusion_matrix(np.argmax(y_test,axis=1), np.argmax(y_pred,axis=1))).plot()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;lt;sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay object at 0x000000004939E748&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;plt.show()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;plt.close()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;不均衡データのバイアス修正はしたんですが、それでもなお負値を予測しやすいモデルとなっています。これでは使えないですね。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;shap値を用いた結果解釈&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;3. Shap値を用いた結果解釈&lt;/h2&gt;
&lt;p&gt;今学習したモデルの&lt;code&gt;shap&lt;/code&gt;値を考え、結果の解釈をしたいと思います。&lt;code&gt;shap&lt;/code&gt;値については時間があれば、説明を追記したいと思います。簡単に言えば、CNNが画像のどの部分に特徴を捉え、馬が上位に入るかを予想したかを可視化で捉えることができます。この馬の解析をすることにします。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;plt.imshow(X_test[0])
plt.show()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;plt.close()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import shap
background = X_train[np.random.choice(X_train.shape[0],100,replace=False)]

e = shap.GradientExplainer(model,background)

shap_values = e.shap_values(X_test[[0]])
shap.image_plot(shap_values[1],X_test[[0]])&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;非常に微妙ですが、足や臀部などを評価しているようにみえます。ですが、背景に反応しているようにも見えるので馬体のみ取り出すトリミングをやる必要がありますね。これは物体検知のモデルを構築する必要がありそうです。また、今度の機会に考えます。
各層において画像のどの側面を捉えているかを可視化してみたいと思います。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;from keras import models

layer_outputs = [layer.output for layer in model.layers[:8]]
layer_names = []
for layer in model.layers[:8]:
    layer_names.append(layer.name)
images_per_row = 16

activation_model = models.Model(inputs=model.input, outputs=layer_outputs)
activations = activation_model.predict(X_train[[0]])

for layer_name, layer_activation in zip(layer_names, activations):
    n_features = layer_activation.shape[-1]

    size = layer_activation.shape[1]

    n_cols = n_features // images_per_row
    display_grid = np.zeros((size * n_cols, images_per_row * size))

    for col in range(n_cols):
        for row in range(images_per_row):
            channel_image = layer_activation[0,
                                             :, :,
                                             col * images_per_row + row]
            channel_image -= channel_image.mean()
            channel_image /= channel_image.std()
            channel_image *= 64
            channel_image += 128
            channel_image = np.clip(channel_image, 0, 255).astype(&amp;#39;uint8&amp;#39;)
            display_grid[col * size : (col + 1) * size,
                         row * size : (row + 1) * size] = channel_image

    scale = 1. / size
    plt.figure(figsize=(scale * display_grid.shape[1],
                        scale * display_grid.shape[0]))
    plt.title(layer_name)
    plt.grid(False)
    plt.imshow(display_grid, cmap=&amp;#39;viridis&amp;#39;)
    plt.show()
    plt.close()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;1536&#34; /&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-16-2.png&#34; width=&#34;1536&#34; /&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-16-3.png&#34; width=&#34;1536&#34; /&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-16-4.png&#34; width=&#34;1536&#34; /&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-16-5.png&#34; width=&#34;1536&#34; /&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-16-6.png&#34; width=&#34;1536&#34; /&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-16-7.png&#34; width=&#34;1536&#34; /&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-16-8.png&#34; width=&#34;1536&#34; /&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-16-9.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;自分が未熟なこともあり、解釈が難しいですね。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;最後に&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;4. 最後に&lt;/h2&gt;
&lt;p&gt;正直まったく上手くいっていません。やはり馬体から順位予測をするのは難しいのでしょうか。ほかの変数と掛け合わせると結果が変わったりするのでしょうか。今のままだとよい特徴量を抽出することができていないように思います。
Youtubeからパドック動画を取得して、&lt;code&gt;Encoder-Decoder&lt;/code&gt;モデルで解析するところまでやらないとうまくいかないんですかね。自分の実力が十分上がれば是非やってみたいと思います(いつになることやら)。それまでには、PCのスペックを上げないといけません。定額給付金を使うかな。。。&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>LightGBMを使用して競馬結果を予想してみる</title>
      <link>/post/post16/</link>
      <pubDate>Sat, 29 Feb 2020 00:00:00 +0000</pubDate>
      <guid>/post/post16/</guid>
      <description>
&lt;script src=&#34;index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#データインポート&#34;&gt;1.データインポート&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#予測モデルの作成&#34;&gt;2. 予測モデルの作成&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#shapでの結果解釈&#34;&gt;3. shapでの結果解釈&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#最後に&#34;&gt;4. 最後に&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;おはこんばんにちは。かなり久しぶりではありますが、Pythonの勉強をかねて以前yahoo.keibaで収集した競馬のレース結果データから、レース結果を予想するモデルを作成したいと思います。&lt;/p&gt;
&lt;div id=&#34;データインポート&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;1.データインポート&lt;/h2&gt;
&lt;p&gt;まず、前回&lt;code&gt;sqlite&lt;/code&gt;に保存したレース結果データを&lt;code&gt;pandas&lt;/code&gt;データフレームへ保存します。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;conn = sqlite3.connect(r&amp;#39;C:\hogehoge\horse_data.db&amp;#39;)
sql = r&amp;#39;SELECT * FROM race_result&amp;#39;
df = pd.read_sql(con=conn,sql=sql)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;データの中身を確認してみましょう。列は以下のようになっています。orderが着順となっています。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df.columns&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Index([&amp;#39;order&amp;#39;, &amp;#39;frame_number&amp;#39;, &amp;#39;horse_number&amp;#39;, &amp;#39;trainer&amp;#39;, &amp;#39;passing_rank&amp;#39;,
##        &amp;#39;last_3F&amp;#39;, &amp;#39;time&amp;#39;, &amp;#39;margin&amp;#39;, &amp;#39;horse_name&amp;#39;, &amp;#39;horse_age&amp;#39;, &amp;#39;horse_sex&amp;#39;,
##        &amp;#39;horse_weight&amp;#39;, &amp;#39;horse_weight_change&amp;#39;, &amp;#39;brinker&amp;#39;, &amp;#39;jockey&amp;#39;,
##        &amp;#39;jockey_weight&amp;#39;, &amp;#39;jockey_weight_change&amp;#39;, &amp;#39;odds&amp;#39;, &amp;#39;popularity&amp;#39;,
##        &amp;#39;race_date&amp;#39;, &amp;#39;race_course&amp;#39;, &amp;#39;race_name&amp;#39;, &amp;#39;race_distance&amp;#39;, &amp;#39;type&amp;#39;,
##        &amp;#39;race_turn&amp;#39;, &amp;#39;race_condition&amp;#39;, &amp;#39;race_weather&amp;#39;, &amp;#39;colour&amp;#39;, &amp;#39;owner&amp;#39;,
##        &amp;#39;farm&amp;#39;, &amp;#39;locality&amp;#39;, &amp;#39;horse_birthday&amp;#39;, &amp;#39;father&amp;#39;, &amp;#39;mother&amp;#39;, &amp;#39;prize&amp;#39;,
##        &amp;#39;http&amp;#39;],
##       dtype=&amp;#39;object&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;orderの中身を確認してみると、括弧（）がついている物が多く、また取消や中止、失格などが存在するため、文字型に認識されていることがわかります。ちなみに括弧（）内の順位は入線順位というやつで、他馬の走行を妨害したりして順位が降着させられたことを意味します（&lt;a href=&#34;http://www.jra.go.jp/judge/&#34; class=&#34;uri&#34;&gt;http://www.jra.go.jp/judge/&lt;/a&gt;）。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df.loc[:,&amp;#39;order&amp;#39;].unique()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## array([&amp;#39;1&amp;#39;, &amp;#39;7&amp;#39;, &amp;#39;2&amp;#39;, &amp;#39;8&amp;#39;, &amp;#39;5&amp;#39;, &amp;#39;15&amp;#39;, &amp;#39;6&amp;#39;, &amp;#39;12&amp;#39;, &amp;#39;11&amp;#39;, &amp;#39;14&amp;#39;, &amp;#39;3&amp;#39;, &amp;#39;13&amp;#39;,
##        &amp;#39;4&amp;#39;, &amp;#39;16&amp;#39;, &amp;#39;9&amp;#39;, &amp;#39;10&amp;#39;, &amp;#39;取消&amp;#39;, &amp;#39;中止&amp;#39;, &amp;#39;除外&amp;#39;, &amp;#39;17&amp;#39;, &amp;#39;18&amp;#39;, &amp;#39;4(3)&amp;#39;, &amp;#39;2(1)&amp;#39;,
##        &amp;#39;3(2)&amp;#39;, &amp;#39;6(4)&amp;#39;, &amp;#39;失格&amp;#39;, &amp;#39;9(8)&amp;#39;, &amp;#39;16(6)&amp;#39;, &amp;#39;12(12)&amp;#39;, &amp;#39;13(9)&amp;#39;, &amp;#39;6(3)&amp;#39;,
##        &amp;#39;10(7)&amp;#39;, &amp;#39;6(5)&amp;#39;, &amp;#39;9(3)&amp;#39;, &amp;#39;11(8)&amp;#39;, &amp;#39;13(2)&amp;#39;, &amp;#39;12(9)&amp;#39;, &amp;#39;14(7)&amp;#39;,
##        &amp;#39;10(1)&amp;#39;, &amp;#39;16(8)&amp;#39;, &amp;#39;14(6)&amp;#39;, &amp;#39;10(3)&amp;#39;, &amp;#39;12(1)&amp;#39;, &amp;#39;13(6)&amp;#39;, &amp;#39;7(1)&amp;#39;,
##        &amp;#39;12(6)&amp;#39;, &amp;#39;6(2)&amp;#39;, &amp;#39;11(2)&amp;#39;, &amp;#39;15(6)&amp;#39;, &amp;#39;13(10)&amp;#39;, &amp;#39;14(4)&amp;#39;, &amp;#39;7(5)&amp;#39;,
##        &amp;#39;17(4)&amp;#39;, &amp;#39;9(7)&amp;#39;, &amp;#39;16(14)&amp;#39;, &amp;#39;12(11)&amp;#39;, &amp;#39;14(2)&amp;#39;, &amp;#39;8(2)&amp;#39;, &amp;#39;9(5)&amp;#39;,
##        &amp;#39;11(5)&amp;#39;, &amp;#39;12(7)&amp;#39;, &amp;#39;11(1)&amp;#39;, &amp;#39;12(8)&amp;#39;, &amp;#39;7(4)&amp;#39;, &amp;#39;5(4)&amp;#39;, &amp;#39;13(12)&amp;#39;,
##        &amp;#39;14(3)&amp;#39;, &amp;#39;10(2)&amp;#39;, &amp;#39;11(10)&amp;#39;, &amp;#39;18(3)&amp;#39;, &amp;#39;10(4)&amp;#39;, &amp;#39;15(8)&amp;#39;, &amp;#39;8(3)&amp;#39;,
##        &amp;#39;5(1)&amp;#39;, &amp;#39;10(5)&amp;#39;, &amp;#39;7(3)&amp;#39;, &amp;#39;5(2)&amp;#39;, &amp;#39;9(1)&amp;#39;, &amp;#39;13(3)&amp;#39;, &amp;#39;16(11)&amp;#39;,
##        &amp;#39;11(3)&amp;#39;, &amp;#39;18(15)&amp;#39;, &amp;#39;11(6)&amp;#39;, &amp;#39;10(6)&amp;#39;, &amp;#39;14(12)&amp;#39;, &amp;#39;12(5)&amp;#39;, &amp;#39;15(14)&amp;#39;,
##        &amp;#39;17(8)&amp;#39;, &amp;#39;18(6)&amp;#39;, &amp;#39;4(2)&amp;#39;, &amp;#39;18(10)&amp;#39;, &amp;#39;16(7)&amp;#39;, &amp;#39;13(1)&amp;#39;, &amp;#39;16(10)&amp;#39;,
##        &amp;#39;15(7)&amp;#39;, &amp;#39;9(4)&amp;#39;, &amp;#39;15(5)&amp;#39;, &amp;#39;12(3)&amp;#39;, &amp;#39;8(7)&amp;#39;, &amp;#39;15(2)&amp;#39;, &amp;#39;12(10)&amp;#39;,
##        &amp;#39;14(9)&amp;#39;, &amp;#39;3(1)&amp;#39;, &amp;#39;6(1)&amp;#39;, &amp;#39;14(5)&amp;#39;, &amp;#39;15(4)&amp;#39;, &amp;#39;11(4)&amp;#39;, &amp;#39;12(4)&amp;#39;,
##        &amp;#39;16(4)&amp;#39;, &amp;#39;9(2)&amp;#39;, &amp;#39;13(5)&amp;#39;, &amp;#39;12(2)&amp;#39;, &amp;#39;15(1)&amp;#39;, &amp;#39;4(1)&amp;#39;, &amp;#39;14(13)&amp;#39;,
##        &amp;#39;14(1)&amp;#39;, &amp;#39;13(7)&amp;#39;, &amp;#39;5(3)&amp;#39;, &amp;#39;8(6)&amp;#39;, &amp;#39;15(13)&amp;#39;, &amp;#39;7(2)&amp;#39;, &amp;#39;15(11)&amp;#39;,
##        &amp;#39;10(9)&amp;#39;, &amp;#39;11(9)&amp;#39;, &amp;#39;8(4)&amp;#39;, &amp;#39;15(3)&amp;#39;, &amp;#39;13(4)&amp;#39;, &amp;#39;16(12)&amp;#39;, &amp;#39;16(5)&amp;#39;,
##        &amp;#39;18(11)&amp;#39;, &amp;#39;10(8)&amp;#39;, &amp;#39;18(8)&amp;#39;, &amp;#39;14(8)&amp;#39;, &amp;#39;16(9)&amp;#39;, &amp;#39;8(5)&amp;#39;, &amp;#39;8(1)&amp;#39;,
##        &amp;#39;14(11)&amp;#39;, &amp;#39;9(6)&amp;#39;, &amp;#39;16(13)&amp;#39;, &amp;#39;16(15)&amp;#39;, &amp;#39;11(11)&amp;#39;, &amp;#39;15(10)&amp;#39;, &amp;#39;7(6)&amp;#39;],
##       dtype=object)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;まずここを修正しましょう。括弧を除去してint型に型変更し、入線順位は新たな列&lt;code&gt;arriving order&lt;/code&gt;として追加します。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df[&amp;#39;arriving order&amp;#39;] = df[df.order.str.contains(r&amp;#39;\d*\(\d*\)&amp;#39;,regex=True)][&amp;#39;order&amp;#39;].replace(r&amp;#39;\d+\(&amp;#39;,r&amp;#39;&amp;#39;,regex=True).replace(r&amp;#39;\)&amp;#39;,r&amp;#39;&amp;#39;,regex=True).astype(&amp;#39;float64&amp;#39;)
df[&amp;#39;arriving order&amp;#39;].unique()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## array([nan,  3.,  1.,  2.,  4.,  8.,  6., 12.,  9.,  7.,  5., 10., 14.,
##        11., 15., 13.])&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df[&amp;#39;order&amp;#39;] = df[&amp;#39;order&amp;#39;].replace(r&amp;#39;\(\d+\)&amp;#39;,r&amp;#39;&amp;#39;,regex=True)
df = df[lambda df: ~df.order.str.contains(r&amp;#39;(取消|中止|除外|失格)&amp;#39;,regex=True)]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## C:\Users\aashi\Anaconda3\envs\umanalytics\lib\site-packages\pandas\core\strings.py:1954: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.
##   return func(self, *args, **kwargs)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df[&amp;#39;order&amp;#39;] = df[&amp;#39;order&amp;#39;].astype(&amp;#39;float64&amp;#39;)
df[&amp;#39;order&amp;#39;].unique()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## array([ 1.,  7.,  2.,  8.,  5., 15.,  6., 12., 11., 14.,  3., 13.,  4.,
##        16.,  9., 10., 17., 18.])&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;きれいな&lt;code&gt;float&lt;/code&gt;型に処理することができました。では、次にラスト3Fのタイムの前処理に移ります。前走のラスト3Fのタイムを予測に使用します。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import numpy as np
df[&amp;#39;last_3F&amp;#39;] = df[&amp;#39;last_3F&amp;#39;].replace(r&amp;#39;character(0)&amp;#39;,np.nan,regex=False).astype(&amp;#39;float64&amp;#39;)
df[&amp;#39;last_3F&amp;#39;] = df.groupby(&amp;#39;horse_name&amp;#39;)[&amp;#39;last_3F&amp;#39;].shift(-1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;前走のレースと順位、追加順位もデータセットへ含めましょう。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df[&amp;#39;prerace&amp;#39;] = df.groupby(&amp;#39;horse_name&amp;#39;)[&amp;#39;race_name&amp;#39;].shift(-1)
df[&amp;#39;preorder&amp;#39;] = df.groupby(&amp;#39;horse_name&amp;#39;)[&amp;#39;order&amp;#39;].shift(-1)
df[&amp;#39;prepassing&amp;#39;] = df.groupby(&amp;#39;horse_name&amp;#39;)[&amp;#39;passing_rank&amp;#39;].shift(-1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;出走時点で獲得している累積賞金額も追加します。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df[&amp;#39;preprize&amp;#39;] = df.groupby(&amp;#39;horse_name&amp;#39;)[&amp;#39;prize&amp;#39;].shift(-1)
df[&amp;#39;preprize&amp;#39;] = df[&amp;#39;preprize&amp;#39;].fillna(0)
df[&amp;#39;margin&amp;#39;] = df.groupby(&amp;#39;horse_name&amp;#39;)[&amp;#39;margin&amp;#39;].shift(-1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;その他、欠損値やデータ型の修正、カテゴリデータのラベルエンコーディングです。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df[&amp;#39;horse_weight&amp;#39;] = df[&amp;#39;horse_weight&amp;#39;].astype(&amp;#39;float64&amp;#39;)
df[&amp;#39;margin&amp;#39;] = df[&amp;#39;margin&amp;#39;].replace(r&amp;#39;character(0)&amp;#39;,np.nan,regex=False)
df[&amp;#39;horse_age&amp;#39;] = df[&amp;#39;horse_age&amp;#39;].astype(&amp;#39;float64&amp;#39;)
df[&amp;#39;horse_weight_change&amp;#39;] = df[&amp;#39;horse_weight_change&amp;#39;].astype(&amp;#39;float64&amp;#39;)
df[&amp;#39;jockey_weight&amp;#39;] = df[&amp;#39;jockey_weight&amp;#39;].astype(&amp;#39;float64&amp;#39;)
df[&amp;#39;race_distance&amp;#39;] = df[&amp;#39;race_distance&amp;#39;].replace(r&amp;#39;m&amp;#39;,r&amp;#39;&amp;#39;,regex=True).astype(&amp;#39;float64&amp;#39;)
df[&amp;#39;race_turn&amp;#39;] = df[&amp;#39;race_turn&amp;#39;].replace(r&amp;#39;character(0)&amp;#39;,np.nan,regex=False)
df.loc[df[&amp;#39;order&amp;#39;]!=1,&amp;#39;order&amp;#39;] = 0

df[&amp;#39;race_turn&amp;#39;] = df[&amp;#39;race_turn&amp;#39;].fillna(&amp;#39;missing&amp;#39;)
df[&amp;#39;colour&amp;#39;] = df[&amp;#39;colour&amp;#39;].fillna(&amp;#39;missing&amp;#39;)
df[&amp;#39;prepassing&amp;#39;] = df[&amp;#39;prepassing&amp;#39;].fillna(&amp;#39;missing&amp;#39;)
df[&amp;#39;prerace&amp;#39;] = df[&amp;#39;prerace&amp;#39;].fillna(&amp;#39;missing&amp;#39;)
df[&amp;#39;father&amp;#39;] = df[&amp;#39;father&amp;#39;].fillna(&amp;#39;missing&amp;#39;)
df[&amp;#39;mother&amp;#39;] = df[&amp;#39;mother&amp;#39;].fillna(&amp;#39;missing&amp;#39;)

from sklearn import preprocessing
cat_list = [&amp;#39;trainer&amp;#39;, &amp;#39;horse_name&amp;#39;, &amp;#39;horse_sex&amp;#39;, &amp;#39;brinker&amp;#39;, &amp;#39;jockey&amp;#39;, &amp;#39;race_course&amp;#39;, &amp;#39;race_name&amp;#39;, &amp;#39;type&amp;#39;, &amp;#39;race_turn&amp;#39;, &amp;#39;race_condition&amp;#39;, &amp;#39;race_weather&amp;#39;, &amp;#39;colour&amp;#39;, &amp;#39;father&amp;#39;, &amp;#39;mother&amp;#39;, &amp;#39;prerace&amp;#39;, &amp;#39;prepassing&amp;#39;]
for column in cat_list:
    target_column = df[column]
    le = preprocessing.LabelEncoder()
    le.fit(target_column)
    label_encoded_column = le.transform(target_column)
    df[column] = pd.Series(label_encoded_column).astype(&amp;#39;category&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## LabelEncoder()
## LabelEncoder()
## LabelEncoder()
## LabelEncoder()
## LabelEncoder()
## LabelEncoder()
## LabelEncoder()
## LabelEncoder()
## LabelEncoder()
## LabelEncoder()
## LabelEncoder()
## LabelEncoder()
## LabelEncoder()
## LabelEncoder()
## LabelEncoder()
## LabelEncoder()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import pandas_profiling as pdq
profile = pdq.ProfileReport(df)
profile&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;予測モデルの作成&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;2. 予測モデルの作成&lt;/h2&gt;
&lt;p&gt;では&lt;code&gt;LightGBM&lt;/code&gt;で予測モデルを作ってみます。&lt;code&gt;optuna&lt;/code&gt;の&lt;code&gt;LightGBM&lt;/code&gt;を使用して、ハイパーパラメータチューニングを行い、学習したモデルを用いて計算したテストデータの予測値と実績値の&lt;code&gt;confusion matrix&lt;/code&gt;ならびに正解率を算出します。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import optuna.integration.lightgbm as lgb
from sklearn.model_selection import train_test_split

y = df[&amp;#39;order&amp;#39;]
x = df.drop([&amp;#39;order&amp;#39;,&amp;#39;passing_rank&amp;#39;,&amp;#39;time&amp;#39;,&amp;#39;odds&amp;#39;,&amp;#39;popularity&amp;#39;,&amp;#39;owner&amp;#39;,&amp;#39;farm&amp;#39;,&amp;#39;locality&amp;#39;,&amp;#39;horse_birthday&amp;#39;,&amp;#39;http&amp;#39;,&amp;#39;prize&amp;#39;,&amp;#39;race_date&amp;#39;,&amp;#39;margin&amp;#39;],axis=1)

X_train, X_test, y_train, y_test = train_test_split(x, y)
X_train, x_val, y_train, y_val = train_test_split(X_train, y_train)

lgb_train = lgb.Dataset(X_train, y_train)
lgb_eval = lgb.Dataset(x_val, y_val)
lgb_test = lgb.Dataset(X_test, y_test, reference=lgb_train)

lgbm_params = {
        &amp;#39;objective&amp;#39;: &amp;#39;binary&amp;#39;,
        &amp;#39;boost_from_average&amp;#39;: False
    }

best_params, history = {}, []
model = lgb.train(lgbm_params, lgb_train, categorical_feature = cat_list,valid_sets = lgb_eval, num_boost_round=100,early_stopping_rounds=20,best_params=best_params,tuning_history=history, verbose_eval=False)
best_params

def calibration(y_proba, beta):
    return y_proba / (y_proba + (1 - y_proba) / beta)

sampling_rate = y_train.sum() / len(y_train)
y_proba = model.predict(X_test, num_iteration=model.best_iteration)
y_proba_calib = calibration(y_proba, sampling_rate)

y_pred = np.vectorize(lambda x: 1 if x &amp;gt; 0.49 else 0)(y_proba_calib)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可視化パートです。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc
import matplotlib.pyplot as plt
import seaborn as sns

# AUC (Area Under the Curve) を計算する
fpr, tpr, thresholds = roc_curve(y_test, y_pred)
auc = auc(fpr, tpr)

# ROC曲線をプロット
plt.plot(fpr, tpr, label=&amp;#39;ROC curve (area = %.2f)&amp;#39;%auc)
plt.legend()
plt.title(&amp;#39;ROC curve&amp;#39;)
plt.xlabel(&amp;#39;False Positive Rate&amp;#39;)
plt.ylabel(&amp;#39;True Positive Rate&amp;#39;)
plt.grid(True)
plt.show()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;plt.close()

# Confusion Matrixを生成
ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred)).plot()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;lt;sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay object at 0x000000004F873388&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;plt.show()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-16-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;plt.close()

accuracy_score(y_test, y_pred)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 0.9300814465677578&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;precision_score(y_test, y_pred)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 0.9426605504587156&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;accuracy_score&lt;/code&gt;（予測精度）が90%を超え、&lt;code&gt;precision_Score&lt;/code&gt;（適合率、陽=1着と予想したデータの正解率）もいい感じです。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;recall_score(y_test, y_pred)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 0.01211460236986382&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;f1_score(y_test, y_pred)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 0.02392177405273267&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;一方、&lt;code&gt;recall_score&lt;/code&gt;(再現性、陽=1着のサンプルのうち実際に正解した割合)が低く偽陰性が高いことが確認できます。その結果、&lt;code&gt;F1&lt;/code&gt;値も低くなっていますね。競馬予測モデルの場合、偽陰性が高いことは偽陽性が高いことよりはましなのですが、回収率を上げるためには偽陰性を下げることを頑張らなければいけません。これは今後の課題ですね。次節では&lt;code&gt;shapley&lt;/code&gt;値を使って要因分解をしたいと思います。。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;shapでの結果解釈&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;3. shapでの結果解釈&lt;/h2&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import shap

shap.initjs()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;lt;IPython.core.display.HTML object&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;explainer = shap.TreeExplainer(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Setting feature_perturbation = &amp;quot;tree_path_dependent&amp;quot; because no background data was given.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;shap_values = explainer.shap_values(X_test)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;まず、各特徴量の重要度を見ることにします。&lt;code&gt;summary_plot&lt;/code&gt;メソッドを使用します。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;shap.summary_plot(shap_values, X_test)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;横軸は各特徴量の平均的な重要度を表しています(shap値の絶対値)。preprize(前走までの賞金獲得金額)やhorse_age、preorder(前走の着順)などが予測に重要であることが分かります。特にpreprizeの重要度は1着の予測、1着以外の予測どちらに対しても大きいです。horse_ageも同様です。ただ、これでは重要というだけで定性的な評価はできません。例えば、preprizeが大きい→1位になる確率が上昇といった関係が確認できれば、それは重要な情報になり得ます。次にそれを確認します。&lt;code&gt;summary_plot&lt;/code&gt;メソッドを使用します。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;shap.summary_plot(shap_values[1], X_test)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;上図も各特徴量の重要度を表しています(今回は絶対値ではありません)。今回はそれぞれの特徴量の重要度がバイオリンプロットによって表されており、かつ特徴量の値の大きさで色分けがされています。例えば、preprizeだと横軸が0以上の部分でのみ赤色の分布が発生しており、ここからpreprizeの特徴量が大きい、つまり前走までの獲得賞金額が多いと平均的に1着の確率が上がるという当たり前の解釈をすることができます。
他にも、horse_age,preorder,last_3Fは特徴量が小さくなるほど1着になる確率があがることも読み取れます。horse_weight, jokey_weightは大きくなるほど1着になる確率が上がるようです。一方、その他は特に定性的な関係を読み取ることはできません。&lt;/p&gt;
&lt;p&gt;次に、特徴量と確率の関係をより詳しく確認してみましょう。先ほど、preprizeは特徴量が大きくなるほど1着になる確率が上昇するということがわかりました。ただ、その確率の上昇は1次関数的に増加するのか、指数的に増大するのか、それとも&lt;span class=&#34;math inline&#34;&gt;\(\log x\)&lt;/span&gt;のように逓減していくのか、わかりません。&lt;code&gt;dependence_plot&lt;/code&gt;を使用してそれを確認してみましょう。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;shap.dependence_plot(ind=&amp;quot;preprize&amp;quot;, shap_values=shap_values[1], features=X_test)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;720&#34; /&gt;&lt;/p&gt;
&lt;p&gt;上図は学習した&lt;code&gt;LightGBM&lt;/code&gt;をpreprizeの関数として見たときの概形をplotしたものです。先に確認したとおり、やはり特徴量が大きくなるにつれ、1着になる確率が上昇していきます。ただ、その上昇は徐々に逓減していき、2000万円を超えるところでほぼ頭打ちとなります。また、上図ではhorse_ageでの色分けを行っており、preprizeとの関係性も確認できるようになっています。やはり、直感と同じく、preprizeが高い馬の中でもhorse_ageが若い馬の1着確率が高くなることが見て取れます。&lt;/p&gt;
&lt;p&gt;preorderの&lt;code&gt;dependence_plot&lt;/code&gt;も確認してみましょう。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;shap.dependence_plot(ind=&amp;quot;preorder&amp;quot;, shap_values=shap_values[1], features=X_test)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-22-1.png&#34; width=&#34;720&#34; /&gt;&lt;/p&gt;
&lt;p&gt;やはり、前走の着順が上位になるほど1着確率が高まることがここからも分かります。また、その確率は6着以上とそれ以外で水準感が変わることも分かります。last_3Fのタイムとの関係性も確認していますが、こちらはあまり関連性はなさそうです。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;最後に&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;4. 最後に&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;LightGBM&lt;/code&gt;を使用し、競馬の予測モデルを作成してみました。さすが&lt;code&gt;LightGBM&lt;/code&gt;といった感じで、予測精度は高かったです。また、&lt;code&gt;shap&lt;/code&gt;値を使用した重要特徴量の検出も上手くいきました。これによって、&lt;code&gt;LightGBM&lt;/code&gt;の気持ちを理解し、より良い特徴量の発見を進めていくことでモデリングの精度を高めていこうと思います。&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Google Earth Engine APIで衛星画像データを取得し、景況感をナウキャスティングしてみる</title>
      <link>/post/post12/</link>
      <pubDate>Tue, 16 Jul 2019 00:00:00 +0000</pubDate>
      <guid>/post/post12/</guid>
      <description>
&lt;script src=&#34;index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#earth-engineを使うための事前準備&#34;&gt;1. Earth Engineを使うための事前準備&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#python-apiを用いた衛星画像データの取得&#34;&gt;2. Python APIを用いた衛星画像データの取得&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#image&#34;&gt;Image…&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#imagecollection&#34;&gt;ImageCollection…&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#featurecollection&#34;&gt;FeatureCollection…&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;皆さんおはこんばんにちわ。前回、GPLVMモデルを用いたGDP予測モデルを構築しました。ただ、ナウキャスティングというからにはオルタナティブデータを用いた解析を行いたいところではあります。ふと、以下の記事を見つけました。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://jp.reuters.com/article/gdp-u-tokyo-idJPKBN15M0NH&#34;&gt;焦点：ナウキャストのＧＤＰ推計、世界初の衛星画像利用　利用拡大も&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;こちらは東京大学の渡辺努先生が人工衛星画像を用いてGDP予測モデルを開発したというものです。記事には&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;米国の海洋大気庁が運営する気象衛星「スオミＮＰＰ」が日本上空を通過する毎日午前１時３０分時点の画像を購入し、縦、横７２０メートル四方のマス目ごとの明るさを計測する。同じ明るさでも、農地、商業用地、工業用地など土地の用途によって経済活動の大きさが異なるため、国土地理院の土地利用調査を参照。土地の用途と、明るさが示す経済活動の相関を弾き出し、この結果を考慮した上で、明るさから経済活動の大きさを試算する。
（中略）衛星画像のように誰もが入手可能な公表データであれば、政府、民間の区別なく分析が可能であるため、渡辺氏はこれを「統計の民主化」と呼び、世界的な潮流になると予想している。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;と書かれており、衛星写真を用いた分析に興味を惹かれました。 衛星写真って誰でも利用可能か？というところですが、Googleが&lt;code&gt;Earth Engine&lt;/code&gt;というサービスを提供していることがわかりました。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;earthengine3.jpg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://earthengine.google.com/&#34; class=&#34;uri&#34;&gt;https://earthengine.google.com/&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;（拙訳）Google Earth Engineは、数ペタバイトの衛星画像群と地理空間データセットを惑星規模の解析機能と組み合わせ、科学者、研究者、開発者が変化を検出し、傾向を射影し、地球の変容を定量化することを可能にします。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;研究・教育・非営利目的ならば、なんと&lt;strong&gt;無料&lt;/strong&gt;で衛星写真データを解析することができます。具体的に何ができるのかは以下の動画を見てください。&lt;/p&gt;
&lt;iframe src=&#34;//www.youtube.com/embed/gKGOeTFHnKY&#34; width=&#34;100%&#34; height=&#34;500&#34; seamless frameborder=&#34;0&#34; allowfullscreen&gt;
&lt;/iframe&gt;
&lt;p&gt;今回はそんなEath Engineのpython APIを用いて衛星画像データを取得し、解析していきたいと思います。&lt;/p&gt;
&lt;div id=&#34;earth-engineを使うための事前準備&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;1. Earth Engineを使うための事前準備&lt;/h2&gt;
&lt;p&gt;Earth Engineを使用するためには、Google Accountを使って申請を行う必要があります。先ほどの画像の右上の「Sign Up」からできます。申請を行って、Gmailに以下のようなメールが来るととりあえずEarth Engineは使用できるようになります。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;earthengine4.jpg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;とりあえずというのはWEB上の&lt;code&gt;Earth Engine&lt;/code&gt; コードエディタは使用できるということです。コードエディタというのは以下のようなもので、ブラウザ上でデータを取得したり、解析をしたり、解析結果をMAPに投影したりすることができる便利ツールです。&lt;code&gt;Earth Engine&lt;/code&gt;の本体はむしろこいつで、APIは副次的なものと考えています。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;earthengine5.jpg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;真ん中のコードエディタにコードを打っていきますが、言語はjavascriptです(APIは&lt;code&gt;python&lt;/code&gt;と&lt;code&gt;javascript&lt;/code&gt;両方あるんですけどね)。解析結果をMAPに投影したり、reference（左）を参照したり、Consoleに吐き出したデータを確認することができるのでかなり便利です。が、データを落とした後で高度な解析を行いたい場合はpythonを使ったほうが慣れているので今回はAPIを使用しています。
話が脱線しました。さて、&lt;code&gt;Earth Engine&lt;/code&gt;の承認を得たら、&lt;code&gt;pip&lt;/code&gt;で&lt;code&gt;earthengine-api&lt;/code&gt;をインストールしておきます。そして、コマンドプロンプト上で、&lt;code&gt;earthengine authenticate&lt;/code&gt;と打ちます。そうすると、勝手にブラウザが立ち上がり、以下のように&lt;code&gt;python api&lt;/code&gt;のauthenticationを行う画面がでますので「次へ」を押下します。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;earthengine1.jpg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;次に以下のような画面にいきますので、そのまま承認します。これでauthenticationの完成です。&lt;code&gt;python&lt;/code&gt;からAPIが使えます。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;earthengine2.jpg&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;python-apiを用いた衛星画像データの取得&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;2. Python APIを用いた衛星画像データの取得&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;Python&lt;/code&gt; APIを使用する準備ができました。ここからは衛星画像データを取得していきます。以下にあるように&lt;code&gt;Earth Engine&lt;/code&gt;にはたくさんのデータセットが存在します。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://developers.google.com/earth-engine/datasets/&#34; class=&#34;uri&#34;&gt;https://developers.google.com/earth-engine/datasets/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;今回は&lt;code&gt;VIIRS Stray Light Corrected Nighttime Day/Night Band Composites Version 1&lt;/code&gt;というデータセットを使用します。このデータセットは世界中の夜間光の光量を月次単位で平均し、提供するものです。サンプル期間は2014-01~現在です。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Earth Engine&lt;/code&gt;にはいくつかの固有なデータ型が存在します。覚えておくべきものは以下の3つです。&lt;/p&gt;
&lt;div id=&#34;image&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Image…&lt;/h3&gt;
&lt;p&gt;ある１時点における&lt;code&gt;raste&lt;/code&gt;rデータです。&lt;code&gt;image&lt;/code&gt;オブジェクトはいくつかの&lt;code&gt;band&lt;/code&gt;で構成されています。この&lt;code&gt;band&lt;/code&gt;はデータによって異なりますが、おおよそのデータは&lt;code&gt;band&lt;/code&gt;それぞれがRGB値を表していたりします。&lt;code&gt;Earth Engine&lt;/code&gt;を使用する上で最も基本的なデータです。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;imagecollection&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;ImageCollection…&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Image&lt;/code&gt;オブジェクトを時系列に並べたオブジェクトです。今回は時系列解析をするのでこのデータを使用します。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;featurecollection&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;FeatureCollection…&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;GeoJSON Feature&lt;/code&gt;です。地理情報を表す&lt;code&gt;Geometry&lt;/code&gt;オブジェクトやそのデータのプロパティ（国名等）が格納されています。今回は日本の位置情報を取得する際に使用しています。&lt;/p&gt;
&lt;p&gt;ではコーディングしていきます。まず、日本の地理情報の&lt;code&gt;FeatureCollection&lt;/code&gt;オブジェクトを取得します。地理情報は&lt;code&gt;Fusion Tables&lt;/code&gt;に格納されていますので、IDで引っ張りCountryがJapanのものを抽出します。&lt;code&gt;ee.FeatureCollection()&lt;/code&gt;の引数にIDを入力すれば簡単に取得できます。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import ee
from dateutil.parser import parse

ee.Initialize()

# get Japan geometory as FeatureCollection from fusion table
japan = ee.FeatureCollection(&amp;#39;ft:1tdSwUL7MVpOauSgRzqVTOwdfy17KDbw-1d9omPw&amp;#39;).filter(ee.Filter.eq(&amp;#39;Country&amp;#39;, &amp;#39;Japan&amp;#39;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;次に夜間光の衛星画像を取得してみます。こちらも&lt;code&gt;ee.ImageCollection()&lt;/code&gt;にデータセットのIDを渡すと取得できます。なお、ここでは&lt;code&gt;band&lt;/code&gt;を月次の平均光量である&lt;code&gt;avg_rad&lt;/code&gt;に抽出しています。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# get night-light data from earth engine from 2014-01-01 to 2019-01-01
dataset = ee.ImageCollection(&amp;#39;NOAA/VIIRS/DNB/MONTHLY_V1/VCMSLCFG&amp;#39;).filter(ee.Filter.date(&amp;#39;2014-01-01&amp;#39;,&amp;#39;2019-01-01&amp;#39;)).select(&amp;#39;avg_rad&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;取得した衛星画像を日本周辺に切り出し、画像ファイルとして出力してみましょう。画像ファイルの出力は&lt;code&gt;image&lt;/code&gt;オブジェクトで可能です（そうでないと画像がたくさん出てきてしまいますからね。。。）。今取得したのは&lt;code&gt;ImageCollection&lt;/code&gt;オブジェクトですから&lt;code&gt;Image&lt;/code&gt;オブジェクトへ圧縮してやる必要があります（上が&lt;code&gt;ImageCollection&lt;/code&gt;オブジェクト、下が圧縮された&lt;code&gt;Image&lt;/code&gt;オブジェクト）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://developers.google.com/earth-engine/images/Reduce_ImageCollection.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;ここでは、&lt;code&gt;ImageCollection&lt;/code&gt;オブジェクトの中にあるの&lt;code&gt;Image&lt;/code&gt;オブジェクトの平均値をとってサンプル期間の平均的な画像を出力してみたいと思います。&lt;code&gt;ImageCollection.mean()&lt;/code&gt;でできます。また、&lt;code&gt;.visualize({min:0.5})&lt;/code&gt;でピクセル値が0.5以上でフィルターをかけています。こうしないと雲と思われるものやゴミ？みたいなものがついてしまいます。次に、ここまで加工した画像データをダウンロードするurlを&lt;code&gt;.getDownloadURL&lt;/code&gt;メソッドで取得しています。その際、&lt;code&gt;region&lt;/code&gt;で切り出す範囲をポリゴン値で指定し、&lt;code&gt;scale&lt;/code&gt;でデータの解像度を指定しています（&lt;code&gt;scale&lt;/code&gt;が小さすぎると処理が重すぎるらしくエラーが出て処理できません）。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;dataset.mean().visualize(min=0.5).getDownloadURL(dict(name=&amp;#39;thumbnail&amp;#39;,region=[[[120.3345348936478, 46.853488838010854],[119.8071911436478, 24.598157870729043],[148.6353161436478, 24.75788466523463],[149.3384411436478, 46.61252884462868]]],scale=5000))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;取得した画像が以下です。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;earthengine6.jpg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;やはり、東京を中心とした関東圏、大阪を中心とした関西圏、愛知、福岡、北海道（札幌周辺）の光量が多く、経済活動が活発であることがわかります。また、陸内よりも沿岸部で光量が多い地域があることがわかります。これは経済活動とは直接関係しない現象のような気もします。今回は分析対象外ですが、北緯38度を境に北側が真っ暗になるのが印象的です。これは言うまでもなく北朝鮮と韓国の境界線ですから、両国の経済活動水準の差が視覚的にコントラストされているのでしょう。今回使用したデータセットは2014年からのものですが、他のデータセットでは1990年代からのデータが取得できるものもあります（その代わり最近のデータは取れませんが）。それらを用いて朝鮮半島や中国の経済発展を観察するのも面白いかもしれません。&lt;/p&gt;
&lt;p&gt;さて、画像は取得できましたがこのままでは解析ができません。ここからは夜間光をピクセル値にマッピングしたデータを取得し、数値的な解析を試みます。ただ、先ほどとはデータ取得の手続きが少し変わります。というのも、今度は日本各地で各ピクセル単位ごとにさまざまな値をとる夜間光を&lt;strong&gt;集約&lt;/strong&gt;し、1つの代用値にしなければならないからです。ピクセルごとの数値を手に入れたところで解析するには手に余ってしまいますからね。イメージは以下のような感じです（Earth Engineサイトから引用）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://developers.google.com/earth-engine/images/Reduce_region_diagram.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;先ほど取得した夜間光の&lt;code&gt;ImageCollection&lt;/code&gt;のある1時点の衛星画像が左です。その中に日本という&lt;code&gt;Region&lt;/code&gt;が存在し、それを&lt;code&gt;ee.Reducer&lt;/code&gt;によって定量的に集約（aggregate）します。Earth Engine APIには&lt;code&gt;.reduceRegions()&lt;/code&gt;メソッドが用意されていますのでそれを用いればいいです。引数は、&lt;code&gt;reducer&lt;/code&gt;=集約方法（ここでは合計値）、&lt;code&gt;collection&lt;/code&gt;=集約をかける&lt;code&gt;region&lt;/code&gt;（&lt;code&gt;FeatureCollection&lt;/code&gt;オブジェクト）、&lt;code&gt;scale&lt;/code&gt;=解像度、です。以下では、&lt;code&gt;ImageCollection&lt;/code&gt;（dataset）の中にある1番目の&lt;code&gt;Image&lt;/code&gt;オブジェクトに&lt;code&gt;.reduceRegions()&lt;/code&gt;メソッドをかけています。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# initialize output box
time0 = dataset.first().get(&amp;#39;system:time_start&amp;#39;);
first = dataset.first().reduceRegions(reducer=ee.Reducer.sum(),collection=japan,scale=1000).set(&amp;#39;time_start&amp;#39;, time0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我々は時系列データが欲しいわけですから、&lt;code&gt;ImageCollection&lt;/code&gt;内にある&lt;code&gt;Image&lt;/code&gt;それぞれに対して同じ処理を行う必要があります。Earth Engineには&lt;code&gt;iterate&lt;/code&gt;という便利な関数があり、引数に処理したい関数を渡せばfor文いらずでこの処理を行ってくれます。ここでは&lt;code&gt;Image&lt;/code&gt;オブジェクトに&lt;code&gt;reduceRegions&lt;/code&gt;メソッドを処理した&lt;code&gt;Computed Object&lt;/code&gt;を以前に処理したものとmergeする&lt;code&gt;myfunc&lt;/code&gt;という関数を定義し、それを&lt;code&gt;iterate&lt;/code&gt;に渡しています。最後に、先ほどと同じく生成したデータを&lt;code&gt;getDownloadURL&lt;/code&gt;メソッドを用いてurlを取得しています（ファイル形式はcsv）。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# define reduceRegions function for iteration
def myfunc(image,first):
  added = image.reduceRegions(reducer=ee.Reducer.sum(),collection=japan,scale=1000).set(&amp;#39;time_start&amp;#39;, image.get(&amp;#39;system:time_start&amp;#39;))
  return ee.FeatureCollection(first).merge(added)

# implement iteration
nightjp = dataset.filter(ee.Filter.date(&amp;#39;2014-02-01&amp;#39;,&amp;#39;2019-01-01&amp;#39;)).iterate(myfunc,first)

# get url to download
ee.FeatureCollection(nightjp).getDownloadURL(filetype=&amp;#39;csv&amp;#39;,selectors=ee.FeatureCollection(nightjp).first().propertyNames().getInfo())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;CSVファイルのurlが取得できました。この時系列をプロットして今日は終わりにしたいと思います。
データを読み込むとこんな感じです。&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import pandas as pd
import matplotlib.pyplot as plt
import os

os.environ[&amp;#39;QT_QPA_PLATFORM_PLUGIN_PATH&amp;#39;] = &amp;#39;C:/Users/aashi/Anaconda3/Library/plugins/platforms&amp;#39;

plt.style.use(&amp;#39;ggplot&amp;#39;)

nightjp_csv.head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   system:index          sum Country  Unnamed: 3  Unnamed: 4
## 0     2014/1/1  881512.4572   Japan         NaN         NaN
## 1     2014/2/1  827345.3551   Japan         NaN         NaN
## 2     2014/3/1  729110.4619   Japan         NaN         NaN
## 3     2014/4/1  612665.8866   Japan         NaN         NaN
## 4     2014/5/1  661434.5027   Japan         NaN         NaN&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;plt.plot(pd.to_datetime(nightjp_csv[&amp;#39;system:index&amp;#39;]),nightjp_csv[&amp;#39;sum&amp;#39;])&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;かなり季節性がありますね。冬場は日照時間が少ないこともあって光量が増えているみたいです。それにしても急激な増え方ですが。次回はこのデータと景況感の代理変数となる経済統計を元に統計解析を行いたいと思います。おたのしみに。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
