<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>カルマンフィルタ | 東京の資産運用会社で働く社会人が研究に没頭するブログ</title>
    <link>/tag/%E3%82%AB%E3%83%AB%E3%83%9E%E3%83%B3%E3%83%95%E3%82%A3%E3%83%AB%E3%82%BF/</link>
      <atom:link href="/tag/%E3%82%AB%E3%83%AB%E3%83%9E%E3%83%B3%E3%83%95%E3%82%A3%E3%83%AB%E3%82%BF/index.xml" rel="self" type="application/rss+xml" />
    <description>カルマンフィルタ</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>ja</language><lastBuildDate>Sun, 10 Feb 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>カルマンフィルタ</title>
      <link>/tag/%E3%82%AB%E3%83%AB%E3%83%9E%E3%83%B3%E3%83%95%E3%82%A3%E3%83%AB%E3%82%BF/</link>
    </image>
    
    <item>
      <title>カルマンフィルタの実装</title>
      <link>/post/post3/</link>
      <pubDate>Sun, 10 Feb 2019 00:00:00 +0000</pubDate>
      <guid>/post/post3/</guid>
      <description>
&lt;script src=&#34;index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;index_files/pagedtable/css/pagedtable.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;index_files/pagedtable/js/pagedtable.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#カルマンフィルタとは&#34;&gt;1. カルマンフィルタとは？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#カルマンフィルタアルゴリズムの導出&#34;&gt;2. カルマンフィルタアルゴリズムの導出&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#rで実装する&#34;&gt;3. &lt;code&gt;R&lt;/code&gt;で実装する。&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#カルマンスムージング&#34;&gt;4. カルマンスムージング&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;おはこんばんにちは。かなり久しぶりの投稿となってしまいました。決して研究をさぼっていたのではなく、&lt;code&gt;BVAR&lt;/code&gt;のコーディングに手こずっていました。あと少しで完成します。さて、今回は&lt;code&gt;BVAR&lt;/code&gt;やこの前のGiannnone et a (2008)のような分析でも大活躍のカルマンフィルタを実装してしまいたいと思います。このブログではパッケージソフトに頼らず、基本的に自分で一から実装を行い、研究することをポリシーとしていますので、これから頻繁に使用するであろうカルマンフィルタを関数として実装してしまうことは非常に有益であると考えます。今回はRで実装をしましたので、そのご報告をします。&lt;/p&gt;
&lt;div id=&#34;カルマンフィルタとは&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;1. カルマンフィルタとは？&lt;/h2&gt;
&lt;p&gt;まず、カルマンフィルタに関する簡単な説明を行います。非常にわかりやすい記事があるので、&lt;a href=&#34;https://qiita.com/MoriKen/items/0c80ef75749977767b43&#34;&gt;こちら&lt;/a&gt;を読んでいただいたほうがより分かりやすいかと思います。&lt;/p&gt;
&lt;p&gt;カルマンフィルタとは、状態空間モデルを解くアルゴリズムの一種です。状態空間モデルとは、手元の観測可能な変数から観測できない変数を推定するモデルであり、以下のような形をしています。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
Y_{t} = Z_{t}\alpha_{t} + d_{t} + S_{t}\epsilon_{t} \\
\alpha_{t} = T_{t}\alpha_{t-1} + c_{t} + R_{t}\eta_{t}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;ここで、&lt;span class=&#34;math inline&#34;&gt;\(Y_{t}\)&lt;/span&gt;は&lt;span class=&#34;math inline&#34;&gt;\(g×1\)&lt;/span&gt;ベクトルの観測可能な変数(観測変数)、&lt;span class=&#34;math inline&#34;&gt;\(Z_{t}\)&lt;/span&gt;は&lt;span class=&#34;math inline&#34;&gt;\(g×k\)&lt;/span&gt;係数行列、&lt;span class=&#34;math inline&#34;&gt;\(\alpha_{t}\)&lt;/span&gt;は&lt;span class=&#34;math inline&#34;&gt;\(k×1\)&lt;/span&gt;ベクトルの観測不可能な変数(状態変数)、&lt;span class=&#34;math inline&#34;&gt;\(T_{t}\)&lt;/span&gt;は&lt;span class=&#34;math inline&#34;&gt;\(k×k\)&lt;/span&gt;係数行列です。また、&lt;span class=&#34;math inline&#34;&gt;\(\epsilon_{t}\)&lt;/span&gt;は観測変数の誤差項、&lt;span class=&#34;math inline&#34;&gt;\(\eta_{t}\)&lt;/span&gt;は状態変数の誤差項です。これらの誤差項はそれぞれ&lt;span class=&#34;math inline&#34;&gt;\(N(0,H_{t})\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(N(0,Q_{t})\)&lt;/span&gt;に従います（&lt;span class=&#34;math inline&#34;&gt;\(H_{t},Q_{t}\)&lt;/span&gt;は分散共分散行列）。&lt;span class=&#34;math inline&#34;&gt;\(d_{t}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(c_{t}\)&lt;/span&gt;は定数項です。1本目の式は観測方程式、2本目の式は遷移方程式と呼ばれます。
状態空間モデルを使用する例として、しばしば池の魚の数を推定する問題が使用されます。今、池の中の魚の全数が知りたいとして、その推定を考えます。観測時点毎に池の中の魚をすべて捕まえてその数を調べるのは現実的に困難なので、一定期間釣りをして釣れた魚をサンプルに全数を推定することを考えます。ここで、釣れた魚は観測変数、池にいる魚の全数は状態変数と考えることができます。今、経験的に釣れた魚の数と全数の間に以下のような関係があるとします。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
Y_{t} = 0.01\alpha_{t} + 5 + \epsilon_{t}
\]&lt;/span&gt;
これが観測方程式になります。また、魚の全数は過去の値からそれほど急速には変化しないと考えられるため、以下のようなランダムウォークに従うと仮定します。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\alpha_{t} = \alpha_{t-1}  + 500 + \eta_{t}
\]&lt;/span&gt;
これが遷移方程式になります。あとは、これをカルマンフィルタアルゴリズムを用いて計算すれば、観測できない魚の全数を推定することができます。
このように状態空間モデルは非常に便利なモデルであり、また応用範囲も広いです。例えば、販売額から潜在顧客数を推定したり、クレジットスプレッドやトービンのQ等経済モデル上の概念として存在する変数を推定する、&lt;code&gt;BVAR&lt;/code&gt;のように&lt;code&gt;VAR&lt;/code&gt;や回帰式の時変パラメータ推定などにも使用されます。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;カルマンフィルタアルゴリズムの導出&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;2. カルマンフィルタアルゴリズムの導出&lt;/h2&gt;
&lt;p&gt;さて、非常に便利な状態空間モデルの説明はこれくらいにして、カルマンフィルタの説明に移りたいと思います。カルマンフィルタは状態空間モデルを解くアルゴリズムの一種であると先述しました。つまり、他にも状態空間モデルを解くアルゴリズムは存在します。カルマンフィルタアルゴリズムは一般に誤差項の正規性の仮定を必要としないフィルタリングアルゴリズムであり、観測方程式と遷移方程式の線形性の仮定さえあれば、線形最小分散推定量となります。カルマンフィルタアルゴリズムの導出にはいくつかの方法がありますが、今回はこの線形最小分散推定量としての導出を行います。まず、以下の３つの仮定を置きます。&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;初期値&lt;span class=&#34;math inline&#34;&gt;\(\alpha_{0}\)&lt;/span&gt;は正規分布&lt;span class=&#34;math inline&#34;&gt;\(N(a_{0},\Sigma_{0})\)&lt;/span&gt;に従う確率ベクトルである(&lt;span class=&#34;math inline&#34;&gt;\(a_{t}\)&lt;/span&gt;は&lt;span class=&#34;math inline&#34;&gt;\(\alpha_{t}\)&lt;/span&gt;の推定値)。&lt;/li&gt;
&lt;li&gt;誤差項&lt;span class=&#34;math inline&#34;&gt;\(\epsilon_{t}\)&lt;/span&gt;,&lt;span class=&#34;math inline&#34;&gt;\(\eta_{s}\)&lt;/span&gt;は全ての&lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;,&lt;span class=&#34;math inline&#34;&gt;\(s\)&lt;/span&gt;で互いに独立で、初期値ベクトル&lt;span class=&#34;math inline&#34;&gt;\(\alpha_{0}\)&lt;/span&gt;と無相関である（&lt;span class=&#34;math inline&#34;&gt;\(E(\epsilon_{t}\eta_{s})=0\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(E(\epsilon_{t}\alpha_{0})=0\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(E(\eta_{t}\alpha_{0})=0\)&lt;/span&gt;）。&lt;/li&gt;
&lt;li&gt;2より、&lt;span class=&#34;math inline&#34;&gt;\(E(\epsilon_{t}\alpha_{t}&amp;#39;)=0\)&lt;/span&gt;、&lt;span class=&#34;math inline&#34;&gt;\(E(\eta_{t}\alpha_{t-1}&amp;#39;)=0\)&lt;/span&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;まず、&lt;span class=&#34;math inline&#34;&gt;\(t-1\)&lt;/span&gt;期の情報集合&lt;span class=&#34;math inline&#34;&gt;\(\Omega_{t-1}\)&lt;/span&gt;が既知の状態での&lt;span class=&#34;math inline&#34;&gt;\(\alpha_{t}\)&lt;/span&gt;と&lt;span class=&#34;math inline&#34;&gt;\(Y_{t}\)&lt;/span&gt;の期待値（予測値）を求めてみましょう。上述した状態空間モデルと誤差項の期待値がどちらもゼロである事実を用いると、以下のように計算することができます。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
E(\alpha_{t}|\Omega_{t-1}) = a_{t|t-1} = T_{t}a_{t-1|t-1} + c_{t}
E(Y_{t}|\Omega_{t-1}) = Y_{t|t-1} = Z_{t}a_{t|t-1} + d_{t}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;ここで、次に、これらの分散を求めます。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{eqnarray}
E( (\alpha_{t}-a_{t|t-1})(\alpha_{t}-a_{t|t-1})&amp;#39;|\Omega_{t-1}) &amp;amp;=&amp;amp; E( (T_{t}\alpha_{t-1} + c_{t} + R_{t}\eta_{t}-a_{t|t-1})(T_{t}\alpha_{t-1} + c_{t} + R_{t}\eta_{t}-a_{t|t-1})&amp;#39;|\Omega_{t-1}) \\ 
&amp;amp;=&amp;amp; E(T_{t}\alpha_{t-1}\alpha_{t-1}&amp;#39;T_{t}&amp;#39; + R_{t}\eta_{t}\eta_{t}&amp;#39;R_{t}&amp;#39;|\Omega_{t-1}) \\
&amp;amp;=&amp;amp; E(T_{t}\alpha_{t-1}\alpha_{t-1}&amp;#39;T_{t}&amp;#39;|\Omega_{t-1}) + E(R_{t}\eta_{t}\eta_{t}&amp;#39;R_{t}&amp;#39;|\Omega_{t-1}) \\
&amp;amp;=&amp;amp; T_{t}E(\alpha_{t-1}\alpha_{t-1}&amp;#39;|\Omega_{t-1})T_{t}&amp;#39; + R_{t}E(\eta_{t}\eta_{t}&amp;#39;|\Omega_{t-1})R_{t}&amp;#39; \\
&amp;amp;=&amp;amp; T_{t}\Sigma_{t-1|t-1}T_{t}&amp;#39; + R_{t}Q_{t}R_{t}&amp;#39; \\
&amp;amp;=&amp;amp; \Sigma_{t|t-1}
\end{eqnarray}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{eqnarray}
E( (Y_{t}-Y_{t|t-1})(Y_{t}-Y_{t|t-1})&amp;#39;|\Omega_{t-1}) &amp;amp;=&amp;amp; E( (Z_{t}\alpha_{t} + d_{t} + S_{t}\epsilon_{t}-Y_{t|t-1})(Z_{t}\alpha_{t} + d_{t} + S_{t}\epsilon_{t}-Y_{t|t-1})&amp;#39;|\Omega_{t-1}) \\
&amp;amp;=&amp;amp; E(Z_{t}\alpha_{t}\alpha_{t}&amp;#39;Z_{t}&amp;#39; + S_{t}\epsilon_{t}\epsilon_{t}&amp;#39;S_{t}&amp;#39;|\Omega_{t-1}) \\
&amp;amp;=&amp;amp; E(Z_{t}\alpha_{t}\alpha_{t}&amp;#39;Z_{t}&amp;#39;|\Omega_{t-1}) + E(S_{t}\epsilon_{t}\epsilon_{t}&amp;#39;S_{t}&amp;#39;|\Omega_{t-1}) \\
&amp;amp;=&amp;amp; Z_{t}E(\alpha_{t}\alpha_{t}&amp;#39;|\Omega_{t-1})Z_{t}&amp;#39; + S_{t}E(\epsilon_{t}\epsilon_{t}&amp;#39;|\Omega_{t-1})S_{t}&amp;#39; \\
&amp;amp;=&amp;amp; Z_{t}\Sigma_{t|t-1}Z_{t}&amp;#39; + S_{t}H_{t}S_{t}&amp;#39; \\
&amp;amp;=&amp;amp; F_{t|t-1}
\end{eqnarray}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;ここで、&lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;期の情報集合&lt;span class=&#34;math inline&#34;&gt;\(\Omega_{t}\)&lt;/span&gt;が得られたとします（つまり、観測値&lt;span class=&#34;math inline&#34;&gt;\(Y_{t}\)&lt;/span&gt;を入手）。カルマンフィルタでは、&lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;期の情報である観測値&lt;span class=&#34;math inline&#34;&gt;\(Y_{t}\)&lt;/span&gt;を用いて&lt;span class=&#34;math inline&#34;&gt;\(a_{t|t-1}\)&lt;/span&gt;を以下の方程式で更新します。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
E(\alpha_{t}|\Omega_{t}) = a_{t|t} = a_{t|t-1} + k_{t}(Y_{t} - Y_{t|t-1})
\]&lt;/span&gt;
つまり、観測値と&lt;span class=&#34;math inline&#34;&gt;\(Y_{t}\)&lt;/span&gt;の期待値（予測値）の差をあるウェイト&lt;span class=&#34;math inline&#34;&gt;\(k_{t}\)&lt;/span&gt;（&lt;span class=&#34;math inline&#34;&gt;\(k×g\)&lt;/span&gt;行列）でかけたもので補正をかけるわけです。よって、観測値と予測値が完全に一致していた場合は補正は行われないことになります。ここで重要なのは、ウエイト&lt;span class=&#34;math inline&#34;&gt;\(k_{t}\)&lt;/span&gt;をどのように決めるのかです。&lt;span class=&#34;math inline&#34;&gt;\(k_{t}\)&lt;/span&gt;は更新後の状態変数の分散&lt;span class=&#34;math inline&#34;&gt;\(E( (\alpha_{t} - a_{t|t})(\alpha_{t} - a_{t|t})&amp;#39;)= \Sigma_{t|t}\)&lt;/span&gt;を最小化するよう決定します。これが、カルマンフィルタが線形最小分散推定量である根拠です。最小化にあたっては以下のベクトル微分が必要になりますので、おさらいをしておきましょう。今回使用するのは以下の事実です。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\displaystyle \frac{\partial a&amp;#39;b}{\partial b} = \frac{\partial b&amp;#39;a}{\partial b} = a \\
\displaystyle \frac{\partial b&amp;#39;Ab}{\partial b} = 2Ab
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;ここで、&lt;span class=&#34;math inline&#34;&gt;\(a,b\)&lt;/span&gt;はベクトル（それぞれ&lt;span class=&#34;math inline&#34;&gt;\(n×1\)&lt;/span&gt;ベクトル、&lt;span class=&#34;math inline&#34;&gt;\(1×n\)&lt;/span&gt;ベクトル）、&lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt;は&lt;span class=&#34;math inline&#34;&gt;\(n×n\)&lt;/span&gt;の対称行列です。まず、１つ目から証明していきます。&lt;span class=&#34;math inline&#34;&gt;\(\displaystyle y = a&amp;#39;b = b&amp;#39;a = \sum_{i=1}^{n}a_{i}b_{i}\)&lt;/span&gt;とします。
このとき、&lt;span class=&#34;math inline&#34;&gt;\(\frac{\partial y}{\partial b_{i}}=a_{i}\)&lt;/span&gt;なので、&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\displaystyle \frac{\partial a&amp;#39;b}{\partial b} = \frac{\partial b&amp;#39;a}{\partial b} = a
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;次に２つ目です。&lt;span class=&#34;math inline&#34;&gt;\(y = b&amp;#39;Ab = \sum_{i=1}^{n}\sum_{j=1}^{n}a_{ij}b_{i}b_{j}\)&lt;/span&gt;とします。このとき、&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\displaystyle \frac{\partial y}{\partial b_{i}} = \sum_{j=1}^{n}a_{ij}b_{j} + \sum_{j=1}^{n}a_{ji}b_{j} = 2\sum_{j=1}^{n}a_{ij}b_{j} = 2a_{i}&amp;#39;b
\]&lt;/span&gt;
よって、&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\displaystyle \frac{\partial y}{\partial b} =
\left(
    \begin{array}{cccc}
      \frac{\partial y}{\partial b_{1}} \\
      \vdots \\
      \frac{\partial y}{\partial b_{n}} \\
    \end{array}
  \right) = 2
\left(
    \begin{array}{cccc}
      \sum_{j=1}^{n}a_{1j}b_{j} \\
      \vdots \\
      \sum_{j=1}^{n}a_{nj}b_{j} \\
    \end{array}
  \right) = 2
\left(
    \begin{array}{cccc}
      a_{1}&amp;#39;b \\
      \vdots \\
      a_{n}&amp;#39;b \\
    \end{array}
  \right)
= 2Ab
\]&lt;/span&gt;
さて、準備ができたので、更新後の状態変数の分散&lt;span class=&#34;math inline&#34;&gt;\(E( (\alpha_{t} - a_{t|t})(\alpha_{t} - a_{t|t})&amp;#39;)\)&lt;/span&gt;を求めてみましょう。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{eqnarray}
E( (\alpha_{t} - a_{t|t})(\alpha_{t} - a_{t|t})&amp;#39;) &amp;amp;=&amp;amp; \Sigma_{t|t} \\
&amp;amp;=&amp;amp; E\{ (\alpha_{t} - a_{t|t-1} + k_{t}(Y_{t} - Y_{t|t-1}))(\alpha_{t} - a_{t|t-1} + k_{t}(Y_{t} - Y_{t|t-1}))&amp;#39;\} \\
&amp;amp;=&amp;amp; E\{ ( (\alpha_{t} - a_{t|t-1}) - k_{t}(Z_{t}\alpha_{t} + d_{t} + S_{t}\epsilon_{t} - Z_{t}a_{t|t-1} - d_{t}) )( (\alpha_{t} - a_{t|t-1}) - k_{t}(Z_{t}\alpha_{t} + d_{t} + S_{t}\epsilon_{t} - Z_{t}a_{t|t-1} - d_{t}) )\} \\
&amp;amp;=&amp;amp; E\{ ( (\alpha_{t} - a_{t|t-1}) - k_{t}(Z_{t}\alpha_{t} + S_{t}\epsilon_{t} - Z_{t}a_{t|t-1}) )( (\alpha_{t} - a_{t|t-1}) - k_{t}(Z_{t}\alpha_{t} + S_{t}\epsilon_{t} - Z_{t}a_{t|t-1}) )&amp;#39;\} \\
&amp;amp;=&amp;amp; E\{ ( (I - k_{t}Z_{t})\alpha_{t} - k_{t}S_{t}\epsilon_{t} - (I - k_{t}Z_{t})a_{t|t-1})( (I - k_{t}Z_{t})\alpha_{t} - k_{t}S_{t}\epsilon_{t} - (I - k_{t}Z_{t})a_{t|t-1})&amp;#39; \} \\
&amp;amp;=&amp;amp; E\{( (I - k_{t}Z_{t})(\alpha_{t}-a_{t|t-1}) - k_{t}S_{t}\epsilon_{t})( (I - k_{t}Z_{t})(\alpha_{t}-a_{t|t-1}) - k_{t}S_{t}\epsilon_{t})&amp;#39;\} \\
&amp;amp;=&amp;amp; (I - k_{t}Z_{t})\Sigma_{t|t-1}(I - k_{t}Z_{t})&amp;#39; + k_{t}S_{t}H_{t}S_{t}&amp;#39;k_{t}&amp;#39; \\
&amp;amp;=&amp;amp; (\Sigma_{t|t-1} - k_{t}Z_{t}\Sigma_{t|t-1})(I - k_{t}Z_{t})&amp;#39; + k_{t}S_{t}H_{t}S_{t}&amp;#39;k_{t}&amp;#39; \\
&amp;amp;=&amp;amp; \Sigma_{t|t-1} - \Sigma_{t|t-1}(k_{t}Z_{t})&amp;#39; - k_{t}Z_{t}\Sigma_{t|t-1} + k_{t}Z_{t}\Sigma_{t|t-1}Z_{t}&amp;#39;k_{t}&amp;#39; + k_{t}S_{t}H_{t}S_{t}&amp;#39;k_{t}&amp;#39; \\
&amp;amp;=&amp;amp; \Sigma_{t|t-1} - \Sigma_{t|t-1}Z_{t}&amp;#39;k_{t}&amp;#39; - k_{t}Z_{t}\Sigma_{t|t-1} + k_{t}(Z_{t}\Sigma_{t|t-1}Z_{t}&amp;#39; + S_{t}H_{t}S_{t}&amp;#39;)k_{t}&amp;#39; \\
\end{eqnarray}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;１回目の式変形で、&lt;span class=&#34;math inline&#34;&gt;\(a_{t|t}\)&lt;/span&gt;に上述した更新式を代入し、２回目の式変形で観測方程式と上で計算した&lt;span class=&#34;math inline&#34;&gt;\(E(Y_{t}|\Omega_{t-1})\)&lt;/span&gt;を代入しています。さて、更新後の状態変数の分散&lt;span class=&#34;math inline&#34;&gt;\(\Sigma_{t|t}\)&lt;/span&gt;を&lt;span class=&#34;math inline&#34;&gt;\(k_{t}\)&lt;/span&gt;の関数として書き表すことができたので、これを&lt;span class=&#34;math inline&#34;&gt;\(k_{t}\)&lt;/span&gt;で微分し、0と置き、&lt;span class=&#34;math inline&#34;&gt;\(\Sigma_{t|t}\)&lt;/span&gt;を最小化する&lt;span class=&#34;math inline&#34;&gt;\(k_{t}\)&lt;/span&gt;を求めます。先述した公式で、&lt;span class=&#34;math inline&#34;&gt;\(a=\Sigma_{t|t-1}Z_{t}&amp;#39;\)&lt;/span&gt;、&lt;span class=&#34;math inline&#34;&gt;\(b=k_{t}&amp;#39;\)&lt;/span&gt;、&lt;span class=&#34;math inline&#34;&gt;\(A=(Z_{t}\Sigma_{t|t-1}Z_{t}&amp;#39; + S_{t}H_{t}S_{t}&amp;#39;)\)&lt;/span&gt;とすると（&lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt;は分散共分散行列の和なので対称行列）、&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\frac{\partial \Sigma_{t|t}}{\partial k_{t}&amp;#39;} = -2(Z_{t}\Sigma_{t|t-1})&amp;#39; + 2(Z_{t}\Sigma_{t|t-1}Z_{t}&amp;#39; + S_{t}H_{t}S_{t}&amp;#39;)k_{t} = 0
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;ここから、&lt;span class=&#34;math inline&#34;&gt;\(k_{t}\)&lt;/span&gt;を解きなおすと、&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{eqnarray}
k_{t} &amp;amp;=&amp;amp; \Sigma_{t|t-1}Z_{t}&amp;#39;(Z_{t}\Sigma_{t|t-1}Z_{t}&amp;#39; + S_{t}H_{t}S_{t}&amp;#39;)^{-1} \\
&amp;amp;=&amp;amp; \Sigma_{t|t-1}Z_{t}&amp;#39;F_{t|t-1}^{-1}
\end{eqnarray}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;突然、&lt;span class=&#34;math inline&#34;&gt;\(F_{t|t-1}\)&lt;/span&gt;が出てきました。これは観測変数の予測値の分散&lt;span class=&#34;math inline&#34;&gt;\(E((Y_{t}-Y_{t|t-1})(Y_{t}-Y_{t|t-1})&amp;#39;|\Omega_{t-1})\)&lt;/span&gt;でした。一方、&lt;span class=&#34;math inline&#34;&gt;\(\Sigma_{t|t-1}Z_{t}\)&lt;/span&gt;は状態変数の予測値の分散を観測変数のスケールに調整したものです（観測空間に写像したもの）。つまり、カルマンゲイン&lt;span class=&#34;math inline&#34;&gt;\(k_{t}\)&lt;/span&gt;は状態変数と観測変数の予測値の分散比となっているのです。観測変数にはノイズがあり、観測方程式はいつも誤差０で満たされるわけではありません。また、状態方程式にも誤差項が存在します。状態の遷移も100%モデル通りにはいかないということです。&lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;期の観測変数&lt;span class=&#34;math inline&#34;&gt;\(Y_{t}\)&lt;/span&gt;が得られたとして、それをどれほど信頼して状態変数を更新するかは観測変数のノイズが状態変数のノイズに比べてどれほど小さいかによります。つまり、相対的に観測方程式が遷移方程式よりも信頼できる場合には状態変数を大きく更新するのです。このように、カルマンフィルタでは、観測方程式と遷移方程式の相対的な信頼度によって、更新の度合いを毎期調整しています。その度合いが分散比であり、カルマンゲインだというわけです。ちなみに欠損値が発生した場合には、観測変数の分散を無限大にし、状態変数の更新を全く行わないという対処を行います。観測変数に信頼がないので当たり前の処置です。この場合は遷移方程式を100%信頼します。これがカルマンフィルタのコアの考え方になります。
更新後の分散を計算しておきます。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{eqnarray}
\Sigma_{t|t} &amp;amp;=&amp;amp; \Sigma_{t|t-1} - \Sigma_{t|t-1}Z_{t}&amp;#39;k_{t}&amp;#39; - k_{t}Z_{t}\Sigma_{t|t-1} + k_{t}F_{t|t-1}k_{t}&amp;#39; \\
&amp;amp;=&amp;amp; \Sigma_{t|t-1} - \Sigma_{t|t-1}Z_{t}&amp;#39;k_{t}&amp;#39; - k_{t}Z_{t}\Sigma_{t|t-1} + (\Sigma_{t|t-1}Z_{t}&amp;#39;F_{t|t-1}^{-1})F_{t|t-1}k_{t}&amp;#39; \\
&amp;amp;=&amp;amp; \Sigma_{t|t-1} - \Sigma_{t|t-1}Z_{t}&amp;#39;k_{t}&amp;#39; - k_{t}Z_{t}\Sigma_{t|t-1} + \Sigma_{t|t-1}Z_{t}&amp;#39;k_{t}&amp;#39; \\
&amp;amp;=&amp;amp; \Sigma_{t|t-1} - k_{t}Z_{t}\Sigma_{t|t-1} \\
&amp;amp;=&amp;amp; \Sigma_{t|t-1} - k_{t}F_{t|t-1}F_{t|t-1}^{-1}Z_{t}\Sigma_{t|t-1} \\
&amp;amp;=&amp;amp; \Sigma_{t|t-1} - k_{t}F_{t|t-1}k_{t}&amp;#39;
\end{eqnarray}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;では、最終的に導出されたアルゴリズムをまとめたいと思います。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{eqnarray}
a_{t|t-1} &amp;amp;=&amp;amp; T_{t}a_{t-1|t-1} + c_{t} \\
\Sigma_{t|t-1} &amp;amp;=&amp;amp; T_{t}\Sigma_{t-1|t-1}T_{t}&amp;#39; + R_{t}Q_{t}R_{t}&amp;#39; \\
Y_{t|t-1} &amp;amp;=&amp;amp; Z_{t}a_{t|t-1} + d_{t} \\
F_{t|t-1} &amp;amp;=&amp;amp;  Z_{t}\Sigma_{t|t-1}Z_{t}&amp;#39; + S_{t}H_{t}S_{t}&amp;#39; \\
k_{t} &amp;amp;=&amp;amp; \Sigma_{t|t-1}Z_{t}&amp;#39;F_{t|t-1}^{-1} \\
a_{t|t} &amp;amp;=&amp;amp; a_{t|t-1} + k_{t}(Y_{t} - Y_{t|t-1}) \\
\Sigma_{t|t} &amp;amp;=&amp;amp;  \Sigma_{t|t-1} - k_{t}F_{t|t-1}k_{t}&amp;#39;
\end{eqnarray}
\]&lt;/span&gt;
初期値&lt;span class=&#34;math inline&#34;&gt;\(a_{0},\Sigma_{0}\)&lt;/span&gt;が所与の元で、まず状態変数の予測値&lt;span class=&#34;math inline&#34;&gt;\(a_{1|0},\Sigma_{1|0}\)&lt;/span&gt;を計算します。その結果を用いて、次は観測変数の予測値&lt;span class=&#34;math inline&#34;&gt;\(Y_{t|t-1},F_{t|t-1}\)&lt;/span&gt;を計算し、カルマンゲイン&lt;span class=&#34;math inline&#34;&gt;\(k_{t}\)&lt;/span&gt;を得ます。&lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;期の観測可能なデータを入手したら、更新方程式を用いて&lt;span class=&#34;math inline&#34;&gt;\(a_{t|t},\Sigma_{t|t}\)&lt;/span&gt;を更新します。これをサンプル期間繰り返していくことになります。ちなみに、遷移方程式の誤差項&lt;span class=&#34;math inline&#34;&gt;\(\eta_{t}\)&lt;/span&gt;と定数項&lt;span class=&#34;math inline&#34;&gt;\(c_{t}\)&lt;/span&gt;がなく、遷移方程式のパラメータが単位行列のカルマンフィルタは逐次最小自乗法と一致します。つまり、新しいサンプルを入手するたびに&lt;code&gt;OLS&lt;/code&gt;をやり直す推計方法ということです（今回はその証明は勘弁してください）。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;rで実装する&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;3. &lt;code&gt;R&lt;/code&gt;で実装する。&lt;/h2&gt;
&lt;p&gt;以下が&lt;code&gt;R&lt;/code&gt;での実装コードです。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;kalmanfiter &amp;lt;- function(y,I,t,z,c=0,R=NA,Q=NA,d=0,S=NA,h=NA,a_int=NA,sig_int=NA){
  #-------------------------------------------------------------------
  # Implemention of Kalman filter
  #   y - observed variable
  #   I - the number of unobserved variable
  #   t - parameter of endogenous variable in state equation
  #   z - parameter of endogenous variable in observable equation
  #   c - constant in state equaion
  #   R - parameter of exogenous variable in state equation
  #   Q - var-cov matrix of exogenous variable in state equation
  #   d - constant in observable equaion
  #   S - parameter of exogenous variable in observable equation
  #   h - var-cov matrix of exogenous variable in observable equation
  #   a_int - initial value of endogenous variable
  #   sig_int - initial value of variance of endogenous variable
  #-------------------------------------------------------------------
  
  library(MASS)
  
  # 1.Define Variable
  if (class(y)!=&amp;quot;matrix&amp;quot;){
    y &amp;lt;- as.matrix(y)
  }
  N &amp;lt;- NROW(y) # sample size
  L &amp;lt;- NCOL(y) # the number of observable variable 
  a_pre &amp;lt;- array(0,dim = c(I,1,N)) # prediction of unobserved variable
  a_fil &amp;lt;- array(0,dim = c(I,1,N+1)) # filtered of unobserved variable
  sig_pre &amp;lt;- array(0,dim = c(I,I,N)) # prediction of var-cov mat. of unobserved variable
  sig_fil &amp;lt;- array(0,dim = c(I,I,N+1)) # filtered of var-cov mat. of unobserved variable
  y_pre &amp;lt;- array(0,dim = c(L,1,N)) # prediction of observed variable
  F_pre &amp;lt;- array(0,dim = c(L,L,N)) # prediction of var-cov mat. of observable variable 
  F_inv &amp;lt;- array(0,dim = c(L,L,N)) # inverse of F_pre
  k &amp;lt;- array(0,dim = c(I,L,N)) # kalman gain
  
  if (any(is.na(a_int))==TRUE){
    a_int &amp;lt;- matrix(0,nrow = I,ncol = 1)
  }
  if (any(is.na(sig_int))==TRUE){
    sig_int &amp;lt;- diag(1,nrow = I,ncol = I)
  }
  if (any(is.na(R))==TRUE){
    R &amp;lt;- diag(1,nrow = I,ncol = I)
  }
  if (any(is.na(Q))==TRUE){
    Q &amp;lt;- diag(1,nrow = I,ncol = I)
  }
  if (any(is.na(S))==TRUE){
    S &amp;lt;- matrix(1,nrow = L,ncol = L)
  }
  if (any(is.na(h))==TRUE){
    H &amp;lt;- array(0,dim = c(L,L,N))
    for(i in 1:N){
      diag(H[,,i]) = 1
    }
  }else if (class(h)!=&amp;quot;array&amp;quot;){
    H &amp;lt;- array(h,dim = c(NROW(h),NCOL(h),N))
  }
  
  # fill infinite if observed data is NA
  for(i in 1:N){
    miss &amp;lt;- is.na(y[i,])
    diag(H[,,i])[miss] &amp;lt;- 1e+32
  }
  y[is.na(y)] &amp;lt;- 0
  
  # 2.Set Initial Value
  a_fil[,,1] &amp;lt;- a_int
  sig_fil[,,1] &amp;lt;- sig_int
  
  # 3.Implement Kalman filter
  for (i in 1:N){
    if(class(z)==&amp;quot;array&amp;quot;){
      Z &amp;lt;- z[,,i]
    }else{
      Z &amp;lt;- z
    }
    a_pre[,,i] &amp;lt;- t%*%a_fil[,,i] + c
    sig_pre[,,i] &amp;lt;- t%*%sig_fil[,,i]%*%t(t) + R%*%Q%*%t(R)
    y_pre[,,i] &amp;lt;- Z%*%a_pre[,,i] + d
    F_pre[,,i] &amp;lt;- Z%*%sig_pre[,,i]%*%t(Z) + S%*%H[,,i]%*%t(S)
    k[,,i] &amp;lt;- sig_pre[,,i]%*%t(Z)%*%ginv(F_pre[,,i])
    a_fil[,,i+1] &amp;lt;- a_pre[,,i] + k[,,i]%*%(y[i,]-y_pre[,,i])
    sig_fil[,,i+1] &amp;lt;- sig_pre[,,i] - k[,,i]%*%F_pre[,,i]%*%t(k[,,i])
  }
  
  # 4.Aggregate results
  result &amp;lt;- list(a_pre,a_fil,sig_pre,sig_fil,y_pre,k,t,z)
  names(result) &amp;lt;- c(&amp;quot;state prediction&amp;quot;, &amp;quot;state filtered&amp;quot;, &amp;quot;state var prediction&amp;quot;, 
                     &amp;quot;state var filtered&amp;quot;, &amp;quot;observable prediction&amp;quot;, &amp;quot;kalman gain&amp;quot;,
                     &amp;quot;parameter of state eq&amp;quot;, &amp;quot;parameter of observable eq&amp;quot;)
  return(result)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;案外簡単に書けるもんですね。これを使って、Giannone et al (2008)をやり直してみます。データセットは前回記事と変わりません。&lt;/p&gt;
&lt;p&gt;以下、分析用の&lt;code&gt;R&lt;/code&gt;コードです。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#------------------------
# Giannone et. al. 2008 
#------------------------

library(MASS)
library(xts)

# ファクターを計算
f &amp;lt;- 3
z &amp;lt;- scale(dataset1)
for (i in 1:nrow(z)){
  eval(parse(text = paste(&amp;quot;S_i &amp;lt;- z[i,]%*%t(z[i,])&amp;quot;,sep = &amp;quot;&amp;quot;)))
  if (i==1){
    S &amp;lt;- S_i
  }else{
    S &amp;lt;- S + S_i
  }
}
S &amp;lt;- (1/nrow(z))*S
gamma &amp;lt;- eigen(S)
D &amp;lt;- diag(gamma$values[1:f])
V &amp;lt;- gamma$vectors[,1:f]
F_t &amp;lt;- matrix(0,nrow(z),f)
for (i in 1:nrow(z)){
  eval(parse(text = paste(&amp;quot;F_t[&amp;quot;,i,&amp;quot;,]&amp;lt;- z[&amp;quot;,i,&amp;quot;,]%*%V&amp;quot;,sep = &amp;quot;&amp;quot;)))
}
lambda_hat &amp;lt;- V
psi &amp;lt;- diag(diag(S-V%*%D%*%t(V)))
R &amp;lt;- diag(diag(cov(z-z%*%V%*%t(V))))

a &amp;lt;- matrix(0,f,f)
b &amp;lt;- matrix(0,f,f)
for(t in 2:nrow(z)){
  a &amp;lt;- a + F_t[t,]%*%t(F_t[t-1,])
  b &amp;lt;- b + F_t[t-1,]%*%t(F_t[t-1,])
}
b_inv &amp;lt;- solve(b)
A_hat &amp;lt;- a%*%b_inv

e &amp;lt;- numeric(f)
for (t in 2:nrow(F_t)){
  e &amp;lt;- e + F_t[t,]-F_t[t-1,]%*%A_hat
}
H &amp;lt;- t(e)%*%e
Q &amp;lt;- diag(1,f,f)
Q[1:f,1:f] &amp;lt;- H

p &amp;lt;- ginv(diag(nrow(kronecker(A_hat,A_hat)))-kronecker(A_hat,A_hat))

result1 &amp;lt;- kalmanfiter(z,f,A_hat,lambda_hat,c=0,R=NA,Q=Q,d=0,S=NA,h=R,a_int=F_t[1,],sig_int=matrix(p,f,f))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;プロットしてみます。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
library(tidyverse)

ggplot(gather(data.frame(factor1=result1$`state filtered`[1,1,-dim(result1$`state filtered`)[3]],factor2=result1$`state filtered`[2,1,-dim(result1$`state filtered`)[3]],factor3=result1$`state filtered`[3,1,-dim(result1$`state filtered`)[3]],time=as.Date(rownames(dataset1))),key = factor,value = value,-time),aes(x=time,y=value,colour=factor)) + geom_line()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;giannoneの記事を書いた際は、元論文の&lt;code&gt;MATLAB&lt;/code&gt;コードを参考にRで書いたのですが、通常のカルマンフィルタとは観測変数の分散共分散行列の逆数の計算方法が違うらしくグラフの形が異なっています。まあでも、概形はほとんど同じですが（なので、ちゃんと動いているはず）。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;カルマンスムージング&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;4. カルマンスムージング&lt;/h2&gt;
&lt;p&gt;カルマンフィルタの実装は以上で終了なのですが、誤差項の正規性を仮定すれば&lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt;期までの情報集合&lt;span class=&#34;math inline&#34;&gt;\(\Omega_{T}\)&lt;/span&gt;を用いて、&lt;span class=&#34;math inline&#34;&gt;\(a_{i|i}, \Sigma_{i|i}(i = 1:T)\)&lt;/span&gt;を&lt;span class=&#34;math inline&#34;&gt;\(a_{i|T}, \Sigma_{i|T}(i = 1:T)\)&lt;/span&gt;へ更新することができます。これをカルマンスムージングと呼びます。これを導出してみましょう。その準備として、以下のような&lt;span class=&#34;math inline&#34;&gt;\(\alpha_{t|t}\)&lt;/span&gt;と&lt;span class=&#34;math inline&#34;&gt;\(\alpha_{t+1|t}\)&lt;/span&gt;の混合分布を計算しておきます。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{eqnarray}
(\alpha_{t|t},\alpha_{t+1|t}) &amp;amp;=&amp;amp; N(
\left(
    \begin{array}{cccc}
      E(\alpha_{t|t}) \\
      E(\alpha_{t+1|t})
    \end{array}
  \right),
\left(
    \begin{array}{cccc}
      Var(\alpha_{t|t}), Cov(\alpha_{t|t},\alpha_{t+1|t}) \\
      Cov(\alpha_{t+1|t},\alpha_{t|t}), Var(\alpha_{t+1|t})
    \end{array}
  \right)
) \\
&amp;amp;=&amp;amp; N(
\left(
    \begin{array}{cccc}
      a_{t|t} \\
      a_{t+1|t}
    \end{array}
  \right),
\left(
    \begin{array}{cccc}
      \Sigma_{t|t}, \Sigma_{t|t}T_{t}&amp;#39; \\
      T_{t}\Sigma_{t|t}, \Sigma_{t+1|t} 
    \end{array}
  \right)
)
\end{eqnarray}
\]&lt;/span&gt;
ここで、&lt;span class=&#34;math inline&#34;&gt;\(Cov(\alpha_{t|t},\alpha_{t+1|t})\)&lt;/span&gt;は&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{eqnarray}
Cov(\alpha_{t+1|t},\alpha_{t|t}) &amp;amp;=&amp;amp; Cov(T_{t}\alpha_{t-1} + c_{t} + R_{t}\eta_{t}, \alpha_{t|t}) \\
&amp;amp;=&amp;amp; T_{t}Cov(\alpha_{t|t},\alpha_{t|t}) + Cov(c_{t},\alpha_{t|t}) + Cov(R_{t}\eta_{t},\alpha_{t|t}) \\
&amp;amp;=&amp;amp; T_{t}Var(\alpha_{t|t}) = T_{t}\Sigma_{t|t}
\end{eqnarray}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;ここで、条件付き多変量正規分布は以下のような分布をしていることを思い出しましょう（
&lt;a href=&#34;https://mathwords.net/gaussjoken&#34;&gt;参考&lt;/a&gt;
）。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
(X_{1},X_{2}) = N(
\left(
    \begin{array}{cccc}
      \mu_{1} \\
      \mu_{2}
    \end{array}
  \right),
\left(
    \begin{array}{cccc}
      \Sigma_{11}, \Sigma_{12} \\
      \Sigma_{21}, \Sigma_{22}
    \end{array}
  \right)
) \\
\]&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[
(X_{1}|X_{2}=x_{2}) = N(\mu_{1} + \Sigma_{12}\Sigma_{22}^{-1}(x_{2}-\mu_{2}),\Sigma_{11}-\Sigma_{12}\Sigma_{22}^{-1}\Sigma_{21})
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;これを用いて、&lt;span class=&#34;math inline&#34;&gt;\((\alpha_{t|t}|\alpha_{t+1|t}=a_{t+1})\)&lt;/span&gt;を計算してみましょう。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{eqnarray}
(\alpha_{t|t}|\alpha_{t+1|t}=a_{t+1}) &amp;amp;=&amp;amp; N(a_{t|t} + \Sigma_{t|t}T_{t}&amp;#39;\Sigma_{t+1|t}^{-1}(a_{t+1}-a_{t+1|t}), \Sigma_{t|t}-\Sigma_{t|t}T_{t}&amp;#39;\Sigma_{t+1|t}^{-1}T_{t}\Sigma_{t|t}) \\
&amp;amp;=&amp;amp;N(a_{t|t} + L_{t}(a_{t+1}-a_{t+1|t}), \Sigma_{t|t}-L_{t}\Sigma_{t+1|t}L_{t}&amp;#39;)
\end{eqnarray}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;ただし、&lt;span class=&#34;math inline&#34;&gt;\(a_{t+1}\)&lt;/span&gt;の値は観測不可能なので、上式を用いて状態変数を更新することはできません。今、わかるのは&lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt;期における&lt;span class=&#34;math inline&#34;&gt;\(a_{t+1|T}\)&lt;/span&gt;の分布のみです。ということで、&lt;span class=&#34;math inline&#34;&gt;\(a_{t+1}\)&lt;/span&gt;を&lt;span class=&#34;math inline&#34;&gt;\(a_{t+1|T}\)&lt;/span&gt;で代用し、&lt;span class=&#34;math inline&#34;&gt;\(\alpha_{t|T}\)&lt;/span&gt;の分布を求めてみます。では、計算していきます。&lt;span class=&#34;math inline&#34;&gt;\(\alpha_{t|T} = N(E(\alpha_{t|T}),Var(\alpha_{t|T}))\)&lt;/span&gt;ですが、&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{eqnarray}
E(\alpha_{t|T}) &amp;amp;=&amp;amp; E_{\alpha_{t+1|T}}(E(\alpha_{t|t}|\alpha_{t+1|t}=\alpha_{t+1|T})) \\
Var(\alpha_{t|T}) &amp;amp;=&amp;amp; E_{\alpha_{t+1|T}}(Var(\alpha_{t|t}|\alpha_{t+1|t} = \alpha_{t+1|T})) + Var_{\alpha_{t+1|T}}(E(\alpha_{t|t}|\alpha_{t+1|t}=\alpha_{t+1|T}))
\end{eqnarray}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;というように、&lt;span class=&#34;math inline&#34;&gt;\(\alpha_{t+1|T}\)&lt;/span&gt;も確率変数となるので、繰り返し期待値の法則と繰り返し分散の法則を使用します（&lt;a href=&#34;https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-041-probabilistic-systems-analysis-and-applied-probability-fall-2010/video-lectures/lecture-12-iterated-expectations-sum-of-a-random-number-of-random-variables/MIT6_041F10_L12.pdf&#34;&gt;こちら&lt;/a&gt;を参照）。&lt;/p&gt;
&lt;p&gt;*繰り返し期待値の法則
&lt;span class=&#34;math inline&#34;&gt;\(E(x) = E_{Z}(E(X|Y=Z))\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;*繰り返し分散の法則
&lt;span class=&#34;math inline&#34;&gt;\(Var(X) = E_{Z}(Var(X|Y=Z))+Var_{Z}(E(X|Y=Z))\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;よって、&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{eqnarray}
E(\alpha_{t|T}) &amp;amp;=&amp;amp; E_{\alpha_{t+1|T}}(E(\alpha_{t|t}|\alpha_{t+1|t}=\alpha_{t+1|T})) \\
&amp;amp;=&amp;amp; a_{t|t} + L_{t}(a_{t+1|T}-a_{t+1|t}) \\
Var(\alpha_{t|T}) &amp;amp;=&amp;amp; E_{\alpha_{t+1|T}}(Var(\alpha_{t|t}|\alpha_{t+1|t}=\alpha_{t+1|T})) + Var_{\alpha_{t+1|T}}(E(\alpha_{t|t}|\alpha_{t+1|t}=\alpha_{t+1|T})) \\
&amp;amp;=&amp;amp; \Sigma_{t|t} - L_{t}\Sigma_{t+1|t}L_{t}&amp;#39; + E( (a_{t|t} + L_{t}(\alpha_{t+1|T}-a_{t+1|t}) - a_{t|t} - L_{t}(a_{t+1|T}-a_{t+1|t}))(a_{t|t} + L_{t}(\alpha_{t+1|T}-a_{t+1|t}) - a_{t|t} - L_{t}(a_{t+1|T}-a_{t+1|t}))&amp;#39;) \\
&amp;amp;=&amp;amp; \Sigma_{t|t} - L_{t}\Sigma_{t+1|t}L_{t}&amp;#39; + E( (L_{t}(\alpha_{t+1|T}-a_{t+1|t}) - L_{t}(a_{t+1|T}-a_{t+1|t}))(L_{t}(\alpha_{t+1|T}-a_{t+1|t}) - L_{t}(a_{t+1|T}-a_{t+1|t}))&amp;#39;) \\
&amp;amp;=&amp;amp; \Sigma_{t|t} - L_{t}\Sigma_{t+1|t}L_{t}&amp;#39; + E( (L_{t}\alpha_{t+1|T} - L_{t}a_{t+1|T})(L_{t}\alpha_{t+1|T} - L_{t}(a_{t+1|T})&amp;#39;) \\
&amp;amp;=&amp;amp; \Sigma_{t|t} - L_{t}\Sigma_{t+1|t}L_{t}&amp;#39; + E( L_{t}(\alpha_{t+1|T} - a_{t+1|T})(\alpha_{t+1|T} - a_{t+1|T})&amp;#39;L_{t}&amp;#39;) \\
&amp;amp;=&amp;amp; \Sigma_{t|t} - L_{t}\Sigma_{t+1|t}L_{t}&amp;#39; + L_{t}E( (\alpha_{t+1|T} - a_{t+1|T})(\alpha_{t+1|T} - a_{t+1|T})&amp;#39;)L_{t}&amp;#39; \\
&amp;amp;=&amp;amp; \Sigma_{t|t} - L_{t}\Sigma_{t+1|t}L_{t}&amp;#39; + L_{t}\Sigma_{t+1|T}L_{t}&amp;#39;
\end{eqnarray}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;となります。カルマンスムージングのアルゴリズムをまとめておきます。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{eqnarray}
L_{t} &amp;amp;=&amp;amp; \Sigma_{t|t}T_{t}\Sigma_{t+1|t}^{-1} \\
a_{t|T} &amp;amp;=&amp;amp; a_{t|t} + L_{t}(a_{t+1|T} - a_{t+1|t}) \\
\Sigma_{t|T} &amp;amp;=&amp;amp; \Sigma_{t+1|t} + L_{t}(\Sigma_{t+1|T}-\Sigma_{t+1|t})L_{t}&amp;#39;
\end{eqnarray}
\]&lt;/span&gt;
カルマンスムージングの特徴的な点は後ろ向きに計算をしていく点です。つまり、&lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt;期から1期に向けて計算を行っていきます。&lt;span class=&#34;math inline&#34;&gt;\(L_{t}\)&lt;/span&gt;に関してはそもそもカルマンフィルタを回した時点で計算可能ですが、&lt;span class=&#34;math inline&#34;&gt;\(\alpha_{t|T}\)&lt;/span&gt;は&lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt;期までのデータが手元にないと計算できません。今、&lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt;期まで観測可能なデータが入手できたとしましょう。すると、２番目の方程式を用いて、&lt;span class=&#34;math inline&#34;&gt;\(a_{T-1|T}\)&lt;/span&gt;を計算します。ちなみに&lt;span class=&#34;math inline&#34;&gt;\(a_{T|T}\)&lt;/span&gt;はカルマンフィルタを回した時点ですでに手に入っているので、計算する必要はありません。同時に、３番目の式を用いて&lt;span class=&#34;math inline&#34;&gt;\(\Sigma_{T-1|T}\)&lt;/span&gt;を計算します。そして、&lt;span class=&#34;math inline&#34;&gt;\(a_{T-1|T},\Sigma_{T-1|T}\)&lt;/span&gt;と&lt;span class=&#34;math inline&#34;&gt;\(L_{T-1}\)&lt;/span&gt;を用いて&lt;span class=&#34;math inline&#34;&gt;\(a_{T-2|T},\Sigma_{T-2|T}\)&lt;/span&gt;を計算、というように1期に向けて後ろ向きに計算をしていくのです。さきほど、遷移方程式の誤差項&lt;span class=&#34;math inline&#34;&gt;\(\eta_{t}\)&lt;/span&gt;と定数項&lt;span class=&#34;math inline&#34;&gt;\(c_{t}\)&lt;/span&gt;がなく、遷移方程式のパラメータが単位行列のカルマンフィルタは逐次最小自乗法と一致すると書きましたが、カルマンスムージングの場合は&lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt;期までのサンプルで&lt;code&gt;OLS&lt;/code&gt;を行った結果と一致します。
&lt;code&gt;R&lt;/code&gt;で実装してみます。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;kalmansmoothing &amp;lt;- function(filter){
  #-------------------------------------------------------------------
  # Implemention of Kalman smoothing
  #   t - parameter of endogenous variable in state equation
  #   z - parameter of endogenous variable in observable equation
  #   a_pre - prediction of state
  #   a_fil - filtered value of state
  #   sig_pre - prediction of var of state
  #   sig_fil - filtered value of state
  #-------------------------------------------------------------------
  
  library(MASS)
  
  # 1.Define variable
  a_pre &amp;lt;- filter$`state prediction`
  a_fil &amp;lt;- filter$`state filtered`
  sig_pre &amp;lt;- filter$`state var prediction`
  sig_fil &amp;lt;- filter$`state var filtered`
  t &amp;lt;- filter$`parameter of state eq`
  C &amp;lt;- array(0,dim = dim(sig_pre))
  a_sm &amp;lt;- array(0,dim = dim(a_pre))
  sig_sm &amp;lt;- array(0,dim = dim(sig_pre))
  N &amp;lt;- dim(C)[3]
  a_sm[,,N] &amp;lt;- a_fil[,,N]
  sig_sm[,,N] &amp;lt;- sig_fil[,,N]
  
  for (i in N:2){
    C[,,i-1] &amp;lt;- sig_fil[,,i-1]%*%t(t)%*%ginv(sig_pre[,,i])
    a_sm[,,i-1] &amp;lt;- a_fil[,,i-1] + C[,,i-1]%*%(a_sm[,,i]-a_pre[,,i])
    sig_sm[,,i-1] &amp;lt;- sig_fil[,,i-1] + C[,,i-1]%*%(sig_sm[,,i]-sig_pre[,,i])%*%t(C[,,i-1])
  }
  
  
  result &amp;lt;- list(a_sm,sig_sm,C)
  names(result) &amp;lt;- c(&amp;quot;state smoothed&amp;quot;, &amp;quot;state var smoothed&amp;quot;, &amp;quot;c&amp;quot;)
  return(result)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;先ほどのコードの続きで&lt;code&gt;R&lt;/code&gt;コードを書いてみます。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;result2 &amp;lt;- kalmansmoothing(result1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;かなりシンプルですね。ちなみにグラフにしましたが、１個目とほぼ変わりませんでした。とりあえず、今日はここまで。&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Gianonne et. al. (2008)のマルチファクターモデルで四半期GDPを予想してみた</title>
      <link>/post/post6/</link>
      <pubDate>Mon, 16 Jul 2018 00:00:00 +0000</pubDate>
      <guid>/post/post6/</guid>
      <description>
&lt;script src=&#34;index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;index_files/pagedtable/css/pagedtable.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;index_files/pagedtable/js/pagedtable.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#gianonne-et.-al.-2008版マルチファクターモデル&#34;&gt;1. Gianonne et. al. (2008)版マルチファクターモデル&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#rで実装する&#34;&gt;2. Rで実装する&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;おはこんばんにちは。
前回、統計ダッシュボードからAPI接続で統計データを落とすという記事を投稿しました。
今回はそのデータを、Gianonne et. al. (2008)のマルチファクターモデルにかけ、四半期GDPの予測を行いたいと思います。&lt;/p&gt;
&lt;div id=&#34;gianonne-et.-al.-2008版マルチファクターモデル&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;1. Gianonne et. al. (2008)版マルチファクターモデル&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;http://dept.ku.edu/~empirics/Courses/Econ844/papers/Nowcasting%20GDP.pdf&#34;&gt;元論文&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;前回の投稿でも書きましたが、この論文はGiannoneらが2008年にパブリッシュした論文です(JME)。彼らはアメリカの経済指標を用いて四半期GDPを日次で推計し、予測指標としての有用性を示しました。指標間の連動性(colinearity)を利用して、多数ある経済指標を2つのファクターに圧縮し、そのファクターを四半期GDPにフィッティングさせることによって高い予測性を実現しています。
まず、このモデルについてご紹介します。このモデルでは2段階推計を行います。まず主成分分析により経済統計を統計間の相関が0となるファクターへ変換します（&lt;a href=&#34;https://datachemeng.com/principalcomponentanalysis/&#34;&gt;参考&lt;/a&gt;）。そして、その後の状態空間モデルでの推計で必要になるパラメータを&lt;code&gt;OLS&lt;/code&gt;推計し、そのパラメータを使用してカルマンフィルタ＆カルマンスムーザーを回し、ファクターを推計しています。では、具体的な説明に移ります。
統計データを&lt;span class=&#34;math inline&#34;&gt;\(x_{i,t|v_j}\)&lt;/span&gt;と定義します。ここで、&lt;span class=&#34;math inline&#34;&gt;\(i=1,...,n\)&lt;/span&gt;は経済統計を表し（つまり&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;が全統計数）、&lt;span class=&#34;math inline&#34;&gt;\(t=1,...,T_{iv_j}\)&lt;/span&gt;は統計&lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;のサンプル期間の時点を表しています（つまり、&lt;span class=&#34;math inline&#34;&gt;\(T_{iv_j}\)&lt;/span&gt;は統計&lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;のその時点での最新データ日付を表す）。また、&lt;span class=&#34;math inline&#34;&gt;\(v_j\)&lt;/span&gt;はある時点&lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;（2005年など）で得られる情報集合（vintage）を表しています。統計データ&lt;span class=&#34;math inline&#34;&gt;\(x_{i,t|v_j}\)&lt;/span&gt;は以下のようにファクター&lt;span class=&#34;math inline&#34;&gt;\(f_{r,t}\)&lt;/span&gt;の線形結合で表すことができます（ここで&lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt;はファクターの数を表す）。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
x_{i,t|v\_j} = \mu_i + \lambda_{i1}f_{1,t} + ... + \lambda_{ir}f_{r,t} + \xi_{i,t|v_j} \tag{1}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mu\_i\)&lt;/span&gt;は定数項、&lt;span class=&#34;math inline&#34;&gt;\(\lambda\_{ir}\)&lt;/span&gt;はファクターローディング、&lt;span class=&#34;math inline&#34;&gt;\(\xi\_{i,t|v\_j}\)&lt;/span&gt;はホワイトノイズの誤差項を表しています。これを行列形式で書くと以下のようになります。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
x_{t|v_j}  = \mu + \Lambda F_t + \xi_{t|v_j} = \mu + \chi_t + \xi_{t|v_j} \tag{2}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;ここで、&lt;span class=&#34;math inline&#34;&gt;\(x_{t|v_j} = (x_{1,t|v_j}, ..., x_{n,t|v_j} )^{\mathrm{T}}\)&lt;/span&gt;、&lt;span class=&#34;math inline&#34;&gt;\(\xi_{t|v_j}=(\xi_{1,t|v_j}, ..., \xi_{n,t|v_j})^{\mathrm{T}}\)&lt;/span&gt;、&lt;span class=&#34;math inline&#34;&gt;\(F_t = (f_{1,t}, ..., f_{r,t})^{\mathrm{T}}\)&lt;/span&gt;であり、&lt;span class=&#34;math inline&#34;&gt;\(\Lambda\)&lt;/span&gt;は各要素が$ _{ij}&lt;span class=&#34;math inline&#34;&gt;\(の\)&lt;/span&gt;nr&lt;span class=&#34;math inline&#34;&gt;\(行列のファクターローディングを表しています。また、\)&lt;/span&gt;&lt;em&gt;t = F_t&lt;span class=&#34;math inline&#34;&gt;\(です。よって、ファクター\)&lt;/span&gt; F_t&lt;span class=&#34;math inline&#34;&gt;\(を推定するためには、データ\)&lt;/span&gt;x&lt;/em&gt;{i,t|v_j}$を以下のように基準化したうえで、分散共分散行列を計算し、その固有値問題を解けばよいという事になります。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\displaystyle z_{it} = \frac{1}{\hat{\sigma}_i}(x_{it} - \hat{\mu}_{it}) \tag{3}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;ここで、&lt;span class=&#34;math inline&#34;&gt;\(\displaystyle \hat{\mu}_{it} = 1/T \sum_{t=1}^T x_{it}\)&lt;/span&gt;であり、&lt;span class=&#34;math inline&#34;&gt;\(\hat{\sigma}_i = \sqrt{1/T \sum_{t=1}^T (x_{it}-\hat{\mu_{it}})^2}\)&lt;/span&gt;です（ここで&lt;span class=&#34;math inline&#34;&gt;\(T\)&lt;/span&gt;はサンプル期間）。分散共分散行列&lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt;を以下のように定義します。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\displaystyle S = \frac{1}{T} \sum_{t=1}^T z_t z_t^{\mathrm{T}} \tag{4}
\]&lt;/span&gt;
次に、&lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt;のうち、固有値を大きい順に&lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt;個取り出し、それを要素にした$ r r&lt;span class=&#34;math inline&#34;&gt;\(対角行列を\)&lt;/span&gt; D&lt;span class=&#34;math inline&#34;&gt;\(、それに対応する固有ベクトルを\)&lt;/span&gt;n r&lt;span class=&#34;math inline&#34;&gt;\(行列にしたものを\)&lt;/span&gt; V&lt;span class=&#34;math inline&#34;&gt;\(と定義します。ファクター\)&lt;/span&gt; _t$は以下のように推計できます。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\tilde{F}_t = V^{\mathrm{T}} z_t \tag{5}
\]&lt;/span&gt;
ファクターローディング&lt;span class=&#34;math inline&#34;&gt;\(\Lambda\)&lt;/span&gt;と誤差項の共分散行列&lt;span class=&#34;math inline&#34;&gt;\(\Psi = \mathop{\mathbb{E}} [\xi_t\xi^{\mathrm{T}}_t]\)&lt;/span&gt;は&lt;span class=&#34;math inline&#34;&gt;\(\tilde{F}_t\)&lt;/span&gt;を&lt;span class=&#34;math inline&#34;&gt;\(z_t\)&lt;/span&gt;に回帰することで推計します。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\displaystyle \hat{\Lambda} = \sum_{t=1}^T z_t \tilde{F}^{\mathrm{T}}_t (\sum_{t=1}^T\tilde{F}_t\tilde{F}^{\mathrm{T}}_t)^{-1} = V \tag{6}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\hat{\Psi} = diag(S - VDV) \tag{7}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;注意して頂きたいのは、ここで推計した&lt;span class=&#34;math inline&#34;&gt;\(\tilde{F}_t\)&lt;/span&gt;は、以下の状態空間モデルでの推計に必要なパラメータを計算するための一時的な推計値であるという事です（２段階推計の１段階目という事）。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
x_{t|v_j}  = \mu + \Lambda F\_t + \xi_{t|v_j} = \mu + \chi_t + \xi_{t|v_j} \tag{2}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
F\_t = AF\_{t-1} + u\_t \tag{8}
\]&lt;/span&gt;
ここで、&lt;span class=&#34;math inline&#34;&gt;\(u_t\)&lt;/span&gt;は平均0、分散&lt;span class=&#34;math inline&#34;&gt;\(H\)&lt;/span&gt;のホワイトノイズです。再掲している(2)式が観測方程式、(8)式が遷移方程式となっています。推定すべきパラメータは&lt;span class=&#34;math inline&#34;&gt;\(\Lambda\)&lt;/span&gt;、&lt;span class=&#34;math inline&#34;&gt;\(\Psi\)&lt;/span&gt;以外に&lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt;と&lt;span class=&#34;math inline&#34;&gt;\(H\)&lt;/span&gt;があります（&lt;span class=&#34;math inline&#34;&gt;\(\mu=0\)&lt;/span&gt;としています）。&lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt;は主成分分析により計算した&lt;span class=&#34;math inline&#34;&gt;\(\tilde{F}_t\)&lt;/span&gt;を&lt;code&gt;VAR(1)&lt;/code&gt;にかけることで推定します。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\hat{A} = \sum_{t=2}^T\tilde{F}_t\tilde{F}_{t-1}^{\mathrm{T}} (\sum_{t=2}^T\tilde{F}_{t-1}\tilde{F}_{t-1}^{\mathrm{T}})^{-1} \tag{9}
\]&lt;/span&gt;
&lt;span class=&#34;math inline&#34;&gt;\(H\)&lt;/span&gt;は今推計した&lt;code&gt;VAR(1)&lt;/code&gt;の誤差項の共分散行列から計算します。これで必要なパラメータの推定が終わりました。次にカルマンフィルタを回します。カルマンフィルタに関しては&lt;a href=&#34;https://qiita.com/MoriKen/items/0c80ef75749977767b43&#34;&gt;こちら&lt;/a&gt;を参考にしてください。わかりやすいです。これで最終的に&lt;span class=&#34;math inline&#34;&gt;\(\hat{F}_{t|v_j}\)&lt;/span&gt;の推計ができるわけです。
GDPがこれらのファクターで説明可能であり（つまり固有の変動がない）、GDPと月次経済指標がjointly normalであれば以下のような単純なOLS推計でGDPを予測することができます。もちろん月次経済指標の方が早く公表されるので、内生性の問題はないと考えられます。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\hat{y}_{3k|v_j} = \alpha + \beta^{\mathrm{T}} \hat{F}_{3k|v_j} \tag{10}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;ここで、&lt;span class=&#34;math inline&#34;&gt;\(3k\)&lt;/span&gt;は四半期の最終月を示しています（3月、6月など）&lt;span class=&#34;math inline&#34;&gt;\(\hat{y}_{3k|v_j}\)&lt;/span&gt;は&lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;時点で得られる情報集合&lt;span class=&#34;math inline&#34;&gt;\(v_j\)&lt;/span&gt;での四半期GDPを表しており、&lt;span class=&#34;math inline&#34;&gt;\(\hat{F}_{3k|v_j}\)&lt;/span&gt;はその時点で推定したファクターを表しています（四半期最終月の値だけを使用している点に注意）。これで推計方法の説明は終わりです。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;rで実装する&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;2. Rで実装する&lt;/h2&gt;
&lt;p&gt;では実装します。前回記事で得られたデータ（dataset）が読み込まれている状態からスタートします。まず、主成分分析でファクターを計算します。なお、前回の記事で3ファクターの累積寄与度が80%を超えたため、今回もファクター数は3にしています。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#------------------------
# Giannone et. al. 2008 
#------------------------

library(xts)
library(MASS)
library(tidyverse)

# 主成分分析でファクターを計算
f &amp;lt;- 3 # ファクター数を定義
a &amp;lt;- which(dataset1$publication == &amp;quot;2012-04-01&amp;quot;) # サンプル開始期間を2012年に設定。
dataset2 &amp;lt;- dataset1[a:nrow(dataset1),]
rownames(dataset2) &amp;lt;- dataset2$publication
dataset2 &amp;lt;- dataset2[,-2]
z &amp;lt;- scale(dataset2) # zは基準化されたサンプルデータ
for (i in 1:nrow(z)){
  eval(parse(text = paste(&amp;quot;S_i &amp;lt;- z[i,]%*%t(z[i,])&amp;quot;,sep = &amp;quot;&amp;quot;)))
  if (i==1){
    S &amp;lt;- S_i
  }else{
    S &amp;lt;- S + S_i
  }
}
S &amp;lt;- (1/nrow(z))*S # 分散共分散行列を計算 (4)式
gamma &amp;lt;- eigen(S) 
D &amp;lt;- diag(gamma$values[1:f])
V &amp;lt;- gamma$vectors[,1:f]
F_t &amp;lt;- matrix(0,nrow(z),f)
for (i in 1:nrow(z)){
  eval(parse(text = paste(&amp;quot;F_t[&amp;quot;,i,&amp;quot;,]&amp;lt;- z[&amp;quot;,i,&amp;quot;,]%*%V&amp;quot;,sep = &amp;quot;&amp;quot;))) # (5)式を実行
}
F_t.xts &amp;lt;- xts(F_t,order.by = as.Date(row.names(z)))
plot.zoo(F_t.xts,col = c(&amp;quot;red&amp;quot;,&amp;quot;blue&amp;quot;,&amp;quot;green&amp;quot;,&amp;quot;yellow&amp;quot;,&amp;quot;purple&amp;quot;),plot.type = &amp;quot;single&amp;quot;) # 時系列プロット&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lambda_hat &amp;lt;- V
psi &amp;lt;- diag(S-V%*%D%*%t(V)) # (7)式
R &amp;lt;- diag(diag(cov(z-z%*%V%*%t(V)))) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;推計したファクター&lt;span class=&#34;math inline&#34;&gt;\(\tilde{F}\_t\)&lt;/span&gt;の時系列プロットは以下のようになり、前回&lt;code&gt;princomp&lt;/code&gt;関数で計算したファクターと完全一致します（じゃあ&lt;code&gt;princomp&lt;/code&gt;でいいやんと思われるかもしれませんが実装しないと勉強になりませんので）。&lt;/p&gt;
&lt;p&gt;次に、&lt;code&gt;VAR(1)&lt;/code&gt;を推計し、パラメータを取り出します。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# VAR(1)モデルを推計
a &amp;lt;- matrix(0,f,f)
b &amp;lt;- matrix(0,f,f)
for(t in 2:nrow(z)){
  a &amp;lt;- a + F_t[t,]%*%t(F_t[t-1,])
  b &amp;lt;- b + F_t[t-1,]%*%t(F_t[t-1,])
}
b_inv &amp;lt;- solve(b)
A_hat &amp;lt;- a%*%b_inv # (9)式

e &amp;lt;- numeric(f)
for (t in 2:nrow(F_t)){
  e &amp;lt;- e + F_t[t,]-F_t[t-1,]%*%A_hat
}
H &amp;lt;- t(e)%*%e
Q &amp;lt;- diag(1,f,f)
Q[1:f,1:f] &amp;lt;- H&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;VAR(1)&lt;/code&gt;に関しても&lt;code&gt;var&lt;/code&gt;関数とパラメータの数値が一致することを確認済みです。いよいよカルマンフィルタを実行します。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# カルマンフィルタを実行
RR &amp;lt;- array(0,dim = c(ncol(z),ncol(z),nrow(z))) # RRは観測値の分散行列（相関はないと仮定）
for(i in 1:nrow(z)){
  miss &amp;lt;- is.na(z[i,])
  R_temp &amp;lt;- diag(R)
  R_temp[miss] &amp;lt;- 1e+32 # 欠損値の分散は無限大にする
  RR[,,i] &amp;lt;- diag(R_temp)
}
zz &amp;lt;- z; zz[is.na(z)] &amp;lt;- 0 # 欠損値（NA）に0を代入（計算結果にはほとんど影響しない）。
a_t &amp;lt;- matrix(0,nrow(zz),f) # a_tは状態変数の予測値
a_tt &amp;lt;- matrix(0,nrow(zz),f) # a_ttは状態変数の更新後の値
a_tt[1,] &amp;lt;- F_t[1,] # 状態変数の初期値には主成分分析で推計したファクターを使用
sigma_t &amp;lt;- array(0,dim = c(f,f,nrow(zz))) # sigma_tは状態変数の分散の予測値
sigma_tt &amp;lt;- array(0,dim = c(f,f,nrow(zz))) # sigma_tは状態変数の分散の更新値
p &amp;lt;- ginv(diag(nrow(kronecker(A_hat,A_hat)))-kronecker(A_hat,A_hat))
sigma_tt[,,1] &amp;lt;- matrix(p,3,3) # 状態変数の分散の初期値はVAR(1)の推計値から計算
y_t &amp;lt;- matrix(0,nrow(zz),ncol(zz)) # y_tは観測値の予測値
K_t &amp;lt;- array(0,dim = c(f,ncol(zz),nrow(zz))) # K_tはカルマンゲイン
data.m &amp;lt;- as.matrix(dataset2)
# カルマンフィルタを実行
for (t in 2:nrow(zz)){
  a_t[t,] &amp;lt;- A_hat%*%a_tt[t-1,]
  sigma_t[,,t] &amp;lt;- A_hat%*%sigma_tt[,,t-1]%*%t(A_hat) + Q
  y_t[t,] &amp;lt;- as.vector(V%*%a_t[t,])
  S_t &amp;lt;- V%*%sigma_tt[,,t-1]%*%t(V)+RR[,,t]
  GG &amp;lt;- t(V)%*%diag(1/diag(RR[,,t]))%*%V
  Sinv &amp;lt;- diag(1/diag(RR[,,t])) - diag(1/diag(RR[,,t]))%*%V%*%ginv(diag(nrow(A_hat))+sigma_t[,,t]%*%GG)%*%sigma_t[,,t]%*%t(V)%*%diag(1/diag(RR[,,t]))
  K_t[,,t] &amp;lt;- sigma_t[,,t]%*%t(V)%*%Sinv
  a_tt[t,] &amp;lt;- a_t[t,] + K_t[,,t]%*%(zz[t,]-y_t[t,])
  sigma_tt[,,t] &amp;lt;- sigma_t[,,t] - K_t[,,t]%*%V%*%sigma_tt[,,t-1]%*%t(V)%*%t(K_t[,,t])
  }

F.xts &amp;lt;- xts(a_tt,order.by = as.Date(rownames(data.m)))
plot.zoo(F.xts, col = c(&amp;quot;red&amp;quot;,&amp;quot;blue&amp;quot;,&amp;quot;green&amp;quot;,&amp;quot;yellow&amp;quot;,&amp;quot;purple&amp;quot;),plot.type = &amp;quot;single&amp;quot;) # 得られた推計値を時系列プロット&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;カルマンフィルタにより推計したファクターの時系列プロットが以下です。遷移方程式がAR(1)だったからかかなり平準化された値となっています。&lt;/p&gt;
&lt;p&gt;では、この得られたファクターをOLSにかけます。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 得られたファクターとGDPをOLSにかける
F_q &amp;lt;- as.data.frame(a_tt[seq(3,nrow(a_tt),3),]) # 四半期の終わり月の値だけを引っ張ってくる 
colnames(F_q) &amp;lt;- c(&amp;quot;factor1&amp;quot;,&amp;quot;factor2&amp;quot;,&amp;quot;factor3&amp;quot;)
colnames(GDP) &amp;lt;- c(&amp;quot;publication&amp;quot;,&amp;quot;GDP&amp;quot;)
t &amp;lt;- which(GDP$publication==&amp;quot;2012-04-01&amp;quot;)
t2 &amp;lt;- which(GDP$publication==&amp;quot;2015-01-01&amp;quot;) # 2012-2q~2015-1qまでのデータが学習データ、それ以降がテストデータ
GDP_q &amp;lt;- GDP[t:nrow(GDP),]
dataset.q &amp;lt;- cbind(GDP_q[1:(t2-t),],F_q[1:(t2-t),])
test &amp;lt;- lm(GDP~factor1 + factor2 + factor3,data=dataset.q)
summary(test)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = GDP ~ factor1 + factor2 + factor3, data = dataset.q)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1350.34  -361.67   -31.63   375.61  1105.07 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) 125729.4     4134.2  30.412 1.07e-08 ***
## factor1       -199.0     1651.3  -0.121    0.907    
## factor2      -1699.7      960.2  -1.770    0.120    
## factor3      -2097.6     3882.5  -0.540    0.606    
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 897.5 on 7 degrees of freedom
## Multiple R-squared:  0.783,  Adjusted R-squared:   0.69 
## F-statistic: 8.419 on 3 and 7 DF,  p-value: 0.0101&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;out_of_sample &amp;lt;- cbind(GDP_q[(t2-t+1):nrow(GDP_q),],F_q[(t2-t+1):nrow(GDP_q),]) # out of sampleのデータセットを作成
test.pred &amp;lt;-  predict(test, out_of_sample, interval=&amp;quot;prediction&amp;quot;)
pred.GDP.xts &amp;lt;- xts(cbind(test.pred[,1],out_of_sample$GDP),order.by = out_of_sample$publication)
plot.zoo(pred.GDP.xts,col = c(&amp;quot;red&amp;quot;,&amp;quot;blue&amp;quot;),plot.type = &amp;quot;single&amp;quot;) # 予測値と実績値を時系列プロット&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;OLSの推計結果はfactor1（赤）とfactor2（青）が有意との結果。前回の投稿でも言及したように、factor1（赤）はリスクセンチメントを表していそうなので、係数の符号が負であることは頷ける。ただし、factor2（青）も符号が負なのではなぜなのか…。このファクターは生産年齢人口など経済の潜在能力を表していると思っていたのに。かなり謎。まあとりあえず予測に移りましょう。このモデルを使用したGDPの予測値と実績値の推移はいかのようになりました。直近の精度は悪くない？&lt;/p&gt;
&lt;p&gt;というか、これ完全に単位根の問題を無視してOLSしてしまっているな。ファクターもGDPも完全に単位根を持つけど念のため単位根検定をかけてみます。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tseries)

adf.test(F_q$factor1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Augmented Dickey-Fuller Test
## 
## data:  F_q$factor1
## Dickey-Fuller = -2.8191, Lag order = 2, p-value = 0.2603
## alternative hypothesis: stationary&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;adf.test(F_q$factor2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Augmented Dickey-Fuller Test
## 
## data:  F_q$factor2
## Dickey-Fuller = -2.6749, Lag order = 2, p-value = 0.3153
## alternative hypothesis: stationary&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;adf.test(F_q$factor3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Augmented Dickey-Fuller Test
## 
## data:  F_q$factor3
## Dickey-Fuller = -2.8928, Lag order = 2, p-value = 0.2323
## alternative hypothesis: stationary&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;adf.test(GDP_q$GDP)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Augmented Dickey-Fuller Test
## 
## data:  GDP_q$GDP
## Dickey-Fuller = 1.5034, Lag order = 3, p-value = 0.99
## alternative hypothesis: stationary&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;はい。全部単位根もってました…。階差をとったのち、単位根検定を行います。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;GDP_q &amp;lt;- GDP_q %&amp;gt;% mutate(growth.rate=(GDP/lag(GDP)-1)*100)
F_q &amp;lt;- F_q %&amp;gt;% mutate(f1.growth.rate=(factor1/lag(factor1)-1)*100,
                      f2.growth.rate=(factor2/lag(factor2)-1)*100,
                      f3.growth.rate=(factor3/lag(factor3)-1)*100)

adf.test(GDP_q$growth.rate[2:NROW(GDP_q$growth.rate)])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Augmented Dickey-Fuller Test
## 
## data:  GDP_q$growth.rate[2:NROW(GDP_q$growth.rate)]
## Dickey-Fuller = -0.31545, Lag order = 3, p-value = 0.9838
## alternative hypothesis: stationary&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;adf.test(F_q$f1.growth.rate[2:NROW(F_q$f1.growth.rate)])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Augmented Dickey-Fuller Test
## 
## data:  F_q$f1.growth.rate[2:NROW(F_q$f1.growth.rate)]
## Dickey-Fuller = -2.7762, Lag order = 2, p-value = 0.2767
## alternative hypothesis: stationary&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;adf.test(F_q$f2.growth.rate[2:NROW(F_q$f2.growth.rate)])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Augmented Dickey-Fuller Test
## 
## data:  F_q$f2.growth.rate[2:NROW(F_q$f2.growth.rate)]
## Dickey-Fuller = -2.6156, Lag order = 2, p-value = 0.3379
## alternative hypothesis: stationary&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;adf.test(F_q$f3.growth.rate[2:NROW(F_q$f3.growth.rate)])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Augmented Dickey-Fuller Test
## 
## data:  F_q$f3.growth.rate[2:NROW(F_q$f3.growth.rate)]
## Dickey-Fuller = -2.9893, Lag order = 2, p-value = 0.1955
## alternative hypothesis: stationary&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;factor1だけは5%有意水準で帰無仮説を棄却できない…。困りました。有意水準を10%ということにして、とりあえず階差で&lt;code&gt;OLS&lt;/code&gt;してみます。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dataset.q &amp;lt;- cbind(GDP_q[1:(t2-t),],F_q[1:(t2-t),])
colnames(dataset.q) &amp;lt;- c(&amp;quot;publication&amp;quot;,&amp;quot;GDP&amp;quot;,&amp;quot;growth.rate&amp;quot;,&amp;quot;factor1&amp;quot;,&amp;quot;factor2&amp;quot;,&amp;quot;factor3&amp;quot;,&amp;quot;f1.growth.rate&amp;quot;,&amp;quot;f2.growth.rate&amp;quot;,&amp;quot;f3.growth.rate&amp;quot;)
test1 &amp;lt;- lm(growth.rate~f1.growth.rate + f2.growth.rate + f3.growth.rate,data=dataset.q)
summary(test1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = growth.rate ~ f1.growth.rate + f2.growth.rate + 
##     f3.growth.rate, data = dataset.q)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.6940 -0.2411  0.2041  0.4274  1.0904 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&amp;gt;|t|)
## (Intercept)     8.978e-02  4.588e-01   0.196    0.851
## f1.growth.rate -6.353e-03  1.375e-02  -0.462    0.660
## f2.growth.rate  6.155e-04  6.026e-03   0.102    0.922
## f3.growth.rate -9.249e-05  5.152e-04  -0.180    0.863
## 
## Residual standard error: 0.956 on 6 degrees of freedom
##   (1 observation deleted due to missingness)
## Multiple R-squared:  0.04055,    Adjusted R-squared:  -0.4392 
## F-statistic: 0.08452 on 3 and 6 DF,  p-value: 0.966&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;推計結果がわるくなりました…。予測値を計算し、実績値とプロットしてみます。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;out_of_sample1 &amp;lt;- cbind(GDP_q[(t2-t+1):nrow(GDP_q),],F_q[(t2-t+1):nrow(GDP_q),]) # out of sampleのデータセットを作成
test1.pred &amp;lt;- predict(test1, out_of_sample1, interval=&amp;quot;prediction&amp;quot;)
pred1.GDP.xts &amp;lt;- xts(cbind(test1.pred[,1],out_of_sample1$growth.rate),order.by = out_of_sample1$publication)
plot.zoo(pred1.GDP.xts,col = c(&amp;quot;red&amp;quot;,&amp;quot;blue&amp;quot;),plot.type = &amp;quot;single&amp;quot;) # 予測値と実績値を時系列プロット&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;index_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;ん～、これはやり直しですね。今日はここまでで勘弁してください…。&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
