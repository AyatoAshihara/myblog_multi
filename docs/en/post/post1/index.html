<!DOCTYPE html><html lang="en-us" >

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  
  
  
  <meta name="generator" content="Wowchemy 4.8.0 for Hugo">
  

  

  
  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Ayato Ashihara">

  
  
  
    
  
  <meta name="description" content="I implemented the much talked about Gauss regression, which is too versatile to be fun in reverse.">

  
  <link rel="alternate" hreflang="ja" href="../../../post/post1/">
  
  <link rel="alternate" hreflang="en-us" href="../../../en/post/post1/">

  







  




  
  
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  

  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  
  
  <script src="../../../js/mathjax-config.js"></script>
  

  
  
  
  
    
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/solarized-dark.min.css" crossorigin="anonymous" title="hl-light">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/solarized-dark.min.css" crossorigin="anonymous" title="hl-dark" disabled>
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.css" integrity="sha512-1xoFisiGdy9nvho8EgXuXvnpR5GAMSjFwp40gSRE3NwdUdIMIKuPa7bqoUhLD0O/5tPNhteAsE5XyyMi5reQVA==" crossorigin="anonymous">
    

    

    
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.2.2/lazysizes.min.js" integrity="sha512-TmDwFLhg3UA4ZG0Eb4MIyT1O1Mb+Oww5kFG0uHqXsdbyZz9DcvYQhKpGgNkamAI6h2lGGZq2X8ftOJvF/XjTUg==" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    

  

  
  
  
    
      
      
      <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
    
  

  
  
  
  
  <link rel="stylesheet" href="../../../css/wowchemy.css">

  





<script async src="https://www.googletagmanager.com/gtag/js?id=UA-140804055-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url, target) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           if (target !== '_blank') {
             document.location = url;
           }
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target, event.target.getAttribute('target'));  
  }

  gtag('js', new Date());
  gtag('config', 'UA-140804055-1', { 'anonymize_ip': true });

  
  document.addEventListener('click', onClickCallback, false);
</script>


  


  
  

  

  <link rel="manifest" href="../../../en/index.webmanifest">
  <link rel="icon" type="image/png" href="../../../images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_32x32_fill_lanczos_center_2.png">
  <link rel="apple-touch-icon" type="image/png" href="../../../images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_2.png">

  <link rel="canonical" href="../../../en/post/post1/">

  
  
  
  
  
  
  
    
  
  
  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@vdjgdkhvskcndj">
  <meta property="twitter:creator" content="@vdjgdkhvskcndj">
  
  <meta property="og:site_name" content="京都の電子部品メーカーで働く社会人が研究に没頭するブログ">
  <meta property="og:url" content="/en/post/post1/">
  <meta property="og:title" content="Implementing Gaussian regression. | 京都の電子部品メーカーで働く社会人が研究に没頭するブログ">
  <meta property="og:description" content="I implemented the much talked about Gauss regression, which is too versatile to be fun in reverse."><meta property="og:image" content="/en/post/post1/featured.png">
  <meta property="twitter:image" content="/en/post/post1/featured.png"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2018-12-02T00:00:00&#43;00:00">
    
    <meta property="article:modified_time" content="2018-12-02T00:00:00&#43;00:00">
  

  


    






  




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "/en/post/post1/"
  },
  "headline": "Implementing Gaussian regression.",
  
  "image": [
    "/en/post/post1/featured.png"
  ],
  
  "datePublished": "2018-12-02T00:00:00Z",
  "dateModified": "2018-12-02T00:00:00Z",
  
  "author": {
    "@type": "Person",
    "name": "Ayato Ashihara"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "京都の電子部品メーカーで働く社会人が研究に没頭するブログ",
    "logo": {
      "@type": "ImageObject",
      "url": "/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_2.png"
    }
  },
  "description": "I implemented the much talked about Gauss regression, which is too versatile to be fun in reverse."
}
</script>

  

  


  
  
  
  
  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.1/cookieconsent.min.js" integrity="sha256-5VhCqFam2Cn+yjw61zbBNrbHVJ6SRydPeKopYlngbiQ=" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.1/cookieconsent.min.css" integrity="sha256-zQ0LblD/Af8vOppw18+2anxsuaz3pWYyVWi+bTvTH8Q=" crossorigin="anonymous">
  
  <script>
  window.addEventListener("load", function(){
    window.cookieconsent.initialise({
      "palette": {
        "popup": {
          "background": "#2962ff",
          "text": "rgb(255, 255, 255)"
        },
        "button": {
          "background": "rgb(255, 255, 255)",
          "text": "#2962ff"
        }
      },
      "theme": "classic",
      "content": {
        "message": "This website uses cookies to ensure you get the best experience on our website.",
        "dismiss": "Got it!",
        "link": "Learn more",
        "href": "https://www.cookiesandyou.com"
      }
    })});
  </script>



  





  <title>Implementing Gaussian regression. | 京都の電子部品メーカーで働く社会人が研究に没頭するブログ</title>

</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class=" ">

  
  
  
    <script>window.wcDarkLightEnabled = true;</script>
  
  
    <script>const isSiteThemeDark = false;</script>
  
  
  <script src="../../../js/load-theme.js"></script>

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  












<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="../../../en">京都の電子部品メーカーで働く社会人が研究に没頭するブログ</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="../../../en">京都の電子部品メーカーで働く社会人が研究に没頭するブログ</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="../../../en/#about"><span>About</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
        

        <li class="nav-item">
          <a class="nav-link  active" href="../../../en/post"><span>Posts</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="../../../en/publication"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="../../../en/#contact"><span>Contact</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      
      <li class="nav-item dropdown theme-dropdown">
        <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true">
          <i class="fas fa-moon" aria-hidden="true"></i>
        </a>
        <div class="dropdown-menu">
          <a href="#" class="dropdown-item js-set-theme-light">
            <span>Light</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-dark">
            <span>Dark</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-auto">
            <span>Automatic</span>
          </a>
        </div>
      </li>
      

      
      <li class="nav-item dropdown i18n-dropdown">
        <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true">
          <i class="fas fa-globe mr-1" aria-hidden="true"></i><span class="d-none d-lg-inline">English</span></a>
        <div class="dropdown-menu">
          <div class="dropdown-item dropdown-item-active">
            <span>English</span>
          </div>
          
          <a class="dropdown-item" href="../../../post/post1/">
            <span>日本語</span>
          </a>
          
        </div>
      </li>
      

    </ul>

  </div>
</nav>



  <div class="container-fluid docs">
  <div class="row flex-xl-nowrap">

    <div class="d-none d-xl-block col-xl-2 docs-toc">
      <ul class="nav toc-top">
        <li><a href="#" id="back_to_top" class="docs-toc-title">Contents</a></li>
      </ul>
      <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#1-what-is-gpr">1. What is <code>GPR</code>?</a></li>
        <li><a href="#2-implementation-of-the-gpr">2. Implementation of the `GPR'</a></li>
      </ul>
    </li>
  </ul>
</nav>
      
    </div>

    <main class="col-12 col-md-0 col-xl-10 py-md-3 pl-md-5 docs-content" role="main">
      <article class="article">

        




















  
  


<div class="article-container pt-3">
  <h1>Implementing Gaussian regression.</h1>

  

  

<div id="code-folding-buttons" class="dropdown btn-group pull-right">
  <a class="btn btn-light btn-sm dropdown-toggle" href="#" role="button" id="allCodeToggleButton"
     data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
    Code
  </a>
  <div class="dropdown-menu" aria-labelledby="allCodeToggleButton">
    <a id="rmd-show-all-code" class="dropdown-item small" href="#">Show all</a>
    <a id="rmd-hide-all-code" class="dropdown-item small" href="#">Hide all</a>
  </div>
</div>



  


<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
    
    Dec 2, 2018
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    10 min read
  </span>
  

  
  
  
  <span class="middot-divider"></span>
  <a href="../../../en/post/post1/#disqus_thread"></a>
  

  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fas fa-folder mr-1"></i><a href="../../../en/category/macroeconomics/">macroeconomics</a></span>
  

</div>

  














</div>


<div class="article-header container featured-image-wrapper mt-4 mb-4" style="max-width: 1155px; max-height: 645px;">
  <div style="position: relative">
    <img src="../../../en/post/post1/featured.png" alt="" class="featured-image">
    
  </div>
</div>



        <div class="article-container">

          <div class="article-style">
            <p>　Hi. Yesterday, I wrote an article about <code>Bayesian Vector Autoregression</code>.
　In the article, the topic of hyperparameter tuning came up, and looking for some efficient way to tune it, I found <code>Bayesian Optimization</code>. Since I am planning to use machine learning methods in daily GDP, I thought that <code>Bayesian Optimization</code> could be quite useful, and I spent all night yesterday to understand it.<br>
　I will implement it here, but <code>Bayesian Optimization</code> uses <code>Gaussian Pocess Regression</code> (<code>GPR</code>), and my motivation for writing this entry was to implement it first. I will write about the implementation of <code>Bayesian Optimization</code> after this entry.</p>
<h2 id="1-what-is-gpr">1. What is <code>GPR</code>?</h2>
<p>　The <code>GRP</code> is, simply put, <strong>a type of nonlinear regression method using Bayesian estimation</strong>. Although the model itself is linear, it is characterized by its ability to estimate <strong>infinite nonlinear transformations of input variables using a kernel trick</strong> as explanatory variables (depending on what you choose for the kernel).
　The <code>GPR</code> assumes that <code>\(N\)</code> input and teacher data are available for training, and the <code>\(N+1\)</code> of input data are also available. From this situation, we can predict the <code>\(N+1\)</code>th teacher data.<br>
　The data contains noise and follows the following probability model.
　
$$
t_{i} = y_{i} + \epsilon_{i}
$$
where <code>\(t_{i}\)</code> is the <code>\(i\)</code>th observable teacher data (scalar), <code>\(y_{i}\)</code> is the unobservable output data (scalar), and <code>\(\beta_{i}\)</code> follows a normal distribution <code>\(N(0, \beta^{-1})\)</code> with measurement error. <code>\(y_{i}\)</code> follows the following probability model.</p>
<p>$$
\displaystyle y_{i}  = \textbf{w}^{T}\phi(x_{i})
$$</p>
<p>where <code>\(x_{i}\)</code> is the ith input data vector, <code>\(\phi(・)\)</code> is the non-linear function and <code>\(\bf{w}^{T}\)</code> is the weight coefficient (regression coefficient) vector for each input data. As a nonlinear function, I assume <code>\(\psi(x_{i}) = (x_{1,i}, x_{1,i}^{2},... ,x_{1,i}x_{2,i},...)\)</code>. ($x_{1,i}$ is the first variable in the <code>\(i\)</code>th input data <code>\(x_{i}\)</code>). The conditional probability of obtaining <code>\(t_{i}\)</code> from the probabilistic model of the teacher data, with the <code>\(i\)</code>th output data <code>\(y_{i}\)</code> obtained, is</p>
<p>$$
p(t_{i}|y_{i}) = N(t_{i}|y_{i},\beta^{-1})
$$</p>
<p><code>\(\displaystyle \textbf{t} = (t_{1},... ,t_{n})^{T}\)</code> and <code>\(\displaystyle \textbf{y} = (y_{1},... ,y_{n})^{T}\)</code>, then by extending the above equation, we have</p>
<p>$$
\displaystyle p(\textbf{t}|\textbf{y}) = N(\textbf{t}|\textbf{y},\beta^{-1}\textbf{I}_{N})
$$</p>
<p>We assume that the expected value of <code>\(\textbf{w}\)</code> as a prior distribution is 0, and all variances are  <code>\(\alpha\)</code>. We also assume that <code>\(\displaystyle \textbf{y}\)</code> follows a Gaussian process. A Gaussian process is one where the simultaneous distribution of <code>\(\displaystyle \textbf{y}\)</code> follows a multivariate Gaussian distribution. In code, it looks like this</p>
<p>\normalsize</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r"><span style="color:#75715e"># Define Kernel function</span>
Kernel_Mat <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">function</span>(X,sigma,beta){
  N <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">NROW</span>(X)
  K <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">matrix</span>(<span style="color:#ae81ff">0</span>,N,N)
  <span style="color:#a6e22e">for </span>(i in <span style="color:#ae81ff">1</span><span style="color:#f92672">:</span>N) {
    <span style="color:#a6e22e">for </span>(k in <span style="color:#ae81ff">1</span><span style="color:#f92672">:</span>N) {
      <span style="color:#a6e22e">if</span>(i<span style="color:#f92672">==</span>k) kdelta <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span> else kdelta <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
      K[i,k] <span style="color:#f92672">&lt;-</span> K[k,i] <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">exp</span>(<span style="color:#f92672">-</span><span style="color:#a6e22e">t</span>(X[i,]<span style="color:#f92672">-</span>X[k,])<span style="color:#f92672">%*%</span>(X[i,]<span style="color:#f92672">-</span>X[k,])<span style="color:#f92672">/</span>(<span style="color:#ae81ff">2</span><span style="color:#f92672">*</span>sigma^2)) <span style="color:#f92672">+</span> beta^{<span style="color:#ae81ff">-1</span>}<span style="color:#f92672">*</span>kdelta
    }
  }
  <span style="color:#a6e22e">return</span>(K)
}

N <span style="color:#f92672">&lt;-</span> <span style="color:#ae81ff">10</span> <span style="color:#75715e"># max value of X</span>
M <span style="color:#f92672">&lt;-</span> <span style="color:#ae81ff">1000</span> <span style="color:#75715e"># sample size</span>
X <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">matrix</span>(<span style="color:#a6e22e">seq</span>(<span style="color:#ae81ff">1</span>,N,length<span style="color:#f92672">=</span>M),M,<span style="color:#ae81ff">1</span>) <span style="color:#75715e"># create X</span>
testK <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">Kernel_Mat</span>(X,<span style="color:#ae81ff">0.5</span>,<span style="color:#ae81ff">1e+18</span>) <span style="color:#75715e"># calc kernel matrix</span>

<span style="color:#a6e22e">library</span>(MASS)

P <span style="color:#f92672">&lt;-</span> <span style="color:#ae81ff">6</span> <span style="color:#75715e"># num of sample path</span>
Y <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">matrix</span>(<span style="color:#ae81ff">0</span>,M,P) <span style="color:#75715e"># define Y</span>

<span style="color:#a6e22e">for</span>(i in <span style="color:#ae81ff">1</span><span style="color:#f92672">:</span>P){
  Y[,i] <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">mvrnorm</span>(n<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,<span style="color:#a6e22e">rep</span>(<span style="color:#ae81ff">0</span>,M),testK) <span style="color:#75715e"># sample Y</span>
}

<span style="color:#75715e"># Plot</span>
<span style="color:#a6e22e">matplot</span>(x<span style="color:#f92672">=</span>X,y<span style="color:#f92672">=</span>Y,type <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;l&#34;</span>,lwd <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>)
</code></pre></div><p>\normalsize<img src="../../../en/post/post1/index_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>　The covariance matrix <code>\(K\)</code> between the elements of <code>\(\displaystyle \textbf{y}\)</code>, <code>\(\displaystyle y_{i}  = \textbf{w}^{T}\phi(x_{i})\)</code> is calculated using the kernel method from the input <code>\(x\)</code>. Then, from this <code>\(K\)</code> and average 0, we generate six series of multivariate normal random numbers and plot them.As these series are computed from a covariance matrix, we model that <strong>the more positive the covariance of each element, the more likely they are to be the same</strong>. Also, as you can see in the graphs, the graphs are very smooth and very flexible in their representation. The code samples and plots 1000 input points, limiting the input to 0 to 10 due to computational cost, but in principle, <code>\(x\)</code> is defined in the real number space, so <code>\(p(\textbf{y})\)</code> follows an infinite dimensional multivariate normal distribution.</p>
<p>As described above, since <code>\(\displaystyle \textbf{y}\)</code> is assumed to follow a Gaussian process, <code>\(p(\textbf{y})\)</code> follows a multivariate normal distribution <code>\(N(\textbf{y}|0,K)\)</code> with simultaneous probability <code>\(p(\textbf{y})\)</code> averaging 0 and the variance covariance matrix <code>\(K\)</code>. Each element <code>\(K_{i,j}\)</code> of <code>\(K\)</code> is</p>
<p>$$
<code>\begin{eqnarray} K_{i,j} &amp;=&amp; cov[y_{i},y_{j}] = cov[\textbf{w}\phi(x_{i}),\textbf{w}\phi(x_{j})] \\ &amp;=&amp;\phi(x_{i})\phi(x_{j})cov[\textbf{w},\textbf{w}]=\phi(x_{i})\phi(x_{j})\alpha \end{eqnarray}</code>
$$</p>
<p>Here, the <code>\(\phi(x_{i})\phi(x_{j})\alpha\)</code> is more expensive <strong>as the dimensionality of the <code>\(\phi(x_{i})\)</code> is increased</strong> (i.e., the more non-linear transformation is applied, the less the calculation is completed). However, when the kernel function <code>\(k(x,x')\)</code> is used, the computational complexity is higher in the dimensions of the sample size of the input data <code>\(x_{i},x_{j}\)</code>, so the computation becomes easier. There are several types of kernel functions, but the following Gaussian kernels are commonly used.</p>
<p>$$
k(x,x') = a \exp(-b(x-x')^{2})
$$</p>
<p>Now that we have defined the concurrent probability of <code>\(\displaystyle \textbf{y}\)</code>, we can find the joint probability of <code>\(\displaystyle \textbf{t}\)</code>.</p>
<p>$$
<code>\begin{eqnarray} \displaystyle p(\textbf{t}) &amp;=&amp; \int p(\textbf{t}|\textbf{y})p(\textbf{y}) d\textbf{y} \\ \displaystyle &amp;=&amp; \int N(\textbf{t}|\textbf{y},\beta^{-1}\textbf{I}_{N})N(\textbf{y}|0,K)d\textbf{y} \\ &amp;=&amp; N(\textbf{y}|0,\textbf{C}_{N}) \end{eqnarray}</code>
$$</p>
<p>where <code>\(\textbf{C}_{N} = K + \beta^{-1}\beta^{I}_{N}\)</code>. Note that the last expression expansion uses the regenerative nature of the normal distribution (the proof can be easily derived from the moment generating function of the normal distribution). The point is just to say that the covariance is the sum of the covariances of the two distributions, since they are independent. Personally, I imagine that <code>\(p(\textbf{y})\)</code> is the prior distribution of the Gaussian process I just described, <code>\(p(\textbf{t}|\textbf{y})\)</code> is the likelihood function, and <code>\(p(\textbf{t})\)</code> is the posterior distribution. The only constraint on the prior distribution <code>\(p(\textbf{y})\)</code> is that it is smooth with a loosely constrained distribution.
The joint probability of <code>\(N\)</code> observable teacher data <code>\(\textbf{t}\)</code> and <code>\(t_{N+1}\)</code> is</p>
<p>$$
p(\textbf{t},t_{N+1}) = N(\textbf{t},t_{N+1}|0,\textbf{C}_{N+1})
$$</p>
<p>where <code>\(\textbf{C}_{N+1}\)</code> is</p>
<p>$$
\textbf{C}<em>{N+1} = \left(
\begin{array}{cccc}
\textbf{C}</em>{N} &amp; \textbf{k} \<br>
\textbf{k}^{T} &amp; c \<br>
\end{array}
\right)
$$</p>
<p>where <code>\(\textbf{k} = (k(x_{1},x_{N+1}),...,k(x_{N},x_{N+1}))\)</code> and <code>\(c = k(x_{N+1},x_{N+1})\)</code>. The conditional distribution <code>\(p(t_{N+1}|\textbf{t})\)</code> can be obtained from the joint distribution of <code>\(\textbf{t}\)</code> and <code>\(t_{N+1}\)</code>.</p>
<p>$$
p(t_{N+1}|\textbf{t}) = N(t_{N+1}|\textbf{k}^{T}\textbf{C}_{N+1}^{-1}\textbf{t},c-\textbf{k}^{T}\textbf{C}_{N+1}^{-1}\textbf{k})
$$</p>
<p>In calculating the conditional distribution, we use <a href="https://qiita.com/kilometer/items/34249479dc2ac3af5706" target="_blank" rel="noopener">Properties of the conditional multivariate normal distribution</a>. As you can see from the above equation, the conditional distribution <code>\(p(t_{N+1}|\textbf{t})\)</code> can be calculated if <code>\(N+1\)</code> input data, <code>\(N\)</code> teacher data, and parameters <code>\(a,b\)</code> of the kernel function are known, so if any point is given as input data, it is possible to approximate the Generating Process. The nice thing about the <code>GPR</code> is that it gives predictions without the direct estimation of the above defined probabilistic model <code>\(\displaystyle y_{i}  = \textbf{w}^{T}\phi(x_{i})\)</code>. The stochastic model has <code>\(\phi(x_{i})\)</code>, which converts the input data to a high-dimensional vector through a nonlinear transformation. Therefore, the higher the dimensionality, the larger the computational complexity of the <code>\(\phi(x_{i})\phi(x_{j})\alpha\)</code> will be, but the <code>GPR</code> uses a kernel trick, so the computational complexity of the sample size dimension of the input data vector will be sufficient.</p>
<h2 id="2-implementation-of-the-gpr">2. Implementation of the `GPR'</h2>
<p>　For now, let&rsquo;s implement this in <code>R</code>, which I&rsquo;ve implemented in PRML test data, so I tweaked it.
　
\normalsize</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r"><span style="color:#a6e22e">library</span>(ggplot2)
<span style="color:#a6e22e">library</span>(grid)

<span style="color:#75715e"># 1.Gaussian Process Regression</span>

<span style="color:#75715e"># PRML&#39;s synthetic data set</span>
curve_fitting <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">data.frame</span>(
  x<span style="color:#f92672">=</span><span style="color:#a6e22e">c</span>(<span style="color:#ae81ff">0.000000</span>,<span style="color:#ae81ff">0.111111</span>,<span style="color:#ae81ff">0.222222</span>,<span style="color:#ae81ff">0.333333</span>,<span style="color:#ae81ff">0.444444</span>,<span style="color:#ae81ff">0.555556</span>,<span style="color:#ae81ff">0.666667</span>,<span style="color:#ae81ff">0.777778</span>,<span style="color:#ae81ff">0.888889</span>,<span style="color:#ae81ff">1.000000</span>),
  t<span style="color:#f92672">=</span><span style="color:#a6e22e">c</span>(<span style="color:#ae81ff">0.349486</span>,<span style="color:#ae81ff">0.830839</span>,<span style="color:#ae81ff">1.007332</span>,<span style="color:#ae81ff">0.971507</span>,<span style="color:#ae81ff">0.133066</span>,<span style="color:#ae81ff">0.166823</span>,<span style="color:#ae81ff">-0.848307</span>,<span style="color:#ae81ff">-0.445686</span>,<span style="color:#ae81ff">-0.563567</span>,<span style="color:#ae81ff">0.261502</span>))

f <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">function</span>(beta, sigma, xmin, xmax, input, train) {
  kernel <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">function</span>(x1, x2) <span style="color:#a6e22e">exp</span>(<span style="color:#f92672">-</span>(x1<span style="color:#f92672">-</span>x2)^2<span style="color:#f92672">/</span>(<span style="color:#ae81ff">2</span><span style="color:#f92672">*</span>sigma^2)); <span style="color:#75715e"># define Kernel function</span>
  K <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">outer</span>(input, input, kernel); <span style="color:#75715e"># calc gram matrix</span>
  C_N <span style="color:#f92672">&lt;-</span> K <span style="color:#f92672">+</span> <span style="color:#a6e22e">diag</span>(<span style="color:#a6e22e">length</span>(input))<span style="color:#f92672">/</span>beta
  m <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">function</span>(x) (<span style="color:#a6e22e">outer</span>(x, input, kernel) <span style="color:#f92672">%*%</span> <span style="color:#a6e22e">solve</span>(C_N) <span style="color:#f92672">%*%</span> train) <span style="color:#75715e"># coditiona mean </span>
  m_sig <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">function</span>(x)(<span style="color:#a6e22e">kernel</span>(x,x) <span style="color:#f92672">-</span> <span style="color:#a6e22e">diag</span>(<span style="color:#a6e22e">outer</span>(x, input, kernel) <span style="color:#f92672">%*%</span> <span style="color:#a6e22e">solve</span>(C_N) <span style="color:#f92672">%*%</span> <span style="color:#a6e22e">t</span>(<span style="color:#a6e22e">outer</span>(x, input, kernel)))) <span style="color:#75715e">#conditional variance</span>
  x <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">seq</span>(xmin,xmax,length<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>)
  output <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">ggplot</span>(<span style="color:#a6e22e">data.frame</span>(x1<span style="color:#f92672">=</span>x,m<span style="color:#f92672">=</span><span style="color:#a6e22e">m</span>(x),sig1<span style="color:#f92672">=</span><span style="color:#a6e22e">m</span>(x)<span style="color:#ae81ff">+1.96</span><span style="color:#f92672">*</span><span style="color:#a6e22e">sqrt</span>(<span style="color:#a6e22e">m_sig</span>(x)),sig2<span style="color:#f92672">=</span><span style="color:#a6e22e">m</span>(x)<span style="color:#ae81ff">-1.96</span><span style="color:#f92672">*</span><span style="color:#a6e22e">sqrt</span>(<span style="color:#a6e22e">m_sig</span>(x)),
                              tx<span style="color:#f92672">=</span>input,ty<span style="color:#f92672">=</span>train),
                   <span style="color:#a6e22e">aes</span>(x<span style="color:#f92672">=</span>x1,y<span style="color:#f92672">=</span>m)) <span style="color:#f92672">+</span> 
    <span style="color:#a6e22e">geom_line</span>() <span style="color:#f92672">+</span>
    <span style="color:#a6e22e">geom_ribbon</span>(<span style="color:#a6e22e">aes</span>(ymin<span style="color:#f92672">=</span>sig1,ymax<span style="color:#f92672">=</span>sig2),alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>) <span style="color:#f92672">+</span>
    <span style="color:#a6e22e">geom_point</span>(<span style="color:#a6e22e">aes</span>(x<span style="color:#f92672">=</span>tx,y<span style="color:#f92672">=</span>ty))
  <span style="color:#a6e22e">return</span>(output)
}

<span style="color:#a6e22e">grid.newpage</span>() <span style="color:#75715e"># make a palet</span>
<span style="color:#a6e22e">pushViewport</span>(<span style="color:#a6e22e">viewport</span>(layout<span style="color:#f92672">=</span><span style="color:#a6e22e">grid.layout</span>(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>))) <span style="color:#75715e"># divide the palet into 2 by 2</span>
<span style="color:#a6e22e">print</span>(<span style="color:#a6e22e">f</span>(<span style="color:#ae81ff">100</span>,<span style="color:#ae81ff">0.1</span>,<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">1</span>,curve_fitting<span style="color:#f92672">$</span>x,curve_fitting<span style="color:#f92672">$</span>t), vp<span style="color:#f92672">=</span><span style="color:#a6e22e">viewport</span>(layout.pos.row<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, layout.pos.col<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>))
<span style="color:#a6e22e">print</span>(<span style="color:#a6e22e">f</span>(<span style="color:#ae81ff">4</span>,<span style="color:#ae81ff">0.10</span>,<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">1</span>,curve_fitting<span style="color:#f92672">$</span>x,curve_fitting<span style="color:#f92672">$</span>t), vp<span style="color:#f92672">=</span><span style="color:#a6e22e">viewport</span>(layout.pos.row<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, layout.pos.col<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>))
<span style="color:#a6e22e">print</span>(<span style="color:#a6e22e">f</span>(<span style="color:#ae81ff">25</span>,<span style="color:#ae81ff">0.30</span>,<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">1</span>,curve_fitting<span style="color:#f92672">$</span>x,curve_fitting<span style="color:#f92672">$</span>t), vp<span style="color:#f92672">=</span><span style="color:#a6e22e">viewport</span>(layout.pos.row<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, layout.pos.col<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>))
<span style="color:#a6e22e">print</span>(<span style="color:#a6e22e">f</span>(<span style="color:#ae81ff">25</span>,<span style="color:#ae81ff">0.030</span>,<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">1</span>,curve_fitting<span style="color:#f92672">$</span>x,curve_fitting<span style="color:#f92672">$</span>t), vp<span style="color:#f92672">=</span><span style="color:#a6e22e">viewport</span>(layout.pos.row<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, layout.pos.col<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)) 
</code></pre></div><p>\normalsize<img src="../../../en/post/post1/index_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>The <code>\(beta^{-1}\)</code> represents the measurement error. The higher the value of <strong>$\beta$ (i.e., the smaller the measurement error), the easier it is to overfit, since the error of the predictions is less than that of the data already available.</strong> This is the case in the top left corner of the figure above. The top left corner is <code>\(\beta=400\)</code>, which means that it overfits the current data available. Conversely, a small value of <code>\(\beta\)</code> will produce predictions that ignore the errors with the teacher data, but may improve the generalization performance. The top right figure shows this. For <code>\(beta=4\)</code>, the average barely passes through the data points we have, and <code>\(b\)</code> is currently available. <code>\(b\)</code> represents the magnitude of the effect of the data we have at the moment on the surroundings. If <code>\(b\)</code> is small, the adjacent points will interact strongly with each other, which may reduce the accuracy but increase the generalization performance. Conversely, if <code>\(b\)</code> is large, the result will be unnatural, fitting only individual points. This is illustrated in the figure below right ($b=\frac{1}{0.03}, \beta=25$). As you can see, the graph is overfitting because of the large <code>\(\beta\)</code> and because <code>\(b\)</code> is also large, so it fits only individual points, resulting in an absurdly large graph. The bottom left graph is the best. It has <code>\(b=\frac{1}{0.3}\)</code>, and <code>\(b=2\)</code>. Let&rsquo;s try extending the x interval of this graph to [0,2]. Then we get the following graph.</p>
<p>\normalsize</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r"><span style="color:#a6e22e">grid.newpage</span>() <span style="color:#75715e"># make a palet</span>
<span style="color:#a6e22e">pushViewport</span>(<span style="color:#a6e22e">viewport</span>(layout<span style="color:#f92672">=</span><span style="color:#a6e22e">grid.layout</span>(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>))) <span style="color:#75715e"># divide the palet into 2 by 2</span>
<span style="color:#a6e22e">print</span>(<span style="color:#a6e22e">f</span>(<span style="color:#ae81ff">100</span>,<span style="color:#ae81ff">0.1</span>,<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">2</span>,curve_fitting<span style="color:#f92672">$</span>x,curve_fitting<span style="color:#f92672">$</span>t), vp<span style="color:#f92672">=</span><span style="color:#a6e22e">viewport</span>(layout.pos.row<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, layout.pos.col<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)) 
<span style="color:#a6e22e">print</span>(<span style="color:#a6e22e">f</span>(<span style="color:#ae81ff">4</span>,<span style="color:#ae81ff">0.10</span>,<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">2</span>,curve_fitting<span style="color:#f92672">$</span>x,curve_fitting<span style="color:#f92672">$</span>t), vp<span style="color:#f92672">=</span><span style="color:#a6e22e">viewport</span>(layout.pos.row<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, layout.pos.col<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)) 
<span style="color:#a6e22e">print</span>(<span style="color:#a6e22e">f</span>(<span style="color:#ae81ff">25</span>,<span style="color:#ae81ff">0.30</span>,<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">2</span>,curve_fitting<span style="color:#f92672">$</span>x,curve_fitting<span style="color:#f92672">$</span>t), vp<span style="color:#f92672">=</span><span style="color:#a6e22e">viewport</span>(layout.pos.row<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, layout.pos.col<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>))
<span style="color:#a6e22e">print</span>(<span style="color:#a6e22e">f</span>(<span style="color:#ae81ff">25</span>,<span style="color:#ae81ff">0.030</span>,<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">2</span>,curve_fitting<span style="color:#f92672">$</span>x,curve_fitting<span style="color:#f92672">$</span>t), vp<span style="color:#f92672">=</span><span style="color:#a6e22e">viewport</span>(layout.pos.row<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, layout.pos.col<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)) 
</code></pre></div><p>\normalsize<img src="../../../en/post/post1/index_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>As you can see, all the graphs except the bottom left one have a band of 95% confidence intervals that immediately widen and are completely useless where there are no data points. On the other hand, the lower left graph has a decent band up to 1.3 to 1.4, and the average value seems to pass through a point that is consistent with our intuitive understanding of the function. You can also see that if you are too far away from the observable data points, you will get a normal distribution with a mean of 0 and a variance of 1 no matter what you give to the parameters.
Now that we have shown that the accuracy of the prediction of the out-sample varies depending on the value of the parameters, the question here is how to estimate these hyperparameters. This is done by using the gradient method to find the hyperparameters that maximize the log-likelihood function <code>\(\ln p(\bf{t}|a,b)\)</code> (($\beta$ seems to be of a slightly different type, and the developmental discussion appears to take other tuning methods. We haven&rsquo;t gotten to that level yet, so we&rsquo;ll calibrate it here).  Since <code>\(p(\textbf{t}) = N(\textbf{y}|0, \textbf{C}_{N})\)</code>, the log-likelihood function is</p>
<p>$$
\displaystyle \ln p(\textbf{t}|a,b,\beta) = -\frac{1}{2}\ln|\textbf{C}<em>{N}| - \frac{N}{2}\ln(2\pi) - \frac{1}{2}\textbf{t}^{T}\textbf{C}</em>{N}^{-1}\textbf{k}
$$</p>
<p>After that, we can differentiate this with the parameters and solve the obtained simultaneous equations to get the maximum likelihood estimator. Now let&rsquo;s get the derivatives.</p>
<p>$$
\displaystyle \frac{\partial}{\partial \theta_{i}} \ln p(\textbf{t}|\theta) = -\frac{1}{2}Tr(\textbf{C}_{N}^{-1}\frac{\partial \textbf{C}_{N}}{\partial \theta_{i}}) + \frac{1}{2}\textbf{t}^{T}\textbf{C}_{N}^{-1}
\frac{\partial\textbf{C}_{N}}{\partial\theta_{i}}\textbf{C}_{N}^{-1}\textbf{t}
$$</p>
<p>where <code>\(theta\)</code> is the parameter set and <code>\(theta_{i}\)</code> represents the <code>\(i\)</code>th parameter. If you don&rsquo;t understand this derivative [here](<a href="http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning">http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning</a> %20-%20Springer%20Springer%20%202006.pdf) in the supplement to (C.21) and (C.22) equations. Since we are using the Gaussian kernel in this case, we get</p>
<p>$$
\displaystyle \frac{\partial k(x,x')}{\partial a} = \exp(-b(x-x')^{2}) \<br>
\displaystyle \frac{\partial k(x,x')}{\partial b} = -a(x-x')^{2}\exp(-b(x-x')^{2})
$$</p>
<p>from the above formula. However, this time we will use the gradient method to find the best parameters. Here&rsquo;s the code for the implementation (it&rsquo;s pretty much a lost cause).</p>
<p>\normalsize</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-r" data-lang="r">g <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">function</span>(xmin, xmax, input, train){
  <span style="color:#75715e"># initial value</span>
  beta <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span>
  b <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
  a <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
  learning_rate <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.1</span>
  itermax <span style="color:#f92672">&lt;-</span> <span style="color:#ae81ff">1000</span>
  <span style="color:#a6e22e">if </span>(<span style="color:#a6e22e">class</span>(input) <span style="color:#f92672">==</span> <span style="color:#e6db74">&#34;numeric&#34;</span>){
    N <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">length</span>(input)
  } else
  {
    N <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">NROW</span>(input)
  }
  kernel <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">function</span>(x1, x2) a<span style="color:#f92672">*</span><span style="color:#a6e22e">exp</span>(<span style="color:#ae81ff">-0.5</span><span style="color:#f92672">*</span>b<span style="color:#f92672">*</span>(x1<span style="color:#f92672">-</span>x2)^2); <span style="color:#75715e"># define kernel</span>
  derivative_a <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">function</span>(x1,x2) <span style="color:#a6e22e">exp</span>(<span style="color:#ae81ff">-0.5</span><span style="color:#f92672">*</span>b<span style="color:#f92672">*</span>(x1<span style="color:#f92672">-</span>x2)^2)
  derivative_b <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">function</span>(x1,x2) <span style="color:#ae81ff">-0.5</span><span style="color:#f92672">*</span>a<span style="color:#f92672">*</span>(x1<span style="color:#f92672">-</span>x2)^2<span style="color:#f92672">*</span><span style="color:#a6e22e">exp</span>(<span style="color:#ae81ff">-0.5</span><span style="color:#f92672">*</span>b<span style="color:#f92672">*</span>(x1<span style="color:#f92672">-</span>x2)^2)
  dloglik_a <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">function</span>(C_N,y,x1,x2) {
    <span style="color:#f92672">-</span><span style="color:#a6e22e">sum</span>(<span style="color:#a6e22e">diag</span>(<span style="color:#a6e22e">solve</span>(C_N)<span style="color:#f92672">%*%</span><span style="color:#a6e22e">outer</span>(input, input, derivative_a)))<span style="color:#f92672">+</span><span style="color:#a6e22e">t</span>(y)<span style="color:#f92672">%*%</span><span style="color:#a6e22e">solve</span>(C_N)<span style="color:#f92672">%*%</span><span style="color:#a6e22e">outer</span>(input, input, derivative_a)<span style="color:#f92672">%*%</span><span style="color:#a6e22e">solve</span>(C_N)<span style="color:#f92672">%*%</span>y 
  }
  dloglik_b <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">function</span>(C_N,y,x1,x2) {
    <span style="color:#f92672">-</span><span style="color:#a6e22e">sum</span>(<span style="color:#a6e22e">diag</span>(<span style="color:#a6e22e">solve</span>(C_N)<span style="color:#f92672">%*%</span><span style="color:#a6e22e">outer</span>(input, input, derivative_b)))<span style="color:#f92672">+</span><span style="color:#a6e22e">t</span>(y)<span style="color:#f92672">%*%</span><span style="color:#a6e22e">solve</span>(C_N)<span style="color:#f92672">%*%</span><span style="color:#a6e22e">outer</span>(input, input, derivative_b)<span style="color:#f92672">%*%</span><span style="color:#a6e22e">solve</span>(C_N)<span style="color:#f92672">%*%</span>y 
  }
  <span style="color:#75715e"># loglikelihood function</span>
  likelihood <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">function</span>(b,a,x,y){
    kernel <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">function</span>(x1, x2) a<span style="color:#f92672">*</span><span style="color:#a6e22e">exp</span>(<span style="color:#ae81ff">-0.5</span><span style="color:#f92672">*</span>b<span style="color:#f92672">*</span>(x1<span style="color:#f92672">-</span>x2)^2)
    K <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">outer</span>(x, x, kernel)
    C_N <span style="color:#f92672">&lt;-</span> K <span style="color:#f92672">+</span> <span style="color:#a6e22e">diag</span>(N)<span style="color:#f92672">/</span>beta
    itermax <span style="color:#f92672">&lt;-</span> <span style="color:#ae81ff">1000</span>
    l <span style="color:#f92672">&lt;-</span> <span style="color:#ae81ff">-1</span><span style="color:#f92672">/</span><span style="color:#ae81ff">2</span><span style="color:#f92672">*</span><span style="color:#a6e22e">log</span>(<span style="color:#a6e22e">det</span>(C_N)) <span style="color:#f92672">-</span> N<span style="color:#f92672">/</span><span style="color:#ae81ff">2</span><span style="color:#f92672">*</span>(<span style="color:#ae81ff">2</span><span style="color:#f92672">*</span><span style="color:#66d9ef">pi</span>) <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span><span style="color:#f92672">/</span><span style="color:#ae81ff">2</span><span style="color:#f92672">*</span><span style="color:#a6e22e">t</span>(y)<span style="color:#f92672">%*%</span><span style="color:#a6e22e">solve</span>(C_N)<span style="color:#f92672">%*%</span>y
    <span style="color:#a6e22e">return</span>(l)
  }
  K <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">outer</span>(input, input, kernel) 
  C_N <span style="color:#f92672">&lt;-</span> K <span style="color:#f92672">+</span> <span style="color:#a6e22e">diag</span>(N)<span style="color:#f92672">/</span>beta
  <span style="color:#a6e22e">for </span>(i in <span style="color:#ae81ff">1</span><span style="color:#f92672">:</span>itermax){
    kernel <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">function</span>(x1, x2) a<span style="color:#f92672">*</span><span style="color:#a6e22e">exp</span>(<span style="color:#f92672">-</span>b<span style="color:#f92672">*</span>(x1<span style="color:#f92672">-</span>x2)^2)
    derivative_b <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">function</span>(x1,x2) <span style="color:#ae81ff">-0.5</span><span style="color:#f92672">*</span>a<span style="color:#f92672">*</span>(x1<span style="color:#f92672">-</span>x2)^2<span style="color:#f92672">*</span><span style="color:#a6e22e">exp</span>(<span style="color:#ae81ff">-0.5</span><span style="color:#f92672">*</span>b<span style="color:#f92672">*</span>(x1<span style="color:#f92672">-</span>x2)^2)
    dloglik_b <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">function</span>(C_N,y,x1,x2) {
      <span style="color:#f92672">-</span><span style="color:#a6e22e">sum</span>(<span style="color:#a6e22e">diag</span>(<span style="color:#a6e22e">solve</span>(C_N)<span style="color:#f92672">%*%</span><span style="color:#a6e22e">outer</span>(input, input, derivative_b)))<span style="color:#f92672">+</span><span style="color:#a6e22e">t</span>(y)<span style="color:#f92672">%*%</span><span style="color:#a6e22e">solve</span>(C_N)<span style="color:#f92672">%*%</span><span style="color:#a6e22e">outer</span>(input, input, derivative_b)<span style="color:#f92672">%*%</span><span style="color:#a6e22e">solve</span>(C_N)<span style="color:#f92672">%*%</span>y 
    }
    K <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">outer</span>(input, input, kernel) <span style="color:#75715e"># calc gram matrix</span>
    C_N <span style="color:#f92672">&lt;-</span> K <span style="color:#f92672">+</span> <span style="color:#a6e22e">diag</span>(N)<span style="color:#f92672">/</span>beta
    l <span style="color:#f92672">&lt;-</span> <span style="color:#ae81ff">0</span>
    <span style="color:#a6e22e">if</span>(<span style="color:#a6e22e">abs</span>(l<span style="color:#f92672">-</span><span style="color:#a6e22e">likelihood</span>(b,a,input,train))<span style="color:#f92672">&lt;</span><span style="color:#ae81ff">0.0001</span><span style="color:#f92672">&amp;</span>i<span style="color:#f92672">&gt;</span><span style="color:#ae81ff">2</span>){
      break
    }else{
      a <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">as.numeric</span>(a <span style="color:#f92672">+</span> learning_rate<span style="color:#f92672">*</span><span style="color:#a6e22e">dloglik_a</span>(C_N,train,input,input))
      b <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">as.numeric</span>(b <span style="color:#f92672">+</span> learning_rate<span style="color:#f92672">*</span><span style="color:#a6e22e">dloglik_b</span>(C_N,train,input,input))
    }
    l <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">likelihood</span>(b,a,input,train)
  }
  K <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">outer</span>(input, input, kernel)
  C_N <span style="color:#f92672">&lt;-</span> K <span style="color:#f92672">+</span> <span style="color:#a6e22e">diag</span>(<span style="color:#a6e22e">length</span>(input))<span style="color:#f92672">/</span>beta
  m <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">function</span>(x) (<span style="color:#a6e22e">outer</span>(x, input, kernel) <span style="color:#f92672">%*%</span> <span style="color:#a6e22e">solve</span>(C_N) <span style="color:#f92672">%*%</span> train)  
  m_sig <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">function</span>(x)(<span style="color:#a6e22e">kernel</span>(x,x) <span style="color:#f92672">-</span> <span style="color:#a6e22e">diag</span>(<span style="color:#a6e22e">outer</span>(x, input, kernel) <span style="color:#f92672">%*%</span> <span style="color:#a6e22e">solve</span>(C_N) <span style="color:#f92672">%*%</span> <span style="color:#a6e22e">t</span>(<span style="color:#a6e22e">outer</span>(x, input, kernel))))
  x <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">seq</span>(xmin,xmax,length<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>)
  output <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">ggplot</span>(<span style="color:#a6e22e">data.frame</span>(x1<span style="color:#f92672">=</span>x,m<span style="color:#f92672">=</span><span style="color:#a6e22e">m</span>(x),sig1<span style="color:#f92672">=</span><span style="color:#a6e22e">m</span>(x)<span style="color:#ae81ff">+1.96</span><span style="color:#f92672">*</span><span style="color:#a6e22e">sqrt</span>(<span style="color:#a6e22e">m_sig</span>(x)),sig2<span style="color:#f92672">=</span><span style="color:#a6e22e">m</span>(x)<span style="color:#ae81ff">-1.96</span><span style="color:#f92672">*</span><span style="color:#a6e22e">sqrt</span>(<span style="color:#a6e22e">m_sig</span>(x)),
                              tx<span style="color:#f92672">=</span>input,ty<span style="color:#f92672">=</span>train),
                   <span style="color:#a6e22e">aes</span>(x<span style="color:#f92672">=</span>x1,y<span style="color:#f92672">=</span>m)) <span style="color:#f92672">+</span> 
    <span style="color:#a6e22e">geom_line</span>() <span style="color:#f92672">+</span>
    <span style="color:#a6e22e">geom_ribbon</span>(<span style="color:#a6e22e">aes</span>(ymin<span style="color:#f92672">=</span>sig1,ymax<span style="color:#f92672">=</span>sig2),alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.2</span>) <span style="color:#f92672">+</span>
    <span style="color:#a6e22e">geom_point</span>(<span style="color:#a6e22e">aes</span>(x<span style="color:#f92672">=</span>tx,y<span style="color:#f92672">=</span>ty))
  <span style="color:#a6e22e">return</span>(output)
}

<span style="color:#a6e22e">print</span>(<span style="color:#a6e22e">g</span>(<span style="color:#ae81ff">0</span>,<span style="color:#ae81ff">1</span>,curve_fitting<span style="color:#f92672">$</span>x,curve_fitting<span style="color:#f92672">$</span>t), vp<span style="color:#f92672">=</span><span style="color:#a6e22e">viewport</span>(layout.pos.row<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, layout.pos.col<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>))
</code></pre></div><p>\normalsize<img src="../../../en/post/post1/index_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>Yes, it does sound like good (lol).
That&rsquo;s it for today, for now.</p>

          </div>

          






<div class="article-tags">
  
  <a class="badge badge-light" href="../../../en/tag/r/">R</a>
  
</div>



<div class="share-box" aria-hidden="true">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=../../../en/post/post1/&amp;text=Implementing%20Gaussian%20regression." target="_blank" rel="noopener" class="share-btn-twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=/en/post/post1/&amp;t=Implementing%20Gaussian%20regression." target="_blank" rel="noopener" class="share-btn-facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=Implementing%20Gaussian%20regression.&amp;body=/en/post/post1/" target="_blank" rel="noopener" class="share-btn-email">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=../../../en/post/post1/&amp;title=Implementing%20Gaussian%20regression." target="_blank" rel="noopener" class="share-btn-linkedin">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="whatsapp://send?text=Implementing%20Gaussian%20regression.%20/en/post/post1/" target="_blank" rel="noopener" class="share-btn-whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=../../../en/post/post1/&amp;title=Implementing%20Gaussian%20regression." target="_blank" rel="noopener" class="share-btn-weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>











  
  



  
  
  
    
  
  
  
  <div class="media author-card content-widget-hr">
    
      
      <a href="../../../"><img class="avatar mr-3 avatar-circle" src="../../../en/author/ayato-ashihara/avatar_hu77c0c0affdebd3b9cbda9c39412092b5_245163_270x270_fill_q90_lanczos_center.jpg" alt="Ayato Ashihara"></a>
    

    <div class="media-body">
      <h5 class="card-title"><a href="../../../">Ayato Ashihara</a></h5>
      <h6 class="card-subtitle">company employee</h6>
      <p class="card-text">This blog is a nightly update by a man who is working in his forth year since completing graduate school. The content of this blog has nothing to do with the official position of the author&rsquo;s organization.</p>
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="../../../en/#contact" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.facebook.com/ASSIY" target="_blank" rel="noopener">
        <i class="fab fa-facebook"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/AyatoAshihara/myblog_multi" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.linkedin.com/in/%E5%BD%A9%E4%BA%BA-%E8%91%A6%E5%8E%9F-9391b7143/" target="_blank" rel="noopener">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>







<section id="comments">
  
    
<div id="disqus_thread"></div>
<script>
  let disqus_config = function () {
    
    
    
  };
  (function() {
    if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
      document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
      return;
    }
    var d = document, s = d.createElement('script'); s.async = true;
    s.src = 'https://' + "ayatoashihara-github-io-myblog-multi" + '.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>


  
</section>




<div class="article-widget">
  
<div class="post-nav">
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Next</div>
    <a href="../../../en/post/post2/" rel="next">I built the Asset Allocation Model in R.</a>
  </div>
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Previous</div>
    <a href="../../../en/post/post4/" rel="prev">It&#39;s nice to meet you.</a>
  </div>
  
</div>

</div>





  
  
  <div class="article-widget content-widget-hr">
    <h3>Related</h3>
    <ul>
      
      <li><a href="../../../en/post/post14/">Fitting the 10-year long-term interest rate</a></li>
      
      <li><a href="../../../en/post/post21/">Rcpp to speed up data handling (using Tick data processing as an example)</a></li>
      
      <li><a href="../../../en/post/post11/">Scraping past race results on yahoo horse racing on rvest (for the second time)</a></li>
      
      <li><a href="../../../en/post/post2/">I built the Asset Allocation Model in R.</a></li>
      
      <li><a href="../../../en/post/post22/">Get macro panel data from OECD.org via API</a></li>
      
    </ul>
  </div>
  





        </div>
      </article>
    </main>

  </div>
</div>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js" integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin="anonymous"></script>

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.8.0/mermaid.min.js" integrity="sha512-ja+hSBi4JDtjSqc4LTBsSwuBT3tdZ3oKYKd07lTVYmCnTCor56AnRql00ssqnTOR9Ss4gOP/ROGB3SfcJnZkeg==" crossorigin="anonymous" title="mermaid"></script>
      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js" integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/latex.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/python.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/sql.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/cpp.min.js"></script>
        
      

    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.js" integrity="sha512-SeiQaaDh73yrb56sTW/RgVdi/mMqNeM2oBwubFHagc5BkixSpP1fvqF47mKzPGWYSSy4RwbBunrJBQ4Co8fRWA==" crossorigin="anonymous"></script>
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    
    
    
    
    <script>
      const search_config = {"indexURI":"/en/index.json","minLength":1,"threshold":0.3};
      const i18n = {"no_results":"No results found","placeholder":"Search...","results":"results found"};
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks",
        'slides' : "Slides"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    

    
    
    <script id="dsq-count-scr" src="https://ayatoashihara-github-io-myblog-multi.disqus.com/count.js" async></script>
    

    
    
    
    
    
    
    
    
    
      
    
    
      
    
    
    
    <script src="../../../js/wowchemy.min.2a3f95be2bc4762ba1847fb5d7a28317.js"></script>

    


  
  
  <div class="container">
    <footer class="site-footer">
  

  
   
  <script>
  $(document).ready(function () {
    window.initializeCodeFolding("show" === "show");
  });
  </script>
  <script src="../../../js/codefolding.js"></script>


  <p class="powered-by">
    
  </p>

  
  






  <p class="powered-by">
    
    Published with
    <a href="https://wowchemy.com" target="_blank" rel="noopener">Wowchemy</a>  —
    the free, <a href="https://github.com/wowchemy/wowchemy-hugo-modules" target="_blank" rel="noopener">
    open source</a> website builder that empowers creators.
    

    
    <span class="float-right" aria-hidden="true">
      <a href="#" class="back-to-top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
