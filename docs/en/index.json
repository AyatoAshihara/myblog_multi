[{"authors":null,"categories":null,"content":"I\u0026rsquo;m 26 years old, from Nara, Japan and currently in my third year of graduate studies. I majored in macroeconomics (mainly Dynamic Stochastic General Equilibruim models), and also experimented with time series analysis and text mining. Recently, I\u0026rsquo;m interested in data wrangling and am studying for certification to advance my career as an (infrastructure) engineer. Currently, I am working in the Investment Planning Group at an asset management company.\n","date":1522454400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1522454400,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/en/author/ayato-ashihara/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/author/ayato-ashihara/","section":"authors","summary":"I\u0026rsquo;m 26 years old, from Nara, Japan and currently in my third year of graduate studies. I majored in macroeconomics (mainly Dynamic Stochastic General Equilibruim models), and also experimented with time series analysis and text mining.","tags":null,"title":"Ayato Ashihara","type":"authors"},{"authors":null,"categories":null,"content":"Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026quot;Courses\u0026quot; url = \u0026quot;courses/\u0026quot; weight = 50  Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026quot;Docs\u0026quot; url = \u0026quot;docs/\u0026quot; weight = 50  Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"/en/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/en/courses/example/","section":"courses","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"/en/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/en/courses/example/example1/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"/en/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/en/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/en/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/en/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Academic Academic | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/en/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/en/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":["macroeconomics"],"content":"\r\r\r\r1. What is GPR?\r2. Implementation of the `GPR’\r\r\r　Hi. Yesterday, I wrote an article about Bayesian Vector Autoregression.\rIn the article, the topic of hyperparameter tuning came up, and looking for some efficient way to tune it, I found Bayesian Optimization. Since I am planning to use machine learning methods in daily GDP, I thought that Bayesian Optimization could be quite useful, and I spent all night yesterday to understand it.\nI will implement it here, but Bayesian Optimization uses Gaussian Pocess Regression (GPR), and my motivation for writing this entry was to implement it first. I will write about the implementation of Bayesian Optimization after this entry.\n1. What is GPR?\r　The GRP is, simply put, a type of nonlinear regression method using Bayesian estimation. Although the model itself is linear, it is characterized by its ability to estimate infinite nonlinear transformations of input variables using a kernel trick as explanatory variables (depending on what you choose for the kernel).\rThe GPR assumes that \\(N\\) input and teacher data are available for training, and the \\(N+1\\) of input data are also available. From this situation, we can predict the \\(N+1\\)th teacher data.\nThe data contains noise and follows the following probability model.\r\\[\rt_{i} = y_{i} + \\epsilon_{i}\r\\]\rwhere \\(t_{i}\\) is the \\(i\\)th observable teacher data (scalar), \\(y_{i}\\) is the unobservable output data (scalar), and \\(\\beta_{i}\\) follows a normal distribution \\(N(0, \\beta^{-1})\\) with measurement error. \\(y_{i}\\) follows the following probability model.\n\\[\r\\displaystyle y_{i} = \\textbf{w}^{T}\\phi(x_{i})\r\\]\nwhere \\(x_{i}\\) is the ith input data vector, \\(\\phi(・)\\) is the non-linear function and \\(\\bf{w}^{T}\\) is the weight coefficient (regression coefficient) vector for each input data. As a nonlinear function, I assume \\(\\psi(x_{i}) = (x_{1,i}, x_{1,i}^{2},... ,x_{1,i}x_{2,i},...)\\). (\\(x_{1,i}\\) is the first variable in the \\(i\\)th input data \\(x_{i}\\)). The conditional probability of obtaining \\(t_{i}\\) from the probabilistic model of the teacher data, with the \\(i\\)th output data \\(y_{i}\\) obtained, is\n\\[\rp(t_{i}|y_{i}) = N(t_{i}|y_{i},\\beta^{-1})\r\\]\n\\(\\displaystyle \\textbf{t} = (t_{1},... ,t_{n})^{T}\\) and \\(\\displaystyle \\textbf{y} = (y_{1},... ,y_{n})^{T}\\), then by extending the above equation, we have\n\\[\r\\displaystyle p(\\textbf{t}|\\textbf{y}) = N(\\textbf{t}|\\textbf{y},\\beta^{-1}\\textbf{I}_{N})\r\\]\nWe assume that the expected value of \\(\\textbf{w}\\) as a prior distribution is 0, and all variances are \\(\\alpha\\). We also assume that \\(\\displaystyle \\textbf{y}\\) follows a Gaussian process. A Gaussian process is one where the simultaneous distribution of \\(\\displaystyle \\textbf{y}\\) follows a multivariate Gaussian distribution. In code, it looks like this\n# Define Kernel function\rKernel_Mat \u0026lt;- function(X,sigma,beta){\rN \u0026lt;- NROW(X)\rK \u0026lt;- matrix(0,N,N)\rfor (i in 1:N) {\rfor (k in 1:N) {\rif(i==k) kdelta = 1 else kdelta = 0\rK[i,k] \u0026lt;- K[k,i] \u0026lt;- exp(-t(X[i,]-X[k,])%*%(X[i,]-X[k,])/(2*sigma^2)) + beta^{-1}*kdelta\r}\r}\rreturn(K)\r}\rN \u0026lt;- 10 # max value of X\rM \u0026lt;- 1000 # sample size\rX \u0026lt;- matrix(seq(1,N,length=M),M,1) # create X\rtestK \u0026lt;- Kernel_Mat(X,0.5,1e+18) # calc kernel matrix\rlibrary(MASS)\rP \u0026lt;- 6 # num of sample path\rY \u0026lt;- matrix(0,M,P) # define Y\rfor(i in 1:P){\rY[,i] \u0026lt;- mvrnorm(n=1,rep(0,M),testK) # sample Y\r}\r# Plot\rmatplot(x=X,y=Y,type = \u0026quot;l\u0026quot;,lwd = 2)\r　The covariance matrix \\(K\\) between the elements of \\(\\displaystyle \\textbf{y}\\), \\(\\displaystyle y_{i} = \\textbf{w}^{T}\\phi(x_{i})\\) is calculated using the kernel method from the input \\(x\\). Then, from this \\(K\\) and average 0, we generate six series of multivariate normal random numbers and plot them.As these series are computed from a covariance matrix, we model that the more positive the covariance of each element, the more likely they are to be the same. Also, as you can see in the graphs, the graphs are very smooth and very flexible in their representation. The code samples and plots 1000 input points, limiting the input to 0 to 10 due to computational cost, but in principle, \\(x\\) is defined in the real number space, so \\(p(\\textbf{y})\\) follows an infinite dimensional multivariate normal distribution.\nAs described above, since \\(\\displaystyle \\textbf{y}\\) is assumed to follow a Gaussian process, \\(p(\\textbf{y})\\) follows a multivariate normal distribution \\(N(\\textbf{y}|0,K)\\) with simultaneous probability \\(p(\\textbf{y})\\) averaging 0 and the variance covariance matrix \\(K\\). Each element \\(K_{i,j}\\) of \\(K\\) is\n\\[\r\\begin{eqnarray}\rK_{i,j} \u0026amp;=\u0026amp; cov[y_{i},y_{j}] = cov[\\textbf{w}\\phi(x_{i}),\\textbf{w}\\phi(x_{j})] \\\\\r\u0026amp;=\u0026amp;\\phi(x_{i})\\phi(x_{j})cov[\\textbf{w},\\textbf{w}]=\\phi(x_{i})\\phi(x_{j})\\alpha\r\\end{eqnarray}\r\\]\nHere, the \\(\\phi(x_{i})\\phi(x_{j})\\alpha\\) is more expensive as the dimensionality of the \\(\\phi(x_{i})\\) is increased (i.e., the more non-linear transformation is applied, the less the calculation is completed). However, when the kernel function \\(k(x,x\u0026#39;)\\) is used, the computational complexity is higher in the dimensions of the sample size of the input data \\(x_{i},x_{j}\\), so the computation becomes easier. There are several types of kernel functions, but the following Gaussian kernels are commonly used.\n\\[\rk(x,x\u0026#39;) = a \\exp(-b(x-x\u0026#39;)^{2})\r\\]\nNow that we have defined the concurrent probability of \\(\\displaystyle \\textbf{y}\\), we can find the joint probability of \\(\\displaystyle \\textbf{t}\\).\n\\[\r\\begin{eqnarray}\r\\displaystyle p(\\textbf{t}) \u0026amp;=\u0026amp; \\int p(\\textbf{t}|\\textbf{y})p(\\textbf{y}) d\\textbf{y} \\\\\r\\displaystyle \u0026amp;=\u0026amp; \\int N(\\textbf{t}|\\textbf{y},\\beta^{-1}\\textbf{I}_{N})N(\\textbf{y}|0,K)d\\textbf{y} \\\\\r\u0026amp;=\u0026amp; N(\\textbf{y}|0,\\textbf{C}_{N})\r\\end{eqnarray}\r\\]\nwhere \\(\\textbf{C}_{N} = K + \\beta^{-1}\\beta^{I}_{N}\\). Note that the last expression expansion uses the regenerative nature of the normal distribution (the proof can be easily derived from the moment generating function of the normal distribution). The point is just to say that the covariance is the sum of the covariances of the two distributions, since they are independent. Personally, I imagine that \\(p(\\textbf{y})\\) is the prior distribution of the Gaussian process I just described, \\(p(\\textbf{t}|\\textbf{y})\\) is the likelihood function, and \\(p(\\textbf{t})\\) is the posterior distribution. The only constraint on the prior distribution \\(p(\\textbf{y})\\) is that it is smooth with a loosely constrained distribution.\rThe joint probability of \\(N\\) observable teacher data \\(\\textbf{t}\\) and \\(t_{N+1}\\) is\n\\[\rp(\\textbf{t},t_{N+1}) = N(\\textbf{t},t_{N+1}|0,\\textbf{C}_{N+1})\r\\]\nwhere \\(\\textbf{C}_{N+1}\\) is\n\\[\r\\textbf{C}_{N+1} = \\left(\r\\begin{array}{cccc}\r\\textbf{C}_{N} \u0026amp; \\textbf{k} \\\\\r\\textbf{k}^{T} \u0026amp; c \\\\\r\\end{array}\r\\right)\r\\]\nwhere \\(\\textbf{k} = (k(x_{1},x_{N+1}),...,k(x_{N},x_{N+1}))\\) and \\(c = k(x_{N+1},x_{N+1})\\). The conditional distribution \\(p(t_{N+1}|\\textbf{t})\\) can be obtained from the joint distribution of \\(\\textbf{t}\\) and \\(t_{N+1}\\).\n\\[\rp(t_{N+1}|\\textbf{t}) = N(t_{N+1}|\\textbf{k}^{T}\\textbf{C}_{N+1}^{-1}\\textbf{t},c-\\textbf{k}^{T}\\textbf{C}_{N+1}^{-1}\\textbf{k})\r\\]\nIn calculating the conditional distribution, we use Properties of the conditional multivariate normal distribution. As you can see from the above equation, the conditional distribution \\(p(t_{N+1}|\\textbf{t})\\) can be calculated if \\(N+1\\) input data, \\(N\\) teacher data, and parameters \\(a,b\\) of the kernel function are known, so if any point is given as input data, it is possible to approximate the Generating Process. The nice thing about the GPR is that it gives predictions without the direct estimation of the above defined probabilistic model \\(\\displaystyle y_{i} = \\textbf{w}^{T}\\phi(x_{i})\\). The stochastic model has \\(\\phi(x_{i})\\), which converts the input data to a high-dimensional vector through a nonlinear transformation. Therefore, the higher the dimensionality, the larger the computational complexity of the \\(\\phi(x_{i})\\phi(x_{j})\\alpha\\) will be, but the GPR uses a kernel trick, so the computational complexity of the sample size dimension of the input data vector will be sufficient.\n\r2. Implementation of the `GPR’\r　For now, let’s implement this in R, which I’ve implemented in PRML test data, so I tweaked it.\rlibrary(ggplot2)\rlibrary(grid)\r# 1.Gaussian Process Regression\r# PRML\u0026#39;s synthetic data set\rcurve_fitting \u0026lt;- data.frame(\rx=c(0.000000,0.111111,0.222222,0.333333,0.444444,0.555556,0.666667,0.777778,0.888889,1.000000),\rt=c(0.349486,0.830839,1.007332,0.971507,0.133066,0.166823,-0.848307,-0.445686,-0.563567,0.261502))\rf \u0026lt;- function(beta, sigma, xmin, xmax, input, train) {\rkernel \u0026lt;- function(x1, x2) exp(-(x1-x2)^2/(2*sigma^2)); # define Kernel function\rK \u0026lt;- outer(input, input, kernel); # calc gram matrix\rC_N \u0026lt;- K + diag(length(input))/beta\rm \u0026lt;- function(x) (outer(x, input, kernel) %*% solve(C_N) %*% train) # coditiona mean m_sig \u0026lt;- function(x)(kernel(x,x) - diag(outer(x, input, kernel) %*% solve(C_N) %*% t(outer(x, input, kernel)))) #conditional variance\rx \u0026lt;- seq(xmin,xmax,length=100)\routput \u0026lt;- ggplot(data.frame(x1=x,m=m(x),sig1=m(x)+1.96*sqrt(m_sig(x)),sig2=m(x)-1.96*sqrt(m_sig(x)),\rtx=input,ty=train),\raes(x=x1,y=m)) + geom_line() +\rgeom_ribbon(aes(ymin=sig1,ymax=sig2),alpha=0.2) +\rgeom_point(aes(x=tx,y=ty))\rreturn(output)\r}\rgrid.newpage() # make a palet\rpushViewport(viewport(layout=grid.layout(2, 2))) # divide the palet into 2 by 2\rprint(f(100,0.1,0,1,curve_fitting$x,curve_fitting$t), vp=viewport(layout.pos.row=1, layout.pos.col=1))\rprint(f(4,0.10,0,1,curve_fitting$x,curve_fitting$t), vp=viewport(layout.pos.row=1, layout.pos.col=2))\rprint(f(25,0.30,0,1,curve_fitting$x,curve_fitting$t), vp=viewport(layout.pos.row=2, layout.pos.col=1))\rprint(f(25,0.030,0,1,curve_fitting$x,curve_fitting$t), vp=viewport(layout.pos.row=2, layout.pos.col=2)) \rThe \\(beta^{-1}\\) represents the measurement error. The higher the value of \\(\\beta\\) (i.e., the smaller the measurement error), the easier it is to overfit, since the error of the predictions is less than that of the data already available. This is the case in the top left corner of the figure above. The top left corner is \\(\\beta=400\\), which means that it overfits the current data available. Conversely, a small value of \\(\\beta\\) will produce predictions that ignore the errors with the teacher data, but may improve the generalization performance. The top right figure shows this. For \\(beta=4\\), the average barely passes through the data points we have, and \\(b\\) is currently available. \\(b\\) represents the magnitude of the effect of the data we have at the moment on the surroundings. If \\(b\\) is small, the adjacent points will interact strongly with each other, which may reduce the accuracy but increase the generalization performance. Conversely, if \\(b\\) is large, the result will be unnatural, fitting only individual points. This is illustrated in the figure below right (\\(b=\\frac{1}{0.03}, \\beta=25\\)). As you can see, the graph is overfitting because of the large \\(\\beta\\) and because \\(b\\) is also large, so it fits only individual points, resulting in an absurdly large graph. The bottom left graph is the best. It has \\(b=\\frac{1}{0.3}\\), and \\(b=2\\). Let’s try extending the x interval of this graph to [0,2]. Then we get the following graph.\ngrid.newpage() # make a palet\rpushViewport(viewport(layout=grid.layout(2, 2))) # divide the palet into 2 by 2\rprint(f(100,0.1,0,2,curve_fitting$x,curve_fitting$t), vp=viewport(layout.pos.row=1, layout.pos.col=1)) print(f(4,0.10,0,2,curve_fitting$x,curve_fitting$t), vp=viewport(layout.pos.row=1, layout.pos.col=2)) print(f(25,0.30,0,2,curve_fitting$x,curve_fitting$t), vp=viewport(layout.pos.row=2, layout.pos.col=1))\rprint(f(25,0.030,0,2,curve_fitting$x,curve_fitting$t), vp=viewport(layout.pos.row=2, layout.pos.col=2)) \rAs you can see, all the graphs except the bottom left one have a band of 95% confidence intervals that immediately widen and are completely useless where there are no data points. On the other hand, the lower left graph has a decent band up to 1.3 to 1.4, and the average value seems to pass through a point that is consistent with our intuitive understanding of the function. You can also see that if you are too far away from the observable data points, you will get a normal distribution with a mean of 0 and a variance of 1 no matter what you give to the parameters.\rNow that we have shown that the accuracy of the prediction of the out-sample varies depending on the value of the parameters, the question here is how to estimate these hyperparameters. This is done by using the gradient method to find the hyperparameters that maximize the log-likelihood function \\(\\ln p(\\bf{t}|a,b)\\) ((\\(\\beta\\) seems to be of a slightly different type, and the developmental discussion appears to take other tuning methods. We haven’t gotten to that level yet, so we’ll calibrate it here). Since \\(p(\\textbf{t}) = N(\\textbf{y}|0, \\textbf{C}_{N})\\), the log-likelihood function is\n\\[\r\\displaystyle \\ln p(\\textbf{t}|a,b,\\beta) = -\\frac{1}{2}\\ln|\\textbf{C}_{N}| - \\frac{N}{2}\\ln(2\\pi) - \\frac{1}{2}\\textbf{t}^{T}\\textbf{C}_{N}^{-1}\\textbf{k}\r\\]\nAfter that, we can differentiate this with the parameters and solve the obtained simultaneous equations to get the maximum likelihood estimator. Now let’s get the derivatives.\n\\[\r\\displaystyle \\frac{\\partial}{\\partial \\theta_{i}} \\ln p(\\textbf{t}|\\theta) = -\\frac{1}{2}Tr(\\textbf{C}_{N}^{-1}\\frac{\\partial \\textbf{C}_{N}}{\\partial \\theta_{i}}) + \\frac{1}{2}\\textbf{t}^{T}\\textbf{C}_{N}^{-1}\r\\frac{\\partial\\textbf{C}_{N}}{\\partial\\theta_{i}}\\textbf{C}_{N}^{-1}\\textbf{t}\r\\]\nwhere \\(theta\\) is the parameter set and \\(theta_{i}\\) represents the \\(i\\)th parameter. If you don’t understand this derivative here in the supplement to (C.21) and (C.22) equations. Since we are using the Gaussian kernel in this case, we get\n\\[\r\\displaystyle \\frac{\\partial k(x,x\u0026#39;)}{\\partial a} = \\exp(-b(x-x\u0026#39;)^{2}) \\\\\r\\displaystyle \\frac{\\partial k(x,x\u0026#39;)}{\\partial b} = -a(x-x\u0026#39;)^{2}\\exp(-b(x-x\u0026#39;)^{2})\r\\]\nfrom the above formula. However, this time we will use the gradient method to find the best parameters. Here’s the code for the implementation (it’s pretty much a lost cause).\ng \u0026lt;- function(xmin, xmax, input, train){\r# initial value\rbeta = 100\rb = 1\ra = 1\rlearning_rate = 0.1\ritermax \u0026lt;- 1000\rif (class(input) == \u0026quot;numeric\u0026quot;){\rN \u0026lt;- length(input)\r} else\r{\rN \u0026lt;- NROW(input)\r}\rkernel \u0026lt;- function(x1, x2) a*exp(-0.5*b*(x1-x2)^2); # define kernel\rderivative_a \u0026lt;- function(x1,x2) exp(-0.5*b*(x1-x2)^2)\rderivative_b \u0026lt;- function(x1,x2) -0.5*a*(x1-x2)^2*exp(-0.5*b*(x1-x2)^2)\rdloglik_a \u0026lt;- function(C_N,y,x1,x2) {\r-sum(diag(solve(C_N)%*%outer(input, input, derivative_a)))+t(y)%*%solve(C_N)%*%outer(input, input, derivative_a)%*%solve(C_N)%*%y }\rdloglik_b \u0026lt;- function(C_N,y,x1,x2) {\r-sum(diag(solve(C_N)%*%outer(input, input, derivative_b)))+t(y)%*%solve(C_N)%*%outer(input, input, derivative_b)%*%solve(C_N)%*%y }\r# loglikelihood function\rlikelihood \u0026lt;- function(b,a,x,y){\rkernel \u0026lt;- function(x1, x2) a*exp(-0.5*b*(x1-x2)^2)\rK \u0026lt;- outer(x, x, kernel)\rC_N \u0026lt;- K + diag(N)/beta\ritermax \u0026lt;- 1000\rl \u0026lt;- -1/2*log(det(C_N)) - N/2*(2*pi) - 1/2*t(y)%*%solve(C_N)%*%y\rreturn(l)\r}\rK \u0026lt;- outer(input, input, kernel) C_N \u0026lt;- K + diag(N)/beta\rfor (i in 1:itermax){\rkernel \u0026lt;- function(x1, x2) a*exp(-b*(x1-x2)^2)\rderivative_b \u0026lt;- function(x1,x2) -0.5*a*(x1-x2)^2*exp(-0.5*b*(x1-x2)^2)\rdloglik_b \u0026lt;- function(C_N,y,x1,x2) {\r-sum(diag(solve(C_N)%*%outer(input, input, derivative_b)))+t(y)%*%solve(C_N)%*%outer(input, input, derivative_b)%*%solve(C_N)%*%y }\rK \u0026lt;- outer(input, input, kernel) # calc gram matrix\rC_N \u0026lt;- K + diag(N)/beta\rl \u0026lt;- 0\rif(abs(l-likelihood(b,a,input,train))\u0026lt;0.0001\u0026amp;i\u0026gt;2){\rbreak\r}else{\ra \u0026lt;- as.numeric(a + learning_rate*dloglik_a(C_N,train,input,input))\rb \u0026lt;- as.numeric(b + learning_rate*dloglik_b(C_N,train,input,input))\r}\rl \u0026lt;- likelihood(b,a,input,train)\r}\rK \u0026lt;- outer(input, input, kernel)\rC_N \u0026lt;- K + diag(length(input))/beta\rm \u0026lt;- function(x) (outer(x, input, kernel) %*% solve(C_N) %*% train) m_sig \u0026lt;- function(x)(kernel(x,x) - diag(outer(x, input, kernel) %*% solve(C_N) %*% t(outer(x, input, kernel))))\rx \u0026lt;- seq(xmin,xmax,length=100)\routput \u0026lt;- ggplot(data.frame(x1=x,m=m(x),sig1=m(x)+1.96*sqrt(m_sig(x)),sig2=m(x)-1.96*sqrt(m_sig(x)),\rtx=input,ty=train),\raes(x=x1,y=m)) + geom_line() +\rgeom_ribbon(aes(ymin=sig1,ymax=sig2),alpha=0.2) +\rgeom_point(aes(x=tx,y=ty))\rreturn(output)\r}\rprint(g(0,1,curve_fitting$x,curve_fitting$t), vp=viewport(layout.pos.row=1, layout.pos.col=1))\rYes, it does sound like good (lol).\rThat’s it for today, for now.\n\r","date":1543708800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543708800,"objectID":"eb19f4601e090b622a80cdb28ae21cf8","permalink":"/en/post/post1/","publishdate":"2018-12-02T00:00:00Z","relpermalink":"/en/post/post1/","section":"post","summary":"I implemented the much talked about Gauss regression, which is too versatile to be fun in reverse.","tags":["R"],"title":"Implementing Gaussian regression.","type":"post"},{"authors":null,"categories":[],"content":"\r\r\rIt’s nice to meet you.\rMy name is Ayato Ashihara, and I’m a first-year graduate of an asset management company in Tokyo.\nI’d like to introduce myself briefly.\rI’m 24 years old and graduated from a graduate school.\rI majored in macroeconomics, especially DSGE models, state space models, Kalman filters, Bayesian estimation, and MCMC.\rI also did some natural language processing as research support for my advisor.\rI originally wanted to be an academic researcher, but due to financial problems, I had to find a job.\rNow I’m doing menial work in sales support.\nI think this blog will be a memorandum of my research hobby as I cannot give up my interest in research.\nI am currently working on the following two research projects.\nhorse betting version of the factor model\rquarterly GDP projection model\r\rThe first question is whether it is possible to create a model for constructing a horse betting portfolio that aims for a collection rate of over 100%, from the perspective that the horse betting market is more speculatively attractive than the stock market. For stocks, there is a factor model like Pharma French, but I would like to see if we can apply it to create a horse-trading version of the factor model.\nSecondly, we are aware of the problem of the low accuracy of the recent preliminary quarterly GDP report, so we wondered if it would be possible to construct a new, highly accurate forecasting model. In particular, I would like to use machine learning to create a model that incorporates data that is not normally used in macroeconomic research, rather than a model based on macroeconomic theory.\nWe’ve only just begun our research.\rI’ll do my best to keep you interested…\nBest regards.\n","date":1526601600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1526601600,"objectID":"ceb64c07c657dc4dad3f41bf7df6c579","permalink":"/en/post/post4/","publishdate":"2018-05-18T00:00:00Z","relpermalink":"/en/post/post4/","section":"post","summary":"Nice to meet you. I'd like to start this blog by introducing myself.","tags":[],"title":"It's nice to meet you.","type":"post"},{"authors":["Ayato Ashihara"],"categories":null,"content":" Click the Cite button above to get Bibtex and Cite ME !!   ","date":1522454400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1522454400,"objectID":"8eb0b83c007669e1fcaec626e70937a6","permalink":"/en/publication/%E7%B4%80%E8%A6%812019/","publishdate":"2018-03-31T00:00:00Z","relpermalink":"/en/publication/%E7%B4%80%E8%A6%812019/","section":"publication","summary":"Japan  has  experienced  a  long-lasting  stagnation  since  the  early  1990s.  According  to  the  Reference Dates of Business Cycle, the Cabinet Office of Japan, there are four recession periods between 1987 and 2010,  and  three  of  them  are  considered  to  be  financially-related.  This  implies  that  the  stagnation  wastriggered by financial factors. Nonetheless, many studies using Dynamic Stochastic General Equilibrium models claim that a decline in Total Factor Productivity is the main driver of the stagnation. To resolve this contradiction,  this study estimates the Japanese economy by a New-Keynesian  DSGE  model augmented with  financial  friction  used  in  Christiano,  Motto  and  Rostagno  (2014),  where “risk  shock”  is newly incorporated into the model that refers to uncertainty in the financial market. According to our estimationresults, the estimated risk shock can explain the overall fluctuations of GDP and investment, and thus it isconsidered to be the main driver of the stagnation. We also find that it is highly correlated with the Business condition  Diffusion  Index,  the  Financial  Position  Diffusion  Index  and  the  Lending  Attitude  Index  of  Financial Institutions in Tankan released by the Bank of Japan. Therefore, we conclude that the estimated risk  shock  can  be  interpreted  as  the  firms’   distrust  toward  their  business  conditions,  and  it  delayed  theirinvestment decisions, then causing the prolonged economic contraction.","tags":"","title":"Does Financial Risk Explain Japan’s Great Stagnation?","type":"publication"},{"authors":["Ayato Ashihara"],"categories":null,"content":" Click the Cite button above to get Bibtex and Cite ME !!   ","date":1488844800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1488844800,"objectID":"e1ffa3282e6f7fc6edad66690c0b404c","permalink":"/en/publication/ael2018/","publishdate":"2017-03-07T00:00:00Z","relpermalink":"/en/publication/ael2018/","section":"publication","summary":"Using Japanese financial data that provide enough observations under the good and bad regimes of financial conditions, we find that fiscal multipliers are smaller in the bad regime than in the good regime.","tags":[""],"title":"Is fiscal expansion more effective in a financial crisis?","type":"publication"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"/en/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/en/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"/en/project/internal-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/en/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Internal Project","type":"project"}]