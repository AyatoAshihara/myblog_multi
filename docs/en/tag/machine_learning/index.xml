<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>machine_learning | 京都の電子部品メーカーで働く社会人が研究に没頭するブログ</title>
    <link>/en/tag/machine_learning/</link>
      <atom:link href="/en/tag/machine_learning/index.xml" rel="self" type="application/rss+xml" />
    <description>machine_learning</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 12 Aug 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>machine_learning</title>
      <link>/en/tag/machine_learning/</link>
    </image>
    
    <item>
      <title>Automatically cropping the background of a horse body photo with Pytorch&#39;s Pre-trained model</title>
      <link>/en/post/post20/</link>
      <pubDate>Wed, 12 Aug 2020 00:00:00 +0000</pubDate>
      <guid>/en/post/post20/</guid>
      <description>&lt;p&gt;Hi. In the last post, I built a model to predict the order of a racehorse using CNN based on its body image. The results were not so good, and we needed to refine our analysis, especially when we analyzed the factors using &lt;code&gt;shap&lt;/code&gt; values, we found that the horses responded more to the stables in the background than to their bodies. This time, I would like to use Pytorch&amp;rsquo;s Pre-trained model to cut out the background from the horse photo and re-analyze the photo with only the horse body.&lt;/p&gt;
&lt;h2 id=&#34;1-downloading-the-pre-trained-model&#34;&gt;1. Downloading the pre-trained model&lt;/h2&gt;
&lt;p&gt;The code is adapted from &lt;a href=&#34;https://pytorch.org/hub/pytorch_vision_deeplabv3_resnet101/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;. First, install the packages.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; cv2
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; torch
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; torchvision
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; torchvision &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; transforms
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; glob
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; PIL &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Image
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; PIL
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; os
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Next, install the pre-trained model.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#Install a pre-trained model&lt;/span&gt;
device &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;device(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;cuda:0&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cuda&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;is_available() &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;cpu&amp;#34;&lt;/span&gt;)
model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torchvision&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;models&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;segmentation&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;deeplabv3_resnet101(pretrained&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to(device)
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;eval()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Apparently, all pre-trained models assume a mini-batch of 3-channel RGB images of shape &lt;code&gt;\((N, 3, H, W)\)&lt;/code&gt; normalized in the same way. Here, &lt;code&gt;\(N\)&lt;/code&gt; is assumed to be the number of images and &lt;code&gt;\(H\)&lt;/code&gt; and &lt;code&gt;\(W\)&lt;/code&gt; are assumed to be at least 224 pixels. The images need to be scaled to a range of [0, 1] and then normalized using the mean value = [0.485, 0.456, 0.406] and the standard value = [0.229, 0.224, 0.225]. So, we define a function that does the preprocessing.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#preprocessing&lt;/span&gt;
preprocess &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; transforms&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Compose([
    transforms&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ToTensor(),
    transforms&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Normalize(mean&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;0.485&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.456&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.406&lt;/span&gt;], std&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;0.229&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.224&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.225&lt;/span&gt;]),
])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;2-executing-the-background-deletion-process&#34;&gt;2. Executing the Background Deletion Process&lt;/h2&gt;
&lt;p&gt;Now, let&amp;rsquo;s load the images collected by the &lt;code&gt;selenium&lt;/code&gt; code in the previous post and remove the background one by one.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#Specify a folder&lt;/span&gt;
folders &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;listdir(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;C:\Users\aashi\umanalytics\photo\image&amp;#34;&lt;/span&gt;)

&lt;span style=&#34;color:#75715e&#34;&gt;#Reads an image from each folder and converts it to a numpy array of RGB values using the Image function&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i, folder &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; enumerate(folders):
  files &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; glob&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;glob(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;C:/Users/aashi/umanalytics/photo/image/&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; folder &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/*.jpg&amp;#34;&lt;/span&gt;)
  index &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; i
  &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; k, file &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; enumerate(files):
    img_array &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fromfile(file, dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;uint8)
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imdecode(img_array, cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;IMREAD_COLOR)
    h,w,_ &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; img&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape
    input_tensor &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; preprocess(img)
    input_batch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; input_tensor&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unsqueeze(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to(device)

    &lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;no_grad():
      output &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model(input_batch)[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;out&amp;#39;&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
    output_predictions &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; output&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argmax(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
    mask_array &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; output_predictions&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;byte()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cpu()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy()
    Image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fromarray(mask_array&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;255&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;save(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;C:\Users\aashi\umanalytics\photo\image\mask.jpg&amp;#39;&lt;/span&gt;)
    mask &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imread(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;C:\Users\aashi\umanalytics\photo\image\mask.jpg&amp;#39;&lt;/span&gt;)
    bg &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;full_like(img,&lt;span style=&#34;color:#ae81ff&#34;&gt;255&lt;/span&gt;)
    img &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;multiply(img&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(float), mask&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(float)&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;255&lt;/span&gt;)
    bg &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;multiply(bg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(float), &lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; mask&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(float)&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;255&lt;/span&gt;)
    outImage &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cv2&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(img, bg)
    Image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fromarray(outImage&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;uint8))&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;convert(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;L&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;save(file)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The following &lt;code&gt;mask&lt;/code&gt; image is output using the pre-trained model, and the &lt;code&gt;numpy&lt;/code&gt; array and the &lt;code&gt;mask&lt;/code&gt; image are merged to create a background delete image. The output looks like the following.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gray()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;))
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(img)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(mask)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(outImage)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;../../../en/post/post20/index_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;1920&#34; /&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;close()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Here&amp;rsquo;s what the folders look like. Some of them are handled well and some of them show the trainer. I know there is a way to identify the objects and &lt;code&gt;mask&lt;/code&gt; only the horses, but this model doesn&amp;rsquo;t allow for object labeling, so we&amp;rsquo;ll continue with that.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;maskhorse.PNG&#34; alt=&#34;folder&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;3-analysis-using-cnn&#34;&gt;3. Analysis using CNN&lt;/h2&gt;
&lt;p&gt;Here is the same content as in the previous article. I will only post the results.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## Test accuracy: 0.0
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;## &amp;lt;sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay object at 0x000000002F791188&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&#34;../../../en/post/post20/index_files/figure-html/unnamed-chunk-10-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The results have been disastrous.
I have not been able to identify it at all. Aren&amp;rsquo;t there any characteristics in the horse photos that would predict the rankings? Or is it that there is no variation in the photos of the horses in G1 races and it is impossible to identify them? Either way, it seems a bit harsh.&lt;/p&gt;
&lt;h2 id=&#34;4-interpretation-of-results-using-shap-values&#34;&gt;4. Interpretation of results using Shap values&lt;/h2&gt;
&lt;p&gt;As before, let&amp;rsquo;s see how it fails using the &lt;code&gt;shap&lt;/code&gt; value. We will use this image as an example.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(X_test[&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;])
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;../../../en/post/post20/index_files/figure-html/unnamed-chunk-11-5.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;close()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; shap
background &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; X_resampled[np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;choice(X_resampled&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;],&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;,replace&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)]

e &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; shap&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;GradientExplainer(model,background)

shap_values &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; e&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shap_values(X_test[[&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;]])
shap&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image_plot(shap_values[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;],X_test[[&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;]])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;../../../en/post/post20/index_files/figure-html/unnamed-chunk-12-7.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;They seem to be evaluating from the paws to the face. Surprisingly, they do not seem to be evaluating the buttocks.
I would like to try to visualize which aspect of the image is captured in each layer.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; keras &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; models

layer_outputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [layer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;output &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; layer &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers[:&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;]]
layer_names &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; layer &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers[:&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;]:
    layer_names&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(layer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;name)
images_per_row &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;

activation_model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; models&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Model(inputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;input, outputs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;layer_outputs)
activations &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; activation_model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(X_train[[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]])

&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; layer_name, layer_activation &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; zip(layer_names, activations):
    n_features &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; layer_activation&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]

    size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; layer_activation&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]

    n_cols &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; n_features &lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt; images_per_row
    display_grid &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros((size &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; n_cols, images_per_row &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; size))

    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; col &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(n_cols):
        &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; row &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(images_per_row):
            channel_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; layer_activation[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,
                                             :, :,
                                             col &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; images_per_row &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; row]
            channel_image &lt;span style=&#34;color:#f92672&#34;&gt;-=&lt;/span&gt; channel_image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean()
            channel_image &lt;span style=&#34;color:#f92672&#34;&gt;/=&lt;/span&gt; channel_image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;std()
            channel_image &lt;span style=&#34;color:#f92672&#34;&gt;*=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;
            channel_image &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;128&lt;/span&gt;
            channel_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;clip(channel_image, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;255&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;uint8&amp;#39;&lt;/span&gt;)
            display_grid[col &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; size : (col &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; size,
                         row &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; size : (row &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; size] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; channel_image

    scale &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1.&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; size
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(scale &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; display_grid&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;],
                        scale &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; display_grid&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]))
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(layer_name)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;grid(False)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(display_grid, cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;viridis&amp;#39;&lt;/span&gt;)
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;close()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;../../../en/post/post20/index_files/figure-html/unnamed-chunk-13-9.png&#34; width=&#34;1536&#34; /&gt;&lt;img src=&#34;../../../en/post/post20/index_files/figure-html/unnamed-chunk-13-10.png&#34; width=&#34;1536&#34; /&gt;&lt;img src=&#34;../../../en/post/post20/index_files/figure-html/unnamed-chunk-13-11.png&#34; width=&#34;1536&#34; /&gt;&lt;img src=&#34;../../../en/post/post20/index_files/figure-html/unnamed-chunk-13-12.png&#34; width=&#34;1536&#34; /&gt;&lt;img src=&#34;../../../en/post/post20/index_files/figure-html/unnamed-chunk-13-13.png&#34; width=&#34;1536&#34; /&gt;&lt;img src=&#34;../../../en/post/post20/index_files/figure-html/unnamed-chunk-13-14.png&#34; width=&#34;1536&#34; /&gt;&lt;img src=&#34;../../../en/post/post20/index_files/figure-html/unnamed-chunk-13-15.png&#34; width=&#34;1536&#34; /&gt;&lt;img src=&#34;../../../en/post/post20/index_files/figure-html/unnamed-chunk-13-16.png&#34; width=&#34;1536&#34; /&gt;&lt;img src=&#34;../../../en/post/post20/index_files/figure-html/unnamed-chunk-13-17.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I still can&amp;rsquo;t understand this one.&lt;/p&gt;
&lt;h2 id=&#34;5summary&#34;&gt;5.Summary&lt;/h2&gt;
&lt;p&gt;I removed the stable background and rerun it, but the results were the same - it was a good experience using PyTorch and removing the background, but not with any results, so I&amp;rsquo;ll stop with the horse photos for now.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>I predicted the standings based on horse photos using CNN.</title>
      <link>/en/post/post18/</link>
      <pubDate>Sun, 05 Jul 2020 00:00:00 +0000</pubDate>
      <guid>/en/post/post18/</guid>
      <description>&lt;p&gt;Hi. This time I would like to write an article about predicting horse racing. In the last post, I created a prediction model for horse racing rankings using table data obtained from yahoo horse racing using &lt;code&gt;LightGBM&lt;/code&gt;. I used structural data last time, but anyone can do this kind of analysis in these days. So this time, I developed a &lt;code&gt;Convolutional Neural Network&lt;/code&gt; (CNN) which extracts features from a horse&amp;rsquo;s body image and predicts its ranking. This is the second time I&amp;rsquo;ve used &lt;code&gt;Earth Engine&lt;/code&gt; to analyze satellite images, and the first time I&amp;rsquo;ve used deep learning in this blog. The code is written in Python.&lt;/p&gt;
&lt;h2 id=&#34;1-crawling-for-data-collection&#34;&gt;1. Crawling for data collection&lt;/h2&gt;
&lt;p&gt;The first step is to collect images of the horse&amp;rsquo;s body from the internet; the best thing to do would be to use pictures of the paddock on race day. However, as far as I&amp;rsquo;ve been able to find, there are no sites that post photos of the paddock in a cohesive format. It may be interesting to use it as a clipped image or to apply it as a video to the &lt;code&gt;Encoder-Decoder&lt;/code&gt; model of CNN to RNN, because it may be that a horse racing fan may have a paddock video on Youtube. However, I don&amp;rsquo;t have the ability to do that much.&lt;/p&gt;
&lt;h3 id=&#34;where-to-get-the-data-from&#34;&gt;Where to get the data from&lt;/h3&gt;
&lt;p&gt;So in this case, the data is taken from &lt;a href=&#34;https://www.daily.co.jp/horse/horsecheck/photo/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Daley&amp;rsquo;s Web site&lt;/a&gt;. Here you can find pre-race photos of horses running in the last 1 year? You can find pre-race photos of horses running in G1 races in the past year? Horse bettors who can&amp;rsquo;t go to the actual racecourse can look at these pictures and analyze the condition of the horses.&lt;br&gt;
Please note that this site does not include body photos of all the horses that are entered in the race. Also, since this is only a limited number of G1 races, it&amp;rsquo;s entirely possible that all the horses are finished to begin with, and it&amp;rsquo;s entirely possible that you won&amp;rsquo;t be able to tell the difference. However, I&amp;rsquo;ll make it a priority to try and do it quickly and use this data for this one.&lt;/p&gt;
&lt;h3 id=&#34;running-crawling-by-selenium&#34;&gt;Running crawling by selenium&lt;/h3&gt;
&lt;p&gt;For crawling, we&amp;rsquo;ll use selenium. I won&amp;rsquo;t go into web crawling as I&amp;rsquo;m mainly using CNN in this article. The code I used is as follows.&lt;br&gt;
[Note] If you use the following codes, please do so at your own risk.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; selenium &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; webdriver
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; selenium.webdriver.chrome.options &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Options
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; selenium.webdriver.support.select &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Select
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; selenium.webdriver.common.by &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; By
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; selenium.webdriver.common.keys &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Keys
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; selenium.webdriver.common.alert &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Alert
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; selenium.webdriver.support.ui &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; WebDriverWait
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; selenium.webdriver.support &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; expected_conditions &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; EC
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; selenium.common.exceptions &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; TimeoutException
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; selenium.webdriver.common.action_chains &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; ActionChains
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; time &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; sleep
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; urllib &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; request
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; random

&lt;span style=&#34;color:#75715e&#34;&gt;# selenium option settings (spell)&lt;/span&gt;
options &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Options()
options&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_argument(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;--disable-gpu&amp;#39;&lt;/span&gt;);
options&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_argument(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;--disable-extensions&amp;#39;&lt;/span&gt;);
options&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_argument(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;--proxy-server=&amp;#34;direct://&amp;#34;&amp;#39;&lt;/span&gt;);
options&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_argument(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;--proxy-bypass-list=*&amp;#39;&lt;/span&gt;);
options&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_argument(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;--start-maximized&amp;#39;&lt;/span&gt;);

&lt;span style=&#34;color:#75715e&#34;&gt;# driver specification&lt;/span&gt;
DRIVER_PATH &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;C:/Users/aashi/Desktop/chromedriver_win32/chromedriver.exe&amp;#39;&lt;/span&gt;
driver &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; webdriver&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Chrome(executable_path&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;DRIVER_PATH, chrome_options&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;options)

&lt;span style=&#34;color:#75715e&#34;&gt;# Pass the url and go to the site&lt;/span&gt;
url &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;https://www.daily.co.jp/horse/horsecheck/photo/&amp;#39;&lt;/span&gt;
driver&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(url)
driver&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;implicitly_wait(&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;) &lt;span style=&#34;color:#75715e&#34;&gt;# Maximum time to wait for an object to load, and if this is exceeded, an error&lt;/span&gt;
sleep(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;) &lt;span style=&#34;color:#75715e&#34;&gt;# 1 second sleep as the web page transition is performed&lt;/span&gt;

&lt;span style=&#34;color:#75715e&#34;&gt;# Image data is saved for each race.&lt;/span&gt;
selector0 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;body &amp;gt; div &amp;gt; main &amp;gt; div &amp;gt; div.primaryContents &amp;gt; article &amp;gt; div &amp;gt; section &amp;gt; a&amp;#34;&lt;/span&gt;
elements &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; driver&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;find_elements_by_css_selector(selector0)
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,len(elements)):
  elements &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; driver&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;find_elements_by_css_selector(selector0)
  element &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; elements[i]
  element&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;click()
  sleep(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;) &lt;span style=&#34;color:#75715e&#34;&gt;# 5 seconds sleep as the web page transition is performed&lt;/span&gt;

  target &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; driver&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;find_element_by_link_text(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Ｇ１馬体診断写真集のTOP&amp;#39;&lt;/span&gt;)
  actions &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ActionChains(driver)
  actions&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;move_to_element(target)
  actions&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;perform()
  sleep(&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;) &lt;span style=&#34;color:#75715e&#34;&gt;# 5 seconds sleep as the web page transition is performed&lt;/span&gt;
  selector &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;body &amp;gt; div.wrapper.horse.is-fixedHeader.is-fixedAnimation &amp;gt; main &amp;gt; div &amp;gt; div.primaryContents &amp;gt; article &amp;gt; article &amp;gt; div.photoDetail-wrapper &amp;gt; section &amp;gt; div &amp;gt; figure&amp;#34;&lt;/span&gt;
  figures &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; driver&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;find_elements_by_css_selector(selector)
  download_dir &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;C:\Users\aashi\umanalytics\photo\image&amp;#39;&lt;/span&gt;
  selector &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;body &amp;gt; div &amp;gt; main &amp;gt; div &amp;gt; div.primaryContents &amp;gt; article &amp;gt; article &amp;gt; div.photoDetail-wrapper &amp;gt; section &amp;gt; h1&amp;#34;&lt;/span&gt;
  race_name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; driver&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;find_element_by_css_selector(selector)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;text
  &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; figure &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; figures:
    img_name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; figure&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;find_element_by_tag_name(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;figcaption&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;text
    horse_src &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; figure&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;find_element_by_tag_name(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;img&amp;#39;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_attribute(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;src&amp;#34;&lt;/span&gt;)    
    save_name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; download_dir &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; race_name &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;_&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; img_name &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;.jpg&amp;#39;&lt;/span&gt;
    request&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;urlretrieve(horse_src,save_name)
  driver&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;back()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The saved images were cross-checked with the actual race results and manually divided into the top three groups and the rest of the groups. The images are saved as follows.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;horse_photo.PNG&#34; alt=&#34;Stored Horse Image&#34;&gt;&lt;/p&gt;
&lt;p&gt;This completes the collection of the original data.&lt;/p&gt;
&lt;h2 id=&#34;2-training-cnn-using-keras&#34;&gt;2. Training CNN using &lt;code&gt;Keras&lt;/code&gt;&lt;/h2&gt;
&lt;h3 id=&#34;what-is-keras&#34;&gt;What is Keras?&lt;/h3&gt;
&lt;p&gt;Now, let&amp;rsquo;s train CNN using &lt;code&gt;Keras&lt;/code&gt;. &lt;code&gt;Keras&lt;/code&gt; is one of the &lt;code&gt;Neural Network&lt;/code&gt; libraries that runs on &lt;code&gt;Tensorflow&lt;/code&gt; and &lt;code&gt;Theano&lt;/code&gt;. &lt;code&gt;Keras&lt;/code&gt; is one of the &lt;code&gt;Neural Network&lt;/code&gt; libraries that runs on &lt;code&gt;Tensorflow&lt;/code&gt; and &lt;code&gt;Theano&lt;/code&gt;. &lt;code&gt;Keras&lt;/code&gt; is characterized by its ability to build models with relatively short code and its many learning algorithms.&lt;/p&gt;
&lt;h3 id=&#34;what-is-cnn&#34;&gt;What is CNN?&lt;/h3&gt;
&lt;p&gt;CNN is a type of &lt;code&gt;(Deep) Neural Network&lt;/code&gt; often used in image analysis, and as its name suggests, it is an additional &lt;code&gt;convolution&lt;/code&gt;. Convolution is a process like the following.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn-ak.f.st-hatena.com/images/fotolife/t/tdualdir/20180501/20180501211957.png&#34; alt=&#34;Convolutional Layer Processing&#34;&gt;&lt;/p&gt;
&lt;p&gt;The input here is the image data. Image analysis recognizes and analyzes images as numerical values. The image on the computer is represented by the &lt;code&gt;RGB&lt;/code&gt; value, which is a numerical value from 0 to 255 of three colors, red (Red), green (Green) and blue (Blue). There are three layers of vectors in the form of 255 red, 0 green, 0 blue, and so on, and in this case a perfect red is represented. In the case above, you can think of a, b, c, etc. as representing one of the &lt;code&gt;RGB&lt;/code&gt; values of each pixel. Convolution calculates the features of an image by taking the inner product of these &lt;code&gt;RGB&lt;/code&gt; values with a matrix called the kernel. The following video(Japanese) is a good example of what the convolution layer means.&lt;/p&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/vU-JfZNBdYU&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;p&gt;By learning the kernel to successfully get the distinctive parts of that image, it is possible to identify the image. I think the convolutional layer is the most important part of the CNN.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://th.bing.com/th/id/OIP.F2Ik_XFzmu5jZF-byiAKQQHaCg?w=342&amp;amp;h=118&amp;amp;c=7&amp;amp;o=5&amp;amp;dpr=1.25&amp;amp;pid=1.7&#34; alt=&#34;The Big Picture of CNN&#34;&gt;&lt;/p&gt;
&lt;p&gt;As shown in the above figure, CNN has not only convolutional layers but also input and output layers as well as usual &lt;code&gt;Neural Network&lt;/code&gt; layers. If you want to know about the &lt;code&gt;MaxPooling&lt;/code&gt; layer, see the following movie(Japanese).&lt;/p&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/MLixg9K6oeU&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;p&gt;Although the gradient method is known as the most orthodox training method for deep learning, various extension algorithms such as &lt;code&gt;Adam&lt;/code&gt; have been proposed. Basically, &lt;code&gt;Adam&lt;/code&gt; or &lt;code&gt;momentum&lt;/code&gt; is often used.&lt;/p&gt;
&lt;h3 id=&#34;coding&#34;&gt;Coding&lt;/h3&gt;
&lt;p&gt;Now, let&amp;rsquo;s get to the coding.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; keras.utils &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; np_utils
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;## Using TensorFlow backend.
&lt;/code&gt;&lt;/pre&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; keras.models &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Sequential
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; keras.layers.convolutional &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; MaxPooling2D
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; keras.layers &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Activation, Conv2D, Flatten, Dense,Dropout
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; sklearn.model_selection &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; train_test_split
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; keras.optimizers &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; SGD, Adadelta, Adagrad, Adam, Adamax, RMSprop, Nadam
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; PIL &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Image
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; glob
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; time
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; os
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The first step is to convert the collected image data to numerical data to create the training data.
The directory structure is as follows, with the top image and other images being stored in separate directories. When we read in the images from each directory, we give a category variable of 1 for the top image and 0 for others.&lt;/p&gt;
&lt;p&gt;photograph of a horse&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;superior (in rank)&lt;/li&gt;
&lt;li&gt;Other&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#Specify a folder&lt;/span&gt;
folders &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; os&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;listdir(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;C:\Users\aashi\umanalytics\photo\image&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#75715e&#34;&gt;#Specify the total number of strokes (50 x 50 x 3 in this case).&lt;/span&gt;
image_size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;300&lt;/span&gt;
dense_size &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; len(folders)

X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []

&lt;span style=&#34;color:#75715e&#34;&gt;#Reads an image from each folder and converts it to a numpy array of RGB values using the Image function&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i, folder &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; enumerate(folders):
  files &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; glob&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;glob(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;C:/Users/aashi/umanalytics/photo/image/&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; folder &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/*.jpg&amp;#34;&lt;/span&gt;)
  index &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; i
  &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; k, file &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; enumerate(files):
    image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;open(file)
    image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;convert(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;L&amp;#34;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;convert(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;RGB&amp;#34;&lt;/span&gt;)
    image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;resize((image_size, image_size)) &lt;span style=&#34;color:#75715e&#34;&gt;#I&amp;#39;m dropping the number of pixels.&lt;/span&gt;
 
    data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;asarray(image)
    X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(data)
    Y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(index)

X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(X)
Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(Y)
X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;float32&amp;#39;&lt;/span&gt;)
X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; X &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255.0&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# Conversion to 0~1&lt;/span&gt;
X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape
Y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np_utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to_categorical(Y, dense_size)

&lt;span style=&#34;color:#75715e&#34;&gt;#splitting training data and test data&lt;/span&gt;
X_train, X_test, y_train, y_test &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_test_split(X, Y, test_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.20&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;I&amp;rsquo;ve been able to split the training data and the test data. What I&amp;rsquo;m considering now is a binary classification of &amp;ldquo;top&amp;rdquo; and &amp;ldquo;other&amp;rdquo;, but I defined &amp;ldquo;top&amp;rdquo; as the top 3, so the data is unbalanced (about 5 times as much other data as the top data). In this case, if we train on the data as it is, it is easier to predict the label with the larger sample size (in this case, &amp;ldquo;other&amp;rdquo;), and the model will have a bias. Therefore, it is necessary to adjust the training data so that the sample size is the same for each of the two classes.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;index_zero &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;choice(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;where(y_train[:,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;))[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,],np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;count_nonzero(y_train[:,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;),replace&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)
index_one &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;where(y_train[:,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
y_resampled &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; y_train[np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;hstack((index_one,index_zero))]
X_resampled &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; X_train[np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;hstack((index_one,index_zero))]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We will use this &lt;code&gt;y_resampled&lt;/code&gt; and &lt;code&gt;X_resampled&lt;/code&gt; for the training data. Next, we will build the CNN. In &lt;code&gt;Keras&lt;/code&gt;, a model is defined by specifying a &lt;code&gt;sequential model&lt;/code&gt; and adding a layer by &lt;code&gt;add&lt;/code&gt; method.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Sequential()
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(Conv2D(&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, (&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;,input_shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;X_train&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:]))
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(Activation(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;))
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(Conv2D(&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, (&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)))
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(Activation(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;))
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(MaxPooling2D(pool_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)))
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(Dropout(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.25&lt;/span&gt;))

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(Conv2D(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, (&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;), padding&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;same&amp;#39;&lt;/span&gt;))
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(Activation(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;))
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(Conv2D(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, (&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)))
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(Activation(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;))
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(MaxPooling2D(pool_size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)))
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(Dropout(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.25&lt;/span&gt;))

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(Flatten())
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;512&lt;/span&gt;))
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(Activation(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;relu&amp;#39;&lt;/span&gt;))
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(Dropout(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;))
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(Dense(dense_size))
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add(Activation(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;softmax&amp;#39;&lt;/span&gt;))

model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;## Model: &amp;quot;sequential_1&amp;quot;
## _________________________________________________________________
## Layer (type)                 Output Shape              Param #   
## =================================================================
## conv2d_1 (Conv2D)            (None, 300, 300, 32)      896       
## _________________________________________________________________
## activation_1 (Activation)    (None, 300, 300, 32)      0         
## _________________________________________________________________
## conv2d_2 (Conv2D)            (None, 298, 298, 32)      9248      
## _________________________________________________________________
## activation_2 (Activation)    (None, 298, 298, 32)      0         
## _________________________________________________________________
## max_pooling2d_1 (MaxPooling2 (None, 149, 149, 32)      0         
## _________________________________________________________________
## dropout_1 (Dropout)          (None, 149, 149, 32)      0         
## _________________________________________________________________
## conv2d_3 (Conv2D)            (None, 149, 149, 64)      18496     
## _________________________________________________________________
## activation_3 (Activation)    (None, 149, 149, 64)      0         
## _________________________________________________________________
## conv2d_4 (Conv2D)            (None, 147, 147, 64)      36928     
## _________________________________________________________________
## activation_4 (Activation)    (None, 147, 147, 64)      0         
## _________________________________________________________________
## max_pooling2d_2 (MaxPooling2 (None, 73, 73, 64)        0         
## _________________________________________________________________
## dropout_2 (Dropout)          (None, 73, 73, 64)        0         
## _________________________________________________________________
## flatten_1 (Flatten)          (None, 341056)            0         
## _________________________________________________________________
## dense_1 (Dense)              (None, 512)               174621184 
## _________________________________________________________________
## activation_5 (Activation)    (None, 512)               0         
## _________________________________________________________________
## dropout_3 (Dropout)          (None, 512)               0         
## _________________________________________________________________
## dense_2 (Dense)              (None, 2)                 1026      
## _________________________________________________________________
## activation_6 (Activation)    (None, 2)                 0         
## =================================================================
## Total params: 174,687,778
## Trainable params: 174,687,778
## Non-trainable params: 0
## _________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now, let&amp;rsquo;s get to the learning part. We&amp;rsquo;ll use &lt;code&gt;Adadelta&lt;/code&gt; for the algorithm. I don&amp;rsquo;t really understand it.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;optimizers &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Adadelta&amp;#34;&lt;/span&gt;
results &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {}
epochs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;50&lt;/span&gt;
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;compile(loss&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;categorical_crossentropy&amp;#39;&lt;/span&gt;, optimizer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;optimizers, metrics&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;accuracy&amp;#39;&lt;/span&gt;])
results &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(X_resampled, y_resampled, validation_split&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;, epochs&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;epochs)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;undersampling-for-unbalanced-data-adjustment&#34;&gt;Undersampling for unbalanced data adjustment&lt;/h3&gt;
&lt;p&gt;From here, we perform binary classification with Test data, but since we are undersampling the training data, we have an undersampled sample selection bias when calculating the prediction probability. The paper is available &lt;a href=&#34;https://www3.nd.edu/~dial/publications/dalpozzolo2015calibrating.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Therefore, I would like to formulate this part of the problem here, although a correction is needed. I will describe the current binary classification problem as the problem of predicting the objective variable &lt;code&gt;\(Y\)&lt;/code&gt;, which takes a binary value from the explanatory thousand &lt;code&gt;\(X\)&lt;/code&gt;. Let &lt;code&gt;\((X,Y)\)&lt;/code&gt; be a dataset where the positive example is considerably less than the negative example and the sample size of the negative example is matched to the positive example as &lt;code&gt;\((X_s,Y_s)\)&lt;/code&gt;. We define a categorical variable &lt;code&gt;\(s\)&lt;/code&gt; that takes 1 if the &lt;code&gt;\((X,Y)\)&lt;/code&gt; sample set is also included in &lt;code&gt;\((X_s,Y_s)\)&lt;/code&gt; and 0 if it is not.
Given an explanatory variable &lt;code&gt;\(x\)&lt;/code&gt; to the model constructed using the dataset &lt;code&gt;\((X,Y)\)&lt;/code&gt;, the positive example and the conditional probability of predicting can be expressed as &lt;code&gt;\(P(y=1|x)\)&lt;/code&gt;. On the other hand, the conditional probability of predicting a positive example in a model constructed using &lt;code&gt;\((X_s,Y_s)\)&lt;/code&gt; can be expressed as &lt;code&gt;\(P(y=1|x)\)&lt;/code&gt; using Bayes&#39; theorem and the categorical variable &lt;code&gt;\(s\)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;$$
P(y=1|x,s=1) = \frac{P(s=1|y=1)P(y=1|x)}{P(s=1|y=1)P(y=1|x) + P(s=1|y=0)P(y=0|x)}
$$
It can be written as. Since &lt;code&gt;\((X_s,Y_s)\)&lt;/code&gt; matches the sample size of the negative example to the positive example, &lt;code&gt;\(P(s=1,y=1)=1\)&lt;/code&gt;, the above formula is rewritten as&lt;/p&gt;
&lt;p&gt;$$
P(y=1|x,s=1) = \frac{P(y=1|x)}{P(y=1|x) + P(s=1|y=0)P(y=0|x)}
= \frac{P(y=1|x)}{P(y=1|x) + P(s=1|y=0)(1-P(y=1|x))}
$$
It is self-evident from the definition of &lt;code&gt;\((X_s,Y_s)\)&lt;/code&gt; that &lt;code&gt;\(P(s=1|y=0)\neq0\)&lt;/code&gt; (0 would result in unbalanced data with only positive examples). Thus, as long as &lt;code&gt;\(P(y=0,x) \neq0\)&lt;/code&gt;, the probability that the undersampling model will be rejected as a positive example is positively biased against the probability that the original data set will produce. What we want to find is &lt;code&gt;\(P(y=1|x)\)&lt;/code&gt; with no bias, so &lt;code&gt;\(P=P(y=1|x),P_s=P(y|x,s=1),\beta=P(s=1,y=0)\)&lt;/code&gt;, then we can get&lt;/p&gt;
&lt;p&gt;$$
P = \frac{\beta P_s}{\beta P_s-P_s+1}
$$
and can use this relationship formula to correct for bias.
Let&amp;rsquo;s define what we&amp;rsquo;ve just identified as a function.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;calibration&lt;/span&gt;(y_proba, beta):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; y_proba &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; (y_proba &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; y_proba) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; beta)

sampling_rate &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sum(y_train[:,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; sum(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;y_train[:,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
y_proba_calib &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; calibration(model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(X_test), sampling_rate)
y_pred &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np_utils&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;to_categorical(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argmax(y_proba_calib,axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;), dense_size)

&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; sklearn.metrics &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; confusion_matrix, ConfusionMatrixDisplay, accuracy_score
score &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; accuracy_score(y_test, y_pred)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Test accuracy:&amp;#39;&lt;/span&gt;, score)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;## Test accuracy: 0.3220338983050847
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It&amp;rsquo;s not good at all. I ran the &lt;code&gt;ConfusionMatrix&lt;/code&gt; and found out that it doesn&amp;rsquo;t work.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;ConfusionMatrixDisplay(confusion_matrix(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argmax(y_test,axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;), np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argmax(y_pred,axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)))&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;## &amp;lt;sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay object at 0x000000004A54CC88&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;../../../en/post/post18/index_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;close()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;I did a bias correction for the imbalance data, but the model is still very predictive of negative values. This doesn&amp;rsquo;t work.&lt;/p&gt;
&lt;h2 id=&#34;3-interpretation-of-results-using-shap-values&#34;&gt;3. Interpretation of results using Shap values&lt;/h2&gt;
&lt;p&gt;I would like to consider the &lt;code&gt;shap&lt;/code&gt; value of the model we just learned and interpret the results. I&amp;rsquo;ll add an explanation of the &lt;code&gt;shap&lt;/code&gt; value when I have time. Simply put, the visualization captures which parts of the image the CNN captured features and predicted the horse to be at the top. We&amp;rsquo;ll be analyzing this horse.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(X_test[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;../../../en/post/post18/index_files/figure-html/unnamed-chunk-14-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;close()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; shap
background &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; X_train[np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;choice(X_train&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;],&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;,replace&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)]

e &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; shap&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;GradientExplainer(model,background)

shap_values &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; e&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shap_values(X_test[[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]])
shap&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;image_plot(shap_values[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;],X_test[[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;../../../en/post/post18/index_files/figure-html/unnamed-chunk-15-5.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s very subtle, but it looks like you&amp;rsquo;re appreciating the legs and buttocks, etc. It needs to be cropped to take out the horse&amp;rsquo;s body only, since it seems to be responding to the background. I think I need to build a model for object detection. I&amp;rsquo;ll think about this another time.&lt;/p&gt;
&lt;h2 id=&#34;4-finally&#34;&gt;4. Finally&lt;/h2&gt;
&lt;p&gt;To be honest, it hasn&amp;rsquo;t worked out at all. Is it still difficult to predict rankings from the horse&amp;rsquo;s body? Does multiplying it with other variables change the results? I don&amp;rsquo;t think I&amp;rsquo;m able to extract good features from the horses as it is.
Do I need to get to the point where I can get a paddock video from Youtube and analyze it with the &lt;code&gt;Encoder-Decoder&lt;/code&gt; model to make it work? I&amp;rsquo;d love to do it when I&amp;rsquo;m good enough to do it (I don&amp;rsquo;t know when that will be). Until then, I need to improve my PC specs. Maybe I&amp;rsquo;ll use the cash handout.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Predicting Horse Racing Results Using LightGBM</title>
      <link>/en/post/post16/</link>
      <pubDate>Sat, 29 Feb 2020 00:00:00 +0000</pubDate>
      <guid>/en/post/post16/</guid>
      <description>&lt;p&gt;Hi. It&amp;rsquo;s been quite a while, but I&amp;rsquo;d like to create a model to predict the outcome of a race based on race result data previously collected from yahoo.keiba in order to study Python.&lt;/p&gt;
&lt;h2 id=&#34;1data-import&#34;&gt;1.Data Import&lt;/h2&gt;
&lt;p&gt;First, I get the race result data saved from &lt;code&gt;sqlite&lt;/code&gt; to the &lt;code&gt;pandas&lt;/code&gt; data frame.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;conn &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; sqlite3&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;connect(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;C:\hogehoge\horse_data.db&amp;#39;&lt;/span&gt;)
sql &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;SELECT * FROM race_result&amp;#39;&lt;/span&gt;
df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_sql(con&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;conn,sql&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;sql)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Let&amp;rsquo;s check the contents of the data. The columns are as follows, with order being the order of arrival.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;columns
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;## Index([&#39;order&#39;, &#39;frame_number&#39;, &#39;horse_number&#39;, &#39;trainer&#39;, &#39;passing_rank&#39;,
##        &#39;last_3F&#39;, &#39;time&#39;, &#39;margin&#39;, &#39;horse_name&#39;, &#39;horse_age&#39;, &#39;horse_sex&#39;,
##        &#39;horse_weight&#39;, &#39;horse_weight_change&#39;, &#39;brinker&#39;, &#39;jockey&#39;,
##        &#39;jockey_weight&#39;, &#39;jockey_weight_change&#39;, &#39;odds&#39;, &#39;popularity&#39;,
##        &#39;race_date&#39;, &#39;race_course&#39;, &#39;race_name&#39;, &#39;race_distance&#39;, &#39;type&#39;,
##        &#39;race_turn&#39;, &#39;race_condition&#39;, &#39;race_weather&#39;, &#39;colour&#39;, &#39;owner&#39;,
##        &#39;farm&#39;, &#39;locality&#39;, &#39;horse_birthday&#39;, &#39;father&#39;, &#39;mother&#39;, &#39;prize&#39;,
##        &#39;http&#39;],
##       dtype=&#39;object&#39;)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Checking the contents of the order, you&amp;rsquo;ll see that many of the orders have parentheses () and that they are recognized by the letter type because of the presence of cancellation, abort and disqualification. By the way, the order in parentheses is the order of entry, which means that the horse has been disqualified for interfering with another horse&amp;rsquo;s running (&lt;a href=&#34;http://www.jra.go.jp/judge/)&#34;&gt;http://www.jra.go.jp/judge/)&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[:,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;order&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unique()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;## array([&#39;1&#39;, &#39;7&#39;, &#39;2&#39;, &#39;8&#39;, &#39;5&#39;, &#39;15&#39;, &#39;6&#39;, &#39;12&#39;, &#39;11&#39;, &#39;14&#39;, &#39;3&#39;, &#39;13&#39;,
##        &#39;4&#39;, &#39;16&#39;, &#39;9&#39;, &#39;10&#39;, &#39;取消&#39;, &#39;中止&#39;, &#39;除外&#39;, &#39;17&#39;, &#39;18&#39;, &#39;4(3)&#39;, &#39;2(1)&#39;,
##        &#39;3(2)&#39;, &#39;6(4)&#39;, &#39;失格&#39;, &#39;9(8)&#39;, &#39;16(6)&#39;, &#39;12(12)&#39;, &#39;13(9)&#39;, &#39;6(3)&#39;,
##        &#39;10(7)&#39;, &#39;6(5)&#39;, &#39;9(3)&#39;, &#39;11(8)&#39;, &#39;13(2)&#39;, &#39;12(9)&#39;, &#39;14(7)&#39;,
##        &#39;10(1)&#39;, &#39;16(8)&#39;, &#39;14(6)&#39;, &#39;10(3)&#39;, &#39;12(1)&#39;, &#39;13(6)&#39;, &#39;7(1)&#39;,
##        &#39;12(6)&#39;, &#39;6(2)&#39;, &#39;11(2)&#39;, &#39;15(6)&#39;, &#39;13(10)&#39;, &#39;14(4)&#39;, &#39;7(5)&#39;,
##        &#39;17(4)&#39;, &#39;9(7)&#39;, &#39;16(14)&#39;, &#39;12(11)&#39;, &#39;14(2)&#39;, &#39;8(2)&#39;, &#39;9(5)&#39;,
##        &#39;11(5)&#39;, &#39;12(7)&#39;, &#39;11(1)&#39;, &#39;12(8)&#39;, &#39;7(4)&#39;, &#39;5(4)&#39;, &#39;13(12)&#39;,
##        &#39;14(3)&#39;, &#39;10(2)&#39;, &#39;11(10)&#39;, &#39;18(3)&#39;, &#39;10(4)&#39;, &#39;15(8)&#39;, &#39;8(3)&#39;,
##        &#39;5(1)&#39;, &#39;10(5)&#39;, &#39;7(3)&#39;, &#39;5(2)&#39;, &#39;9(1)&#39;, &#39;13(3)&#39;, &#39;16(11)&#39;,
##        &#39;11(3)&#39;, &#39;18(15)&#39;, &#39;11(6)&#39;, &#39;10(6)&#39;, &#39;14(12)&#39;, &#39;12(5)&#39;, &#39;15(14)&#39;,
##        &#39;17(8)&#39;, &#39;18(6)&#39;, &#39;4(2)&#39;, &#39;18(10)&#39;, &#39;16(7)&#39;, &#39;13(1)&#39;, &#39;16(10)&#39;,
##        &#39;15(7)&#39;, &#39;9(4)&#39;, &#39;15(5)&#39;, &#39;12(3)&#39;, &#39;8(7)&#39;, &#39;15(2)&#39;, &#39;12(10)&#39;,
##        &#39;14(9)&#39;, &#39;3(1)&#39;, &#39;6(1)&#39;, &#39;14(5)&#39;, &#39;15(4)&#39;, &#39;11(4)&#39;, &#39;12(4)&#39;,
##        &#39;16(4)&#39;, &#39;9(2)&#39;, &#39;13(5)&#39;, &#39;12(2)&#39;, &#39;15(1)&#39;, &#39;4(1)&#39;, &#39;14(13)&#39;,
##        &#39;14(1)&#39;, &#39;13(7)&#39;, &#39;5(3)&#39;, &#39;8(6)&#39;, &#39;15(13)&#39;, &#39;7(2)&#39;, &#39;15(11)&#39;,
##        &#39;10(9)&#39;, &#39;11(9)&#39;, &#39;8(4)&#39;, &#39;15(3)&#39;, &#39;13(4)&#39;, &#39;16(12)&#39;, &#39;16(5)&#39;,
##        &#39;18(11)&#39;, &#39;10(8)&#39;, &#39;18(8)&#39;, &#39;14(8)&#39;, &#39;16(9)&#39;, &#39;8(5)&#39;, &#39;8(1)&#39;,
##        &#39;14(11)&#39;, &#39;9(6)&#39;, &#39;16(13)&#39;, &#39;16(15)&#39;, &#39;11(11)&#39;, &#39;15(10)&#39;, &#39;7(6)&#39;],
##       dtype=object)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Let&amp;rsquo;s fix this first. Remove the parentheses and change the type to int, and add the arrival order as a new column &lt;code&gt;arriving order&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;arriving order&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;order&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;str&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;contains(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;\d*\(\d*\)&amp;#39;&lt;/span&gt;,regex&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;order&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;replace(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;\d+\(&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;,regex&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;replace(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;\)&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;,regex&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;float64&amp;#39;&lt;/span&gt;)
df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;arriving order&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unique()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;## array([nan,  3.,  1.,  2.,  4.,  8.,  6., 12.,  9.,  7.,  5., 10., 14.,
##        11., 15., 13.])
&lt;/code&gt;&lt;/pre&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;order&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;order&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;replace(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;\(\d+\)&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;,regex&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)
df &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; df: &lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt;df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;order&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;str&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;contains(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;(取消|中止|除外|失格)&amp;#39;&lt;/span&gt;,regex&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;## C:\Users\aashi\ANACON~1\lib\site-packages\pandas\core\strings.py:1954: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.
##   return func(self, *args, **kwargs)
&lt;/code&gt;&lt;/pre&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;order&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;order&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;float64&amp;#39;&lt;/span&gt;)
df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;order&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unique()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;## array([ 1.,  7.,  2.,  8.,  5., 15.,  6., 12., 11., 14.,  3., 13.,  4.,
##        16.,  9., 10., 17., 18.])
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We were able to process it into a clean &lt;code&gt;float&lt;/code&gt; type. Now let&amp;rsquo;s move on to preprocessing the last three furlongs&#39; times. We use the last three furlongs&#39; time of the last race for our prediction.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;last_3F&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;last_3F&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;replace(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;character(0)&amp;#39;&lt;/span&gt;,np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;nan,regex&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;float64&amp;#39;&lt;/span&gt;)
df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;last_3F&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;groupby(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;horse_name&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;last_3F&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shift(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Also include the previous race and rankings and any additional positions in the dataset.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;prerace&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;groupby(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;horse_name&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;race_name&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shift(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;preorder&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;groupby(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;horse_name&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;order&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shift(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;prepassing&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;groupby(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;horse_name&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;passing_rank&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shift(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The accumulated prize money earned at the time of running will also be added.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;preprize&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;groupby(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;horse_name&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;prize&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shift(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;preprize&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;preprize&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fillna(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;margin&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;groupby(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;horse_name&amp;#39;&lt;/span&gt;)[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;margin&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shift(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;We also add missing values, data type fixes, and label encoding for categorical data.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;horse_weight&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;horse_weight&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;float64&amp;#39;&lt;/span&gt;)
df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;margin&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;margin&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;replace(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;character(0)&amp;#39;&lt;/span&gt;,np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;nan,regex&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)
df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;horse_age&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;horse_age&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;float64&amp;#39;&lt;/span&gt;)
df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;horse_weight_change&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;horse_weight_change&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;float64&amp;#39;&lt;/span&gt;)
df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;jockey_weight&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;jockey_weight&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;float64&amp;#39;&lt;/span&gt;)
df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;race_distance&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;race_distance&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;replace(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;m&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;,regex&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;True)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;float64&amp;#39;&lt;/span&gt;)
df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;race_turn&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;race_turn&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;replace(&lt;span style=&#34;color:#e6db74&#34;&gt;r&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;character(0)&amp;#39;&lt;/span&gt;,np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;nan,regex&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)
df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;loc[df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;order&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;!=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;order&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;

df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;race_turn&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;race_turn&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fillna(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;missing&amp;#39;&lt;/span&gt;)
df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;colour&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;colour&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fillna(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;missing&amp;#39;&lt;/span&gt;)
df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;prepassing&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;prepassing&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fillna(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;missing&amp;#39;&lt;/span&gt;)
df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;prerace&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;prerace&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fillna(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;missing&amp;#39;&lt;/span&gt;)
df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;father&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;father&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fillna(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;missing&amp;#39;&lt;/span&gt;)
df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mother&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mother&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fillna(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;missing&amp;#39;&lt;/span&gt;)

&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; sklearn &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; preprocessing
cat_list &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;trainer&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;horse_name&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;horse_sex&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;brinker&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;jockey&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;race_course&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;race_name&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;type&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;race_turn&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;race_condition&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;race_weather&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;colour&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;father&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;mother&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;prerace&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;prepassing&amp;#39;&lt;/span&gt;]
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; column &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; cat_list:
    target_column &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[column]
    le &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; preprocessing&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;LabelEncoder()
    le&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;fit(target_column)
    label_encoded_column &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; le&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transform(target_column)
    df[column] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Series(label_encoded_column)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;astype(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;category&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;## LabelEncoder()
## LabelEncoder()
## LabelEncoder()
## LabelEncoder()
## LabelEncoder()
## LabelEncoder()
## LabelEncoder()
## LabelEncoder()
## LabelEncoder()
## LabelEncoder()
## LabelEncoder()
## LabelEncoder()
## LabelEncoder()
## LabelEncoder()
## LabelEncoder()
## LabelEncoder()
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;2-creating-a-model&#34;&gt;2. Creating a Model&lt;/h2&gt;
&lt;p&gt;Now, let&amp;rsquo;s try to build a prediction model with &lt;code&gt;LightGBM&lt;/code&gt;. The &lt;code&gt;optuna&lt;/code&gt; &lt;code&gt;LightGBM&lt;/code&gt; is used to perform hyperparameter tuning and calculate the &lt;code&gt;confusion matrix&lt;/code&gt;, as well as the correctness rate of test data calculated with the trained model.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; optuna.integration.lightgbm &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; lgb
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; sklearn.model_selection &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; train_test_split

y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;order&amp;#39;&lt;/span&gt;]
x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;drop([&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;order&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;passing_rank&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;time&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;odds&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;popularity&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;owner&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;farm&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;locality&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;horse_birthday&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;prize&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;race_date&amp;#39;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;margin&amp;#39;&lt;/span&gt;],axis&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)

X_train, X_test, y_train, y_test &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_test_split(x, y)
X_train, x_val, y_train, y_val &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; train_test_split(X_train, y_train)

lgb_train &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; lgb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dataset(X_train, y_train)
lgb_eval &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; lgb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dataset(x_val, y_val)
lgb_test &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; lgb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dataset(X_test, y_test, reference&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;lgb_train)

lgbm_params &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;objective&amp;#39;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;binary&amp;#39;&lt;/span&gt;,
        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;boost_from_average&amp;#39;&lt;/span&gt;: False
    }

model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; lgb&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;train(lgbm_params, lgb_train, categorical_feature &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cat_list, valid_sets &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; lgb_eval,  num_boost_round&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;, early_stopping_rounds&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;, verbose_eval&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;False)

&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;calibration&lt;/span&gt;(y_proba, beta):
    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; y_proba &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; (y_proba &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; y_proba) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; beta)

sampling_rate &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; y_train&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum() &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; len(y_train)
y_proba &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(X_test, num_iteration&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;best_iteration)
y_proba_calib &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; calibration(y_proba, sampling_rate)

y_pred &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;vectorize(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.49&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)(y_proba_calib)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Visualization part.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; sklearn.metrics &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; plt
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; seaborn &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; sns

&lt;span style=&#34;color:#75715e&#34;&gt;# Calculating the AUC (Area Under the Curve)&lt;/span&gt;
fpr, tpr, thresholds &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; roc_curve(y_test, y_pred)
auc &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; auc(fpr, tpr)

&lt;span style=&#34;color:#75715e&#34;&gt;# Plot the ROC curve&lt;/span&gt;
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(fpr, tpr, label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;ROC curve (area = &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;%.2f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;)&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;%&lt;/span&gt;auc)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;ROC curve&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;False Positive Rate&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;True Positive Rate&amp;#39;&lt;/span&gt;)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;grid(True)
plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;../../../en/post/post16/index_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;close()

&lt;span style=&#34;color:#75715e&#34;&gt;# Generate a Confusion Matrix&lt;/span&gt;
ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred))&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;## &amp;lt;sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay object at 0x00000000C690E288&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;../../../en/post/post16/index_files/figure-html/unnamed-chunk-15-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;close()

accuracy_score(y_test, y_pred)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;## 0.9300689387764461
&lt;/code&gt;&lt;/pre&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;precision_score(y_test, y_pred)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;## 0.9185022026431718
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The &lt;code&gt;accuracy_score&lt;/code&gt; (prediction accuracy) is over 90% and the &lt;code&gt;precision_Score&lt;/code&gt; (the percentage of data correct that predicted positive = 1) is good.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;recall_score(y_test, y_pred)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;## 0.012291457878912929
&lt;/code&gt;&lt;/pre&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;f1_score(y_test, y_pred)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;## 0.02425828970331588
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;On the other hand, we can see that the &lt;code&gt;recall_score&lt;/code&gt; (percentage of sample that was predicted to be positive and actually true) is low and the false negative is high. As a result, the &lt;code&gt;F1&lt;/code&gt; value is also low. In the case of the horse racing prediction model, high false negatives are better than high false positives, but we have to work harder to reduce the false negatives to increase the return rate. This is an issue for the future. In the next section, I will use the &lt;code&gt;shapley&lt;/code&gt; value to do a factorization.&lt;/p&gt;
&lt;h2 id=&#34;3-interpreting-results-in-shap&#34;&gt;3. Interpreting results in shap&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; shap

shap&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;initjs()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;## &amp;lt;IPython.core.display.HTML object&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;explainer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; shap&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;TreeExplainer(model)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;## Setting feature_perturbation = &amp;quot;tree_path_dependent&amp;quot; because no background data was given.
&lt;/code&gt;&lt;/pre&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;shap_values &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; explainer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shap_values(X_test)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;## LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;First, we&amp;rsquo;ll see how important each feature is. The &lt;code&gt;summary_plot&lt;/code&gt; method is used.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;shap&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary_plot(shap_values, X_test)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;../../../en/post/post16/index_files/figure-html/unnamed-chunk-18-5.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The horizontal axis represents the average importance of each feature (absolute value of the shap value), and we can see that preprize (amount of money won up to the last race), horse_age, and preorder (order of finish in the last race) are all important in predicting the winner of the race. The same is true for horse_age. However, it is not possible to evaluate it qualitatively just because it is important. For example, if the relationship between a higher preprize and a higher probability of being first is confirmed, that can be important information. Then you can check it. The &lt;code&gt;summary_plot&lt;/code&gt; method is used.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;shap&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary_plot(shap_values[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], X_test)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;../../../en/post/post16/index_files/figure-html/unnamed-chunk-19-7.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The above figure also shows the importance of each feature (not absolute values in this case). In this case, the importance of each feature is shown in the violin plot and is colored according to the size of the feature value. For example, in the case of preprize, the red distribution occurs only where the horizontal axis is greater than 0, and this is where the feature value of preprize is large. This means that we can take the obvious interpretation that the probability of finishing first increases on average with the amount of money won up to the previous race.
Other factors such as horse_age, preorder, and last_3F seem to increase the probability of finishing first as the feature value becomes smaller, while horse_weight and jokey_weight seem to increase the probability of finishing first as the feature value becomes larger. On the other hand, there is no qualitative relationship between the two variables.&lt;/p&gt;
&lt;p&gt;Next, let&amp;rsquo;s look at the relationship between feature value and probability in more detail. We saw earlier that preprize increases the probability of being the first one to arrive as the feature value increases. But we don&amp;rsquo;t know if the increase is linear, exponential, or diminishing as in dependence on &lt;code&gt;\(log x\)&lt;/code&gt;. Let&amp;rsquo;s find out with the &lt;code&gt;dependence_plot&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;shap&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dependence_plot(ind&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;preprize&amp;#34;&lt;/span&gt;, shap_values&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;shap_values[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], features&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;X_test)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;../../../en/post/post16/index_files/figure-html/unnamed-chunk-20-9.png&#34; width=&#34;720&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The above figure plots the approximate form of the learned &lt;code&gt;LightGBM&lt;/code&gt; as a function of preprize. As we saw earlier, the probability of being the first one to be placed increases as the feature value increases. However, the increase is gradual and diminishing, and it almost reaches its peak at over 20 million yen. Also, in the figure above, we have color-coded by HORSE_AGE, so you can see the relationship with PREPRIZE. As you might expect, the probability of horses with high preprize is higher for the youngest horses to win the race.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s also check the &lt;code&gt;dependence_plot&lt;/code&gt; of the preorder.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;shap&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dependence_plot(ind&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;preorder&amp;#34;&lt;/span&gt;, shap_values&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;shap_values[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], features&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;X_test)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;../../../en/post/post16/index_files/figure-html/unnamed-chunk-21-11.png&#34; width=&#34;720&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As expected, the higher the order of the last race, the higher the probability of finishing first. I also checked the relationship with the time of last_3F, but it doesn&amp;rsquo;t seem to be very relevant here.&lt;/p&gt;
&lt;h2 id=&#34;4-summary&#34;&gt;4. Summary&lt;/h2&gt;
&lt;p&gt;I made a prediction model of horse racing using &lt;code&gt;LightGBM&lt;/code&gt;. As you would expect of &lt;code&gt;Light GBM&lt;/code&gt;, the prediction accuracy is very high. Also, the &lt;code&gt;shap&lt;/code&gt; value was successfully used to detect important features. This will help us understand how &lt;code&gt;LightGBM&lt;/code&gt; feels and improve our modeling accuracy as we continue to find better features.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
